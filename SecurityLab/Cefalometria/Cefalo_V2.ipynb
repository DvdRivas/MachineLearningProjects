{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60e2ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "# Procesamiento de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing as prp\n",
    "import shap\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelos\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Graficadores\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "#Otros\n",
    "# !pip install category_encoders\n",
    "from category_encoders import TargetEncoder\n",
    "# !pip install scikeras\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b6fa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edad</th>\n",
       "      <td>168.0</td>\n",
       "      <td>16.601190</td>\n",
       "      <td>6.017081</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANB</th>\n",
       "      <td>168.0</td>\n",
       "      <td>4.633929</td>\n",
       "      <td>2.605541</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICS_SN</th>\n",
       "      <td>168.0</td>\n",
       "      <td>107.113095</td>\n",
       "      <td>9.064919</td>\n",
       "      <td>62.0</td>\n",
       "      <td>102.00</td>\n",
       "      <td>107.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICS_plan_pal</th>\n",
       "      <td>168.0</td>\n",
       "      <td>64.851190</td>\n",
       "      <td>8.597897</td>\n",
       "      <td>33.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMPA</th>\n",
       "      <td>168.0</td>\n",
       "      <td>96.095238</td>\n",
       "      <td>7.291401</td>\n",
       "      <td>78.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>96.00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interincisal</th>\n",
       "      <td>168.0</td>\n",
       "      <td>119.976190</td>\n",
       "      <td>11.850340</td>\n",
       "      <td>76.0</td>\n",
       "      <td>113.00</td>\n",
       "      <td>119.00</td>\n",
       "      <td>127.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lab_sup_Lin_e</th>\n",
       "      <td>168.0</td>\n",
       "      <td>-0.776786</td>\n",
       "      <td>2.157537</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lab_inf_Lin_e</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>2.493297</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasolabial</th>\n",
       "      <td>168.0</td>\n",
       "      <td>97.476190</td>\n",
       "      <td>10.836815</td>\n",
       "      <td>72.0</td>\n",
       "      <td>89.00</td>\n",
       "      <td>97.00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overjet</th>\n",
       "      <td>168.0</td>\n",
       "      <td>3.732143</td>\n",
       "      <td>2.559410</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oberbite</th>\n",
       "      <td>168.0</td>\n",
       "      <td>2.636905</td>\n",
       "      <td>2.066776</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jarabak_Sum</th>\n",
       "      <td>168.0</td>\n",
       "      <td>400.410714</td>\n",
       "      <td>41.659057</td>\n",
       "      <td>380.0</td>\n",
       "      <td>393.75</td>\n",
       "      <td>398.00</td>\n",
       "      <td>401.0</td>\n",
       "      <td>931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angulo_perfil</th>\n",
       "      <td>168.0</td>\n",
       "      <td>165.279762</td>\n",
       "      <td>5.735618</td>\n",
       "      <td>149.0</td>\n",
       "      <td>162.00</td>\n",
       "      <td>165.00</td>\n",
       "      <td>169.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discre_long_arco</th>\n",
       "      <td>168.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.268153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clase_molar</th>\n",
       "      <td>168.0</td>\n",
       "      <td>1.327381</td>\n",
       "      <td>0.573852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overjet_2</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.244048</td>\n",
       "      <td>0.430805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perfil_labial</th>\n",
       "      <td>168.0</td>\n",
       "      <td>1.773810</td>\n",
       "      <td>0.989177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>168.0</td>\n",
       "      <td>1.267857</td>\n",
       "      <td>1.364535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count        mean        std    min     25%     50%    75%  \\\n",
       "edad              168.0   16.601190   6.017081    9.0   13.00   15.00   18.0   \n",
       "ANB               168.0    4.633929   2.605541   -7.0    3.00    5.00    6.0   \n",
       "ICS_SN            168.0  107.113095   9.064919   62.0  102.00  107.00  112.0   \n",
       "ICS_plan_pal      168.0   64.851190   8.597897   33.0   60.00   65.00   70.0   \n",
       "IMPA              168.0   96.095238   7.291401   78.0   91.00   96.00  101.0   \n",
       "Interincisal      168.0  119.976190  11.850340   76.0  113.00  119.00  127.0   \n",
       "Lab_sup_Lin_e     168.0   -0.776786   2.157537   -6.0   -2.00   -1.00    1.0   \n",
       "Lab_inf_Lin_e     168.0    0.660714   2.493297   -5.0   -1.00    0.25    2.0   \n",
       "Nasolabial        168.0   97.476190  10.836815   72.0   89.00   97.00  105.0   \n",
       "Overjet           168.0    3.732143   2.559410   -3.0    2.00    3.50    5.0   \n",
       "Oberbite          168.0    2.636905   2.066776   -4.0    1.50    3.00    4.0   \n",
       "Jarabak_Sum       168.0  400.410714  41.659057  380.0  393.75  398.00  401.0   \n",
       "Angulo_perfil     168.0  165.279762   5.735618  149.0  162.00  165.00  169.0   \n",
       "Discre_long_arco  168.0    2.857143   1.268153    0.0    2.00    3.00    4.0   \n",
       "Clase_molar       168.0    1.327381   0.573852    0.0    1.00    1.00    2.0   \n",
       "Overjet_2         168.0    0.244048   0.430805    0.0    0.00    0.00    0.0   \n",
       "Perfil_labial     168.0    1.773810   0.989177    0.0    1.00    2.00    2.0   \n",
       "label             168.0    1.267857   1.364535    0.0    0.00    1.00    2.0   \n",
       "\n",
       "                    max  \n",
       "edad               43.0  \n",
       "ANB                11.0  \n",
       "ICS_SN            141.0  \n",
       "ICS_plan_pal       93.0  \n",
       "IMPA              113.0  \n",
       "Interincisal      165.0  \n",
       "Lab_sup_Lin_e       6.0  \n",
       "Lab_inf_Lin_e       9.0  \n",
       "Nasolabial        130.0  \n",
       "Overjet            12.0  \n",
       "Oberbite           10.0  \n",
       "Jarabak_Sum       931.0  \n",
       "Angulo_perfil     182.0  \n",
       "Discre_long_arco    4.0  \n",
       "Clase_molar         2.0  \n",
       "Overjet_2           1.0  \n",
       "Perfil_labial       4.0  \n",
       "label               4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cefalometria_pva.csv\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58785086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edad</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.386074</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANB</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.421266</td>\n",
       "      <td>0.236867</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICS_SN</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.759667</td>\n",
       "      <td>0.064290</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.758865</td>\n",
       "      <td>0.794326</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICS_plan_pal</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.697325</td>\n",
       "      <td>0.092451</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMPA</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.850400</td>\n",
       "      <td>0.064526</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.849558</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interincisal</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.727128</td>\n",
       "      <td>0.071820</td>\n",
       "      <td>0.460606</td>\n",
       "      <td>0.684848</td>\n",
       "      <td>0.721212</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lab_sup_Lin_e</th>\n",
       "      <td>168.0</td>\n",
       "      <td>-0.129464</td>\n",
       "      <td>0.359590</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lab_inf_Lin_e</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.073413</td>\n",
       "      <td>0.277033</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasolabial</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.749817</td>\n",
       "      <td>0.083360</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overjet</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.311012</td>\n",
       "      <td>0.213284</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oberbite</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.263690</td>\n",
       "      <td>0.206678</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jarabak_Sum</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.430087</td>\n",
       "      <td>0.044747</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.422932</td>\n",
       "      <td>0.427497</td>\n",
       "      <td>0.430720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angulo_perfil</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.908131</td>\n",
       "      <td>0.031514</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.906593</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discre_long_arco</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.317038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clase_molar</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.663690</td>\n",
       "      <td>0.286926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overjet_2</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.244048</td>\n",
       "      <td>0.430805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perfil_labial</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.443452</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>168.0</td>\n",
       "      <td>1.267857</td>\n",
       "      <td>1.364535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count      mean       std       min       25%       50%  \\\n",
       "edad              168.0  0.386074  0.139932  0.209302  0.302326  0.348837   \n",
       "ANB               168.0  0.421266  0.236867 -0.636364  0.272727  0.454545   \n",
       "ICS_SN            168.0  0.759667  0.064290  0.439716  0.723404  0.758865   \n",
       "ICS_plan_pal      168.0  0.697325  0.092451  0.354839  0.645161  0.698925   \n",
       "IMPA              168.0  0.850400  0.064526  0.690265  0.805310  0.849558   \n",
       "Interincisal      168.0  0.727128  0.071820  0.460606  0.684848  0.721212   \n",
       "Lab_sup_Lin_e     168.0 -0.129464  0.359590 -1.000000 -0.333333 -0.166667   \n",
       "Lab_inf_Lin_e     168.0  0.073413  0.277033 -0.555556 -0.111111  0.027778   \n",
       "Nasolabial        168.0  0.749817  0.083360  0.553846  0.684615  0.746154   \n",
       "Overjet           168.0  0.311012  0.213284 -0.250000  0.166667  0.291667   \n",
       "Oberbite          168.0  0.263690  0.206678 -0.400000  0.150000  0.300000   \n",
       "Jarabak_Sum       168.0  0.430087  0.044747  0.408163  0.422932  0.427497   \n",
       "Angulo_perfil     168.0  0.908131  0.031514  0.818681  0.890110  0.906593   \n",
       "Discre_long_arco  168.0  0.714286  0.317038  0.000000  0.500000  0.750000   \n",
       "Clase_molar       168.0  0.663690  0.286926  0.000000  0.500000  0.500000   \n",
       "Overjet_2         168.0  0.244048  0.430805  0.000000  0.000000  0.000000   \n",
       "Perfil_labial     168.0  0.443452  0.247294  0.000000  0.250000  0.500000   \n",
       "label             168.0  1.267857  1.364535  0.000000  0.000000  1.000000   \n",
       "\n",
       "                       75%  max  \n",
       "edad              0.418605  1.0  \n",
       "ANB               0.545455  1.0  \n",
       "ICS_SN            0.794326  1.0  \n",
       "ICS_plan_pal      0.752688  1.0  \n",
       "IMPA              0.893805  1.0  \n",
       "Interincisal      0.769697  1.0  \n",
       "Lab_sup_Lin_e     0.166667  1.0  \n",
       "Lab_inf_Lin_e     0.222222  1.0  \n",
       "Nasolabial        0.807692  1.0  \n",
       "Overjet           0.416667  1.0  \n",
       "Oberbite          0.400000  1.0  \n",
       "Jarabak_Sum       0.430720  1.0  \n",
       "Angulo_perfil     0.928571  1.0  \n",
       "Discre_long_arco  1.000000  1.0  \n",
       "Clase_molar       1.000000  1.0  \n",
       "Overjet_2         0.000000  1.0  \n",
       "Perfil_labial     0.500000  1.0  \n",
       "label             2.000000  4.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['edad'] = df['edad'] / 43\n",
    "df['ANB'] = df['ANB'] / 11\n",
    "df['ICS_SN'] = df['ICS_SN'] / 141\n",
    "df['ICS_plan_pal'] = df['ICS_plan_pal'] / 93\n",
    "df['IMPA'] = df['IMPA'] / 113\n",
    "df['Interincisal'] = df['Interincisal'] / 165\n",
    "df['Lab_sup_Lin_e'] = df['Lab_sup_Lin_e'] / 6\n",
    "df['Lab_inf_Lin_e'] = df['Lab_inf_Lin_e'] / 9\n",
    "df['Nasolabial'] = df['Nasolabial'] / 130\n",
    "df['Overjet'] = df['Overjet'] / 12\n",
    "df['Oberbite'] = df['Oberbite'] / 10\n",
    "df['Jarabak_Sum'] = df['Jarabak_Sum'] / 931\n",
    "df['Angulo_perfil'] = df['Angulo_perfil'] / 182\n",
    "df['Discre_long_arco'] = df['Discre_long_arco'] / 4\n",
    "df['Clase_molar'] = df['Clase_molar'] / 2\n",
    "df['Perfil_labial'] = df['Perfil_labial'] / 4\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01feb2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>genero</th>\n",
       "      <th>ANB</th>\n",
       "      <th>ICS_SN</th>\n",
       "      <th>ICS_plan_pal</th>\n",
       "      <th>IMPA</th>\n",
       "      <th>Interincisal</th>\n",
       "      <th>Lab_sup_Lin_e</th>\n",
       "      <th>Lab_inf_Lin_e</th>\n",
       "      <th>Nasolabial</th>\n",
       "      <th>Overjet</th>\n",
       "      <th>Oberbite</th>\n",
       "      <th>Jarabak_Sum</th>\n",
       "      <th>Angulo_perfil</th>\n",
       "      <th>Discre_long_arco</th>\n",
       "      <th>Clase_molar</th>\n",
       "      <th>Overjet_2</th>\n",
       "      <th>Perfil_labial</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.720930</td>\n",
       "      <td>M</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.751773</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>M</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.716312</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>M</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.725664</td>\n",
       "      <td>0.860606</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.432868</td>\n",
       "      <td>0.895604</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279070</td>\n",
       "      <td>F</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.426423</td>\n",
       "      <td>0.906593</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.325581</td>\n",
       "      <td>F</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.929204</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.415682</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       edad genero       ANB    ICS_SN  ICS_plan_pal      IMPA  Interincisal  \\\n",
       "0  0.720930      M  0.090909  0.751773      0.752688  0.867257      0.769697   \n",
       "1  0.302326      M  0.454545  0.716312      0.752688  0.814159      0.836364   \n",
       "2  0.302326      M  0.272727  0.673759      0.752688  0.725664      0.860606   \n",
       "3  0.279070      F  0.681818  0.673759      0.870968  0.787611      0.854545   \n",
       "4  0.325581      F  0.454545  0.808511      0.645161  0.929204      0.696970   \n",
       "\n",
       "   Lab_sup_Lin_e  Lab_inf_Lin_e  Nasolabial   Overjet  Oberbite  Jarabak_Sum  \\\n",
       "0      -0.333333       0.000000    0.715385  0.333333      0.40     0.421053   \n",
       "1       0.333333       0.000000    0.707692  0.250000      0.20     0.421053   \n",
       "2      -0.500000      -0.222222    0.800000  0.416667      0.80     0.432868   \n",
       "3       0.000000       0.000000    0.730769  0.291667      0.50     0.426423   \n",
       "4      -0.166667      -0.055556    0.700000  0.250000      0.15     0.415682   \n",
       "\n",
       "   Angulo_perfil  Discre_long_arco  Clase_molar  Overjet_2  Perfil_labial  \\\n",
       "0       0.945055              1.00          0.5          0           0.25   \n",
       "1       0.890110              0.50          0.5          0           0.50   \n",
       "2       0.895604              0.50          1.0          1           0.25   \n",
       "3       0.906593              0.50          1.0          0           0.25   \n",
       "4       0.923077              0.25          0.5          0           0.25   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74914a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "data_x = df['label']\n",
    "\n",
    "# Create a list of colors for the boxplots based on the number of features you have\n",
    "boxplots_colors = ['yellowgreen', 'olivedrab']\n",
    "\n",
    "# Boxplot data\n",
    "bp = ax.boxplot(data_x, patch_artist = True, vert = False)\n",
    "\n",
    "# Change to the desired color and add transparency\n",
    "for patch, color in zip(bp['boxes'], boxplots_colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.4)\n",
    "\n",
    "# Create a list of colors for the violin plots based on the number of features you have\n",
    "violin_colors = ['thistle', 'orchid']\n",
    "\n",
    "# Violinplot data\n",
    "vp = ax.violinplot(data_x, points=500, \n",
    "               showmeans=False, showextrema=False, showmedians=False, vert=False)\n",
    "\n",
    "for idx, b in enumerate(vp['bodies']):\n",
    "    # Get the center of the plot\n",
    "    m = np.mean(b.get_paths()[0].vertices[:, 0])\n",
    "    # Modify it so we only see the upper half of the violin plot\n",
    "    b.get_paths()[0].vertices[:, 1] = np.clip(b.get_paths()[0].vertices[:, 1], idx+1, idx+2)\n",
    "    # Change to the desired color\n",
    "    b.set_color(violin_colors[idx])\n",
    "\n",
    "# Crear scatter plot horizontal\n",
    "scatter_data = data_x\n",
    "y = np.random.normal(1, 0.04, size=len(scatter_data)) - 0.1\n",
    "plt.scatter(scatter_data, y, alpha=0.6)\n",
    "\n",
    "# plt.yticks(np.arange(1,1,1), ['Feature 1', 'Feature 2'])  # Set text labels.\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Density')\n",
    "plt.title(\"Raincloud plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9ec044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((117, 18), (51, 18))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.drop(['label'],axis=1),df['label'],test_size=0.3,random_state=42)\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e77b8bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 117 entries, 159 to 102\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   edad              117 non-null    float64\n",
      " 1   genero            117 non-null    float64\n",
      " 2   ANB               117 non-null    float64\n",
      " 3   ICS_SN            117 non-null    float64\n",
      " 4   ICS_plan_pal      117 non-null    float64\n",
      " 5   IMPA              117 non-null    float64\n",
      " 6   Interincisal      117 non-null    float64\n",
      " 7   Lab_sup_Lin_e     117 non-null    float64\n",
      " 8   Lab_inf_Lin_e     117 non-null    float64\n",
      " 9   Nasolabial        117 non-null    float64\n",
      " 10  Overjet           117 non-null    float64\n",
      " 11  Oberbite          117 non-null    float64\n",
      " 12  Jarabak_Sum       117 non-null    float64\n",
      " 13  Angulo_perfil     117 non-null    float64\n",
      " 14  Discre_long_arco  117 non-null    float64\n",
      " 15  Clase_molar       117 non-null    float64\n",
      " 16  Overjet_2         117 non-null    int64  \n",
      " 17  Perfil_labial     117 non-null    float64\n",
      "dtypes: float64(17), int64(1)\n",
      "memory usage: 17.4 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>genero</th>\n",
       "      <th>ANB</th>\n",
       "      <th>ICS_SN</th>\n",
       "      <th>ICS_plan_pal</th>\n",
       "      <th>IMPA</th>\n",
       "      <th>Interincisal</th>\n",
       "      <th>Lab_sup_Lin_e</th>\n",
       "      <th>Lab_inf_Lin_e</th>\n",
       "      <th>Nasolabial</th>\n",
       "      <th>Overjet</th>\n",
       "      <th>Oberbite</th>\n",
       "      <th>Jarabak_Sum</th>\n",
       "      <th>Angulo_perfil</th>\n",
       "      <th>Discre_long_arco</th>\n",
       "      <th>Clase_molar</th>\n",
       "      <th>Overjet_2</th>\n",
       "      <th>Perfil_labial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.279070</td>\n",
       "      <td>1.489372</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.624242</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.441461</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.35887</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.348837</td>\n",
       "      <td>1.489372</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.709220</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.437164</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.62321</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.348837</td>\n",
       "      <td>1.197758</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.423201</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.62321</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.395349</td>\n",
       "      <td>1.197758</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.432868</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.62321</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>1.197758</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.435016</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.35887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         edad    genero       ANB    ICS_SN  ICS_plan_pal      IMPA  \\\n",
       "159  0.279070  1.489372  0.909091  0.822695      0.526882  0.814159   \n",
       "96   0.348837  1.489372  0.545455  0.709220      0.698925  0.840708   \n",
       "11   0.348837  1.197758  0.181818  0.744681      0.731183  0.769912   \n",
       "67   0.395349  1.197758  0.454545  0.702128      0.720430  0.876106   \n",
       "132  0.302326  1.197758  0.636364  0.659574      0.860215  0.814159   \n",
       "\n",
       "     Interincisal  Lab_sup_Lin_e  Lab_inf_Lin_e  Nasolabial   Overjet  \\\n",
       "159      0.624242       0.833333       0.333333    0.653846  1.000000   \n",
       "96       0.727273      -0.250000      -0.111111    0.753846  0.166667   \n",
       "11       0.806061      -1.000000      -0.333333    1.000000  0.166667   \n",
       "67       0.709091      -0.833333      -0.333333    0.946154  0.250000   \n",
       "132      0.787879       0.166667       0.388889    0.753846  0.416667   \n",
       "\n",
       "     Oberbite  Jarabak_Sum  Angulo_perfil  Discre_long_arco  Clase_molar  \\\n",
       "159       0.3     0.441461       0.846154               1.0      2.35887   \n",
       "96        0.2     0.437164       0.890110               1.0      0.62321   \n",
       "11        0.2     0.423201       0.928571               0.5      0.62321   \n",
       "67        0.4     0.432868       0.912088               1.0      0.62321   \n",
       "132       0.2     0.435016       0.868132               1.0      2.35887   \n",
       "\n",
       "     Overjet_2  Perfil_labial  \n",
       "159          1           1.00  \n",
       "96           0           0.25  \n",
       "11           0           0.25  \n",
       "67           0           0.75  \n",
       "132          1           0.75  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "encoder = TargetEncoder(cols=['genero','Clase_molar'])\n",
    "encoder.fit(x_train,y_train)\n",
    "\n",
    "#Utiliza el mismo encoder para transformar el dataset de testing y el de testing?\n",
    "x_train_enc = encoder.transform(x_train)\n",
    "x_test_enc = encoder.transform(x_test)\n",
    "print(x_train_enc.info())\n",
    "x_train_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3864009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-22 11:49:45,419] A new study created in memory with name: no-name-e53a020d-8bac-46a7-bf00-e3e75f7b1ae9\n",
      "[I 2023-11-22 11:49:55,392] Trial 0 finished with value: 0.3921568691730499 and parameters: {'regularizer_type': 'l1', 'activation_1': 'selu', 'activation_2': 'linear', 'activation_3': 'relu', 'activation_4': 'swish', 'activation_5': 'softmax', 'activation_6': 'softplus', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'uniform', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 0 with value: 0.3921568691730499.\n",
      "[I 2023-11-22 11:50:05,642] Trial 1 finished with value: 0.3921568691730499 and parameters: {'regularizer_type': None, 'activation_1': 'softmax', 'activation_2': 'swish', 'activation_3': 'softmax', 'activation_4': 'tanh', 'activation_5': 'sigmoid', 'activation_6': 'sigmoid', 'init_mode_1': 'uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'he_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'glorot_normal'}. Best is trial 0 with value: 0.3921568691730499.\n",
      "[I 2023-11-22 11:50:15,607] Trial 2 finished with value: 0.4117647111415863 and parameters: {'regularizer_type': None, 'activation_1': 'exponential', 'activation_2': 'swish', 'activation_3': 'linear', 'activation_4': 'softplus', 'activation_5': 'elu', 'activation_6': 'softmax', 'init_mode_1': 'zero', 'init_mode_2': 'zero', 'init_mode_3': 'he_uniform', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_normal', 'init_mode_6': 'glorot_normal'}. Best is trial 2 with value: 0.4117647111415863.\n",
      "[I 2023-11-22 11:50:26,395] Trial 3 finished with value: 0.03921568766236305 and parameters: {'regularizer_type': None, 'activation_1': 'selu', 'activation_2': 'swish', 'activation_3': 'hard_sigmoid', 'activation_4': 'sigmoid', 'activation_5': 'linear', 'activation_6': 'tanh', 'init_mode_1': 'he_uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'glorot_normal'}. Best is trial 2 with value: 0.4117647111415863.\n",
      "[I 2023-11-22 11:50:36,587] Trial 4 finished with value: 0.3921568691730499 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softmax', 'activation_2': 'linear', 'activation_3': 'softplus', 'activation_4': 'exponential', 'activation_5': 'elu', 'activation_6': 'elu', 'init_mode_1': 'normal', 'init_mode_2': 'normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'zero', 'init_mode_6': 'he_normal'}. Best is trial 2 with value: 0.4117647111415863.\n",
      "[I 2023-11-22 11:50:46,551] Trial 5 finished with value: 0.4117647111415863 and parameters: {'regularizer_type': 'l2', 'activation_1': 'exponential', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'activation_5': 'softmax', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'normal', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_normal'}. Best is trial 2 with value: 0.4117647111415863.\n",
      "[I 2023-11-22 11:50:56,690] Trial 6 finished with value: 0.3333333432674408 and parameters: {'regularizer_type': 'l1', 'activation_1': 'hard_sigmoid', 'activation_2': 'softsign', 'activation_3': 'selu', 'activation_4': 'hard_sigmoid', 'activation_5': 'exponential', 'activation_6': 'linear', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'he_normal', 'init_mode_6': 'glorot_normal'}. Best is trial 2 with value: 0.4117647111415863.\n",
      "[I 2023-11-22 11:51:06,622] Trial 7 finished with value: 0.3921568691730499 and parameters: {'regularizer_type': 'l2', 'activation_1': 'linear', 'activation_2': 'tanh', 'activation_3': 'elu', 'activation_4': 'swish', 'activation_5': 'tanh', 'activation_6': 'linear', 'init_mode_1': 'uniform', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_normal'}. Best is trial 2 with value: 0.4117647111415863.\n",
      "[I 2023-11-22 11:51:16,967] Trial 8 finished with value: 0.3333333432674408 and parameters: {'regularizer_type': 'l1', 'activation_1': 'sigmoid', 'activation_2': 'exponential', 'activation_3': 'hard_sigmoid', 'activation_4': 'relu', 'activation_5': 'hard_sigmoid', 'activation_6': 'elu', 'init_mode_1': 'he_normal', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'glorot_normal'}. Best is trial 2 with value: 0.4117647111415863.\n",
      "[W 2023-11-22 11:51:25,159] Trial 9 failed with parameters: {'regularizer_type': 'l2', 'activation_1': 'hard_sigmoid', 'activation_2': 'hard_sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'softsign', 'activation_5': 'swish', 'activation_6': 'softmax', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'uniform', 'init_mode_6': 'zero'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\AppData\\Local\\Temp\\ipykernel_7632\\1387473715.py\", line 53, in objective\n",
      "    history = model.fit(x_train_enc, y_train, epochs=100,  validation_data = (x_test_enc, y_test), verbose=0)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 831, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 867, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py\", line 1264, in _call_flat\n",
      "    return self._inference_function.flat_call(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\", line 217, in flat_call\n",
      "    flat_outputs = self(*args)\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\", line 252, in __call__\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 1479, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DiAl_\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 60, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2023-11-22 11:51:25,180] Trial 9 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Iniciar la optimizacin con Optuna\u001b[39;00m\n\u001b[0;32m     60\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores hiperparmetros:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\optuna\\study\\study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     _optimize(\n\u001b[0;32m    443\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    444\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    445\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    446\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    447\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    448\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    449\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    450\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    451\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    452\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[13], line 53\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     49\u001b[0m init_mode_6 \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_mode_6\u001b[39m\u001b[38;5;124m'\u001b[39m, init_list)\n\u001b[0;32m     51\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(activation_1, activation_2, activation_3, activation_4, activation_5, activation_6,\n\u001b[0;32m     52\u001b[0m              init_mode_1, init_mode_2, init_mode_3, init_mode_4, init_mode_5, init_mode_6, regularizer_type)\n\u001b[1;32m---> 53\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train_enc, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,  validation_data \u001b[38;5;241m=\u001b[39m (x_test_enc, y_test), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Usa la prdida de validacin como mtrica para optimizar\u001b[39;00m\n\u001b[0;32m     56\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "# Define el modelo dentro de una funcin que tomar los hiperparmetros como argumentos\n",
    "def create_model(activation_1, activation_2, activation_3, activation_4, activation_5, activation_6, \n",
    "                 init_mode_1, init_mode_2, init_mode_3, init_mode_4, init_mode_5, init_mode_6, regularizer_type):\n",
    "    \n",
    "    if regularizer_type == \"l1\":\n",
    "        regularizer = keras.regularizers.l1(0.01)\n",
    "    elif regularizer_type == \"l2\":\n",
    "        regularizer = keras.regularizers.l2(0.01)\n",
    "    else:\n",
    "        regularizer = None\n",
    "        \n",
    "        \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(1024, input_shape=(x_train_enc.shape[1],), activation=activation_1, \n",
    "                           kernel_initializer=init_mode_1, kernel_regularizer=regularizer_type),\n",
    "        keras.layers.Dense(512, activation=activation_2, kernel_initializer=init_mode_2),\n",
    "        keras.layers.Dense(256, activation=activation_3, kernel_initializer=init_mode_3),\n",
    "        keras.layers.Dense(128, activation=activation_4, kernel_initializer=init_mode_4),\n",
    "        keras.layers.Dense(64, activation=activation_5, kernel_initializer=init_mode_5),\n",
    "        keras.layers.Dense(5, activation=activation_6, kernel_initializer=init_mode_6),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['Accuracy'])\n",
    "    return model\n",
    "\n",
    "# Funcin objetivo para Optuna\n",
    "def objective(trial):\n",
    "    \n",
    "    regularizer_type = trial.suggest_categorical('regularizer_type', [None, \"l1\", \"l2\"])\n",
    "    \n",
    "    activations_list = [\"elu\",\"exponential\",\"hard_sigmoid\",\"linear\", \"relu\",\"selu\",\"sigmoid\",\"softmax\",\"softplus\",\n",
    "                                                                                         \"softsign\",\"swish\",\"tanh\"]\n",
    "    activation_1 = trial.suggest_categorical('activation_1', activations_list)\n",
    "    activation_2 = trial.suggest_categorical('activation_2', activations_list)\n",
    "    activation_3 = trial.suggest_categorical('activation_3', activations_list)\n",
    "    activation_4 = trial.suggest_categorical('activation_4', activations_list)\n",
    "    activation_5 = trial.suggest_categorical('activation_5', activations_list)\n",
    "    activation_6 = trial.suggest_categorical('activation_6', activations_list)\n",
    "    \n",
    "    init_list = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "    init_mode_1 = trial.suggest_categorical('init_mode_1', init_list)\n",
    "    init_mode_2 = trial.suggest_categorical('init_mode_2', init_list)\n",
    "    init_mode_3 = trial.suggest_categorical('init_mode_3', init_list)\n",
    "    init_mode_4 = trial.suggest_categorical('init_mode_4', init_list)\n",
    "    init_mode_5 = trial.suggest_categorical('init_mode_5', init_list)\n",
    "    init_mode_6 = trial.suggest_categorical('init_mode_6', init_list)\n",
    "              \n",
    "    model = create_model(activation_1, activation_2, activation_3, activation_4, activation_5, activation_6,\n",
    "                 init_mode_1, init_mode_2, init_mode_3, init_mode_4, init_mode_5, init_mode_6, regularizer_type)\n",
    "    history = model.fit(x_train_enc, y_train, epochs=100,  validation_data = (x_test_enc, y_test), verbose=0)\n",
    "    \n",
    "    # Usa la prdida de validacin como mtrica para optimizar\n",
    "    val_loss = history.history['val_Accuracy'][-1]\n",
    "    return val_loss\n",
    "\n",
    "# Iniciar la optimizacin con Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Mejores hiperparmetros:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d31fcb1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 2s 127ms/step - loss: 1.5746 - Accuracy: 0.2991 - val_loss: 1.4029 - val_Accuracy: 0.4510\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.3577 - Accuracy: 0.4359 - val_loss: 1.2017 - val_Accuracy: 0.4314\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1600 - Accuracy: 0.5299 - val_loss: 1.2393 - val_Accuracy: 0.4706\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1337 - Accuracy: 0.5641 - val_loss: 1.3643 - val_Accuracy: 0.4314\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0771 - Accuracy: 0.5128 - val_loss: 1.2731 - val_Accuracy: 0.4510\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0359 - Accuracy: 0.5641 - val_loss: 1.2070 - val_Accuracy: 0.4706\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9795 - Accuracy: 0.6667 - val_loss: 1.1311 - val_Accuracy: 0.5294\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9142 - Accuracy: 0.6667 - val_loss: 1.1310 - val_Accuracy: 0.5294\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8599 - Accuracy: 0.6496 - val_loss: 1.2501 - val_Accuracy: 0.6078\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8816 - Accuracy: 0.6581 - val_loss: 2.3099 - val_Accuracy: 0.5490\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9027 - Accuracy: 0.6410 - val_loss: 1.5247 - val_Accuracy: 0.4510\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9557 - Accuracy: 0.5812 - val_loss: 1.7040 - val_Accuracy: 0.5686\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8889 - Accuracy: 0.6496 - val_loss: 1.3776 - val_Accuracy: 0.5490\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8257 - Accuracy: 0.7009 - val_loss: 1.3689 - val_Accuracy: 0.5294\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7995 - Accuracy: 0.6923 - val_loss: 1.8581 - val_Accuracy: 0.5882\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7806 - Accuracy: 0.6581 - val_loss: 1.5589 - val_Accuracy: 0.6078\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7907 - Accuracy: 0.7350 - val_loss: 2.1909 - val_Accuracy: 0.5686\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7839 - Accuracy: 0.7094 - val_loss: 1.8050 - val_Accuracy: 0.5882\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7533 - Accuracy: 0.7094 - val_loss: 2.0399 - val_Accuracy: 0.5882\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8656 - Accuracy: 0.6838 - val_loss: 2.0750 - val_Accuracy: 0.5294\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7379 - Accuracy: 0.7265 - val_loss: 2.0098 - val_Accuracy: 0.5490\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6840 - Accuracy: 0.7009 - val_loss: 2.3154 - val_Accuracy: 0.5490\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6711 - Accuracy: 0.7350 - val_loss: 2.5392 - val_Accuracy: 0.5686\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6252 - Accuracy: 0.7179 - val_loss: 2.3660 - val_Accuracy: 0.5294\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6095 - Accuracy: 0.7265 - val_loss: 2.7985 - val_Accuracy: 0.5490\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6086 - Accuracy: 0.7350 - val_loss: 2.3450 - val_Accuracy: 0.5294\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5513 - Accuracy: 0.7692 - val_loss: 2.8867 - val_Accuracy: 0.5490\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5414 - Accuracy: 0.7778 - val_loss: 3.6341 - val_Accuracy: 0.5294\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8056 - Accuracy: 0.7436 - val_loss: 2.9167 - val_Accuracy: 0.5294\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7575 - Accuracy: 0.7521 - val_loss: 3.3332 - val_Accuracy: 0.5098\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7845 - Accuracy: 0.7350 - val_loss: 2.6455 - val_Accuracy: 0.5490\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7241 - Accuracy: 0.7265 - val_loss: 2.9340 - val_Accuracy: 0.5098\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7102 - Accuracy: 0.7265 - val_loss: 2.9200 - val_Accuracy: 0.5490\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6945 - Accuracy: 0.7778 - val_loss: 2.8997 - val_Accuracy: 0.5294\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7087 - Accuracy: 0.7436 - val_loss: 3.3264 - val_Accuracy: 0.4902\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6491 - Accuracy: 0.7179 - val_loss: 2.4164 - val_Accuracy: 0.5686\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9885 - Accuracy: 0.7094 - val_loss: 2.8114 - val_Accuracy: 0.4706\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1762 - Accuracy: 0.7521 - val_loss: 2.8622 - val_Accuracy: 0.5490\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0951 - Accuracy: 0.7521 - val_loss: 3.3358 - val_Accuracy: 0.5294\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0812 - Accuracy: 0.7521 - val_loss: 4.1059 - val_Accuracy: 0.5294\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1471 - Accuracy: 0.7436 - val_loss: 4.1690 - val_Accuracy: 0.5490\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7706 - Accuracy: 0.7436 - val_loss: 3.3728 - val_Accuracy: 0.5882\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0101 - Accuracy: 0.6496 - val_loss: 2.4787 - val_Accuracy: 0.4118\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.2277 - Accuracy: 0.4359 - val_loss: 2.1997 - val_Accuracy: 0.4902\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3355 - Accuracy: 0.4701 - val_loss: 1.4067 - val_Accuracy: 0.4314\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.2812 - Accuracy: 0.4872 - val_loss: 1.5429 - val_Accuracy: 0.4902\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1343 - Accuracy: 0.5897 - val_loss: 1.1529 - val_Accuracy: 0.5490\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9447 - Accuracy: 0.6496 - val_loss: 1.4632 - val_Accuracy: 0.5490\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8936 - Accuracy: 0.6667 - val_loss: 1.4479 - val_Accuracy: 0.5686\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8324 - Accuracy: 0.6581 - val_loss: 1.8853 - val_Accuracy: 0.5490\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7512 - Accuracy: 0.7265 - val_loss: 2.3327 - val_Accuracy: 0.5490\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6921 - Accuracy: 0.7350 - val_loss: 2.5991 - val_Accuracy: 0.5294\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7728 - Accuracy: 0.7607 - val_loss: 2.9293 - val_Accuracy: 0.5294\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7430 - Accuracy: 0.7350 - val_loss: 2.5970 - val_Accuracy: 0.5294\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5919 - Accuracy: 0.7436 - val_loss: 2.5174 - val_Accuracy: 0.5686\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5921 - Accuracy: 0.7607 - val_loss: 2.5728 - val_Accuracy: 0.5686\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5732 - Accuracy: 0.7607 - val_loss: 2.5777 - val_Accuracy: 0.4902\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6224 - Accuracy: 0.7350 - val_loss: 2.5594 - val_Accuracy: 0.5294\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5960 - Accuracy: 0.7949 - val_loss: 2.4046 - val_Accuracy: 0.5686\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6038 - Accuracy: 0.7607 - val_loss: 2.4621 - val_Accuracy: 0.5490\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5726 - Accuracy: 0.7949 - val_loss: 3.2140 - val_Accuracy: 0.5882\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6985 - Accuracy: 0.8034 - val_loss: 3.4269 - val_Accuracy: 0.5882\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5475 - Accuracy: 0.7778 - val_loss: 3.0378 - val_Accuracy: 0.5490\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5535 - Accuracy: 0.7521 - val_loss: 2.8009 - val_Accuracy: 0.5098\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6638 - Accuracy: 0.7436 - val_loss: 2.7983 - val_Accuracy: 0.5490\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4774 - Accuracy: 0.7863 - val_loss: 3.3015 - val_Accuracy: 0.5490\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4955 - Accuracy: 0.7692 - val_loss: 3.3229 - val_Accuracy: 0.6078\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4636 - Accuracy: 0.8120 - val_loss: 3.1623 - val_Accuracy: 0.5294\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4671 - Accuracy: 0.8120 - val_loss: 3.3250 - val_Accuracy: 0.5490\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4429 - Accuracy: 0.7949 - val_loss: 3.3524 - val_Accuracy: 0.5294\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5341 - Accuracy: 0.8205 - val_loss: 3.9416 - val_Accuracy: 0.5490\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4368 - Accuracy: 0.8291 - val_loss: 3.3503 - val_Accuracy: 0.5686\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4881 - Accuracy: 0.7607 - val_loss: 3.3167 - val_Accuracy: 0.5882\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5160 - Accuracy: 0.7692 - val_loss: 3.3051 - val_Accuracy: 0.5686\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4968 - Accuracy: 0.7692 - val_loss: 3.3119 - val_Accuracy: 0.6078\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4981 - Accuracy: 0.7607 - val_loss: 3.5718 - val_Accuracy: 0.5882\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4601 - Accuracy: 0.8547 - val_loss: 3.5308 - val_Accuracy: 0.6078\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4343 - Accuracy: 0.8120 - val_loss: 3.5150 - val_Accuracy: 0.5882\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4072 - Accuracy: 0.8376 - val_loss: 3.3030 - val_Accuracy: 0.5882\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3907 - Accuracy: 0.8462 - val_loss: 3.5796 - val_Accuracy: 0.5294\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3634 - Accuracy: 0.8376 - val_loss: 4.0846 - val_Accuracy: 0.5490\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3575 - Accuracy: 0.8462 - val_loss: 4.3459 - val_Accuracy: 0.5490\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3200 - Accuracy: 0.8547 - val_loss: 4.7749 - val_Accuracy: 0.5686\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3370 - Accuracy: 0.8547 - val_loss: 4.8248 - val_Accuracy: 0.5098\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 4.6929 - Accuracy: 0.5641 - val_loss: 7.6040 - val_Accuracy: 0.4118\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.2809 - Accuracy: 0.4017 - val_loss: 6.7578 - val_Accuracy: 0.3922\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.4823 - Accuracy: 0.4701 - val_loss: 6.2271 - val_Accuracy: 0.4118\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 4.9168 - Accuracy: 0.5385 - val_loss: 4.0938 - val_Accuracy: 0.4510\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.8241 - Accuracy: 0.5726 - val_loss: 2.9318 - val_Accuracy: 0.4706\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.3090 - Accuracy: 0.6068 - val_loss: 3.1282 - val_Accuracy: 0.3725\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.9428 - Accuracy: 0.4701 - val_loss: 3.2759 - val_Accuracy: 0.3725\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.5820 - Accuracy: 0.4103 - val_loss: 3.3528 - val_Accuracy: 0.3333\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 2.7846 - Accuracy: 0.4359 - val_loss: 3.2636 - val_Accuracy: 0.4510\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.4568 - Accuracy: 0.4530 - val_loss: 3.1603 - val_Accuracy: 0.3529\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.0066 - Accuracy: 0.4530 - val_loss: 2.9828 - val_Accuracy: 0.3922\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2882 - Accuracy: 0.4615 - val_loss: 1.5781 - val_Accuracy: 0.3922\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1343 - Accuracy: 0.4188 - val_loss: 1.5002 - val_Accuracy: 0.3922\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1298 - Accuracy: 0.4017 - val_loss: 1.4922 - val_Accuracy: 0.3725\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1225 - Accuracy: 0.3932 - val_loss: 1.4940 - val_Accuracy: 0.3725\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0803 - Accuracy: 0.4017 - val_loss: 1.4686 - val_Accuracy: 0.3725\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0477 - Accuracy: 0.4017 - val_loss: 1.4322 - val_Accuracy: 0.3922\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0156 - Accuracy: 0.4701 - val_loss: 1.4466 - val_Accuracy: 0.3725\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9951 - Accuracy: 0.4872 - val_loss: 1.4507 - val_Accuracy: 0.3137\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9617 - Accuracy: 0.5043 - val_loss: 1.4292 - val_Accuracy: 0.3922\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9252 - Accuracy: 0.6154 - val_loss: 1.3928 - val_Accuracy: 0.4902\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9101 - Accuracy: 0.6239 - val_loss: 1.3729 - val_Accuracy: 0.4902\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9044 - Accuracy: 0.6581 - val_loss: 1.3664 - val_Accuracy: 0.5294\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8883 - Accuracy: 0.6581 - val_loss: 1.3549 - val_Accuracy: 0.5294\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8759 - Accuracy: 0.6496 - val_loss: 1.3448 - val_Accuracy: 0.5490\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8674 - Accuracy: 0.6239 - val_loss: 1.3346 - val_Accuracy: 0.5294\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8537 - Accuracy: 0.6667 - val_loss: 1.3317 - val_Accuracy: 0.5294\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8572 - Accuracy: 0.6154 - val_loss: 1.6456 - val_Accuracy: 0.5098\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8846 - Accuracy: 0.6154 - val_loss: 1.6110 - val_Accuracy: 0.4902\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8380 - Accuracy: 0.6581 - val_loss: 1.3964 - val_Accuracy: 0.4902\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8031 - Accuracy: 0.7009 - val_loss: 1.6506 - val_Accuracy: 0.5098\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7963 - Accuracy: 0.7009 - val_loss: 1.4420 - val_Accuracy: 0.5294\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7623 - Accuracy: 0.7521 - val_loss: 1.3893 - val_Accuracy: 0.5294\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7386 - Accuracy: 0.7265 - val_loss: 1.3687 - val_Accuracy: 0.5098\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7249 - Accuracy: 0.7094 - val_loss: 1.4134 - val_Accuracy: 0.5098\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7324 - Accuracy: 0.7094 - val_loss: 1.3627 - val_Accuracy: 0.5294\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7059 - Accuracy: 0.7179 - val_loss: 1.7028 - val_Accuracy: 0.4902\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6985 - Accuracy: 0.7179 - val_loss: 1.9056 - val_Accuracy: 0.5294\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6753 - Accuracy: 0.7094 - val_loss: 1.8625 - val_Accuracy: 0.5098\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6542 - Accuracy: 0.7521 - val_loss: 1.9068 - val_Accuracy: 0.5490\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6726 - Accuracy: 0.7265 - val_loss: 1.9503 - val_Accuracy: 0.5294\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6312 - Accuracy: 0.7179 - val_loss: 2.5748 - val_Accuracy: 0.5098\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6463 - Accuracy: 0.7009 - val_loss: 2.1119 - val_Accuracy: 0.5294\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6600 - Accuracy: 0.7350 - val_loss: 2.0987 - val_Accuracy: 0.5098\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6159 - Accuracy: 0.7265 - val_loss: 2.3291 - val_Accuracy: 0.5294\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6318 - Accuracy: 0.7179 - val_loss: 2.1096 - val_Accuracy: 0.5294\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6234 - Accuracy: 0.7436 - val_loss: 2.5937 - val_Accuracy: 0.5294\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6119 - Accuracy: 0.7436 - val_loss: 2.6282 - val_Accuracy: 0.5294\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5708 - Accuracy: 0.6923 - val_loss: 2.3560 - val_Accuracy: 0.5490\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5845 - Accuracy: 0.7350 - val_loss: 2.3349 - val_Accuracy: 0.5294\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5589 - Accuracy: 0.7692 - val_loss: 2.3835 - val_Accuracy: 0.5294\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5239 - Accuracy: 0.7692 - val_loss: 2.6761 - val_Accuracy: 0.5294\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5233 - Accuracy: 0.7350 - val_loss: 2.6507 - val_Accuracy: 0.5686\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5240 - Accuracy: 0.7778 - val_loss: 2.5069 - val_Accuracy: 0.5686\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5223 - Accuracy: 0.7436 - val_loss: 2.6410 - val_Accuracy: 0.5686\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5140 - Accuracy: 0.7521 - val_loss: 2.8657 - val_Accuracy: 0.5882\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4965 - Accuracy: 0.8034 - val_loss: 3.1294 - val_Accuracy: 0.5882\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5395 - Accuracy: 0.7778 - val_loss: 3.1555 - val_Accuracy: 0.5686\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5649 - Accuracy: 0.7436 - val_loss: 2.6465 - val_Accuracy: 0.5490\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5265 - Accuracy: 0.8120 - val_loss: 2.8601 - val_Accuracy: 0.5686\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5485 - Accuracy: 0.7778 - val_loss: 2.8112 - val_Accuracy: 0.5490\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5546 - Accuracy: 0.7949 - val_loss: 2.9132 - val_Accuracy: 0.5294\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5312 - Accuracy: 0.8034 - val_loss: 3.1536 - val_Accuracy: 0.5686\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4665 - Accuracy: 0.8205 - val_loss: 3.3769 - val_Accuracy: 0.5686\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5200 - Accuracy: 0.7692 - val_loss: 2.6205 - val_Accuracy: 0.5686\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4693 - Accuracy: 0.8034 - val_loss: 2.5987 - val_Accuracy: 0.5882\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4633 - Accuracy: 0.8376 - val_loss: 2.6046 - val_Accuracy: 0.5686\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4537 - Accuracy: 0.8547 - val_loss: 2.6239 - val_Accuracy: 0.5686\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5429 - Accuracy: 0.8462 - val_loss: 2.8489 - val_Accuracy: 0.5686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e3a9188090>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1024, input_shape=(x_train_enc.shape[1],), activation='elu', kernel_initializer='he_uniform'),\n",
    "    keras.layers.Dense(512, activation='swish', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(256, activation='relu', kernel_initializer='he_uniform'),\n",
    "    keras.layers.Dense(128, activation='swish', kernel_initializer='glorot_uniform'),\n",
    "    keras.layers.Dense(64, activation='sigmoid', kernel_initializer='normal'),\n",
    "    keras.layers.Dense(5, activation='hard_sigmoid', kernel_initializer='he_normal'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['Accuracy'])\n",
    "\n",
    "callback = EarlyStopping(monitor='val_Accuracy', patience=50, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train_enc, y_train, validation_data = (x_test_enc, y_test), epochs = 500, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba526d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 1.4507 - Accuracy: 0.3137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4506808519363403, 0.3137255012989044]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c01327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'Truth')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_enc)\n",
    "y_pred_labels = [np.argmax(i) for i in y_pred]\n",
    "cm = tf.math.confusion_matrix(labels=y_test, predictions=y_pred_labels)\n",
    "\n",
    "sns.heatmap(cm,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8420f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e637c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b9067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
