{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOnIQIsPUMfD",
    "outputId": "60b326c5-2a45-42b6-e6f2-fc3d5c4f4db8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A6ti0PesWLkM"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.read_csv(\"heart_failure_clinical_records_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ba3bCMhlWx1N",
    "outputId": "d65a53a0-5006-457e-e18d-9b36ed1bc892"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.833893</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>581.839465</td>\n",
       "      <td>0.418060</td>\n",
       "      <td>38.083612</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>263358.029264</td>\n",
       "      <td>1.39388</td>\n",
       "      <td>136.625418</td>\n",
       "      <td>0.648829</td>\n",
       "      <td>0.32107</td>\n",
       "      <td>130.260870</td>\n",
       "      <td>0.32107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.894809</td>\n",
       "      <td>0.496107</td>\n",
       "      <td>970.287881</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>11.834841</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>97804.236869</td>\n",
       "      <td>1.03451</td>\n",
       "      <td>4.412477</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.46767</td>\n",
       "      <td>77.614208</td>\n",
       "      <td>0.46767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25100.000000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212500.000000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262000.000000</td>\n",
       "      <td>1.10000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>303500.000000</td>\n",
       "      <td>1.40000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>850000.000000</td>\n",
       "      <td>9.40000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age     anaemia  creatinine_phosphokinase    diabetes  \\\n",
       "count  299.000000  299.000000                299.000000  299.000000   \n",
       "mean    60.833893    0.431438                581.839465    0.418060   \n",
       "std     11.894809    0.496107                970.287881    0.494067   \n",
       "min     40.000000    0.000000                 23.000000    0.000000   \n",
       "25%     51.000000    0.000000                116.500000    0.000000   \n",
       "50%     60.000000    0.000000                250.000000    0.000000   \n",
       "75%     70.000000    1.000000                582.000000    1.000000   \n",
       "max     95.000000    1.000000               7861.000000    1.000000   \n",
       "\n",
       "       ejection_fraction  high_blood_pressure      platelets  \\\n",
       "count         299.000000           299.000000     299.000000   \n",
       "mean           38.083612             0.351171  263358.029264   \n",
       "std            11.834841             0.478136   97804.236869   \n",
       "min            14.000000             0.000000   25100.000000   \n",
       "25%            30.000000             0.000000  212500.000000   \n",
       "50%            38.000000             0.000000  262000.000000   \n",
       "75%            45.000000             1.000000  303500.000000   \n",
       "max            80.000000             1.000000  850000.000000   \n",
       "\n",
       "       serum_creatinine  serum_sodium         sex    smoking        time  \\\n",
       "count         299.00000    299.000000  299.000000  299.00000  299.000000   \n",
       "mean            1.39388    136.625418    0.648829    0.32107  130.260870   \n",
       "std             1.03451      4.412477    0.478136    0.46767   77.614208   \n",
       "min             0.50000    113.000000    0.000000    0.00000    4.000000   \n",
       "25%             0.90000    134.000000    0.000000    0.00000   73.000000   \n",
       "50%             1.10000    137.000000    1.000000    0.00000  115.000000   \n",
       "75%             1.40000    140.000000    1.000000    1.00000  203.000000   \n",
       "max             9.40000    148.000000    1.000000    1.00000  285.000000   \n",
       "\n",
       "       DEATH_EVENT  \n",
       "count    299.00000  \n",
       "mean       0.32107  \n",
       "std        0.46767  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        1.00000  \n",
       "max        1.00000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGHvhQhCfNSu",
    "outputId": "b3b7f1f4-fd58-4d50-8b09-00c18ea23c37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "JDgIifMWXGQl",
    "outputId": "5c4e9e77-0ccf-400b-9b2d-e7be340cfd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de observaciones por clase\n",
      "DEATH_EVENT\n",
      "0    203\n",
      "1     96\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Cantidad de observaciones por clase')\n",
    "print(df['DEATH_EVENT'].value_counts())\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "data_x = df['DEATH_EVENT']\n",
    "\n",
    "# Create a list of colors for the boxplots based on the number of features you have\n",
    "boxplots_colors = ['blue', 'red']\n",
    "\n",
    "# Boxplot data\n",
    "bp = ax.boxplot(data_x, patch_artist = True, vert = False)\n",
    "\n",
    "# Change to the desired color and add transparency\n",
    "for patch, color in zip(bp['boxes'], boxplots_colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.4)\n",
    "\n",
    "# Create a list of colors for the violin plots based on the number of features you have\n",
    "violin_colors = ['black', 'black']\n",
    "\n",
    "# Violinplot data\n",
    "vp = ax.violinplot(data_x, points=500,\n",
    "               showmeans=False, showextrema=False, showmedians=False, vert=False)\n",
    "\n",
    "for idx, b in enumerate(vp['bodies']):\n",
    "    # Get the center of the plot\n",
    "    m = np.mean(b.get_paths()[0].vertices[:, 0])\n",
    "    # Modify it so we only see the upper half of the violin plot\n",
    "    b.get_paths()[0].vertices[:, 1] = np.clip(b.get_paths()[0].vertices[:, 1], idx+1, idx+2)\n",
    "    # Change to the desired color\n",
    "    b.set_color(violin_colors[idx])\n",
    "\n",
    "# Crear scatter plot horizontal\n",
    "scatter_data = data_x\n",
    "y = np.random.normal(1, 0.04, size=len(scatter_data)) - 0.1\n",
    "plt.scatter(scatter_data, y, alpha=0.6)\n",
    "\n",
    "# plt.yticks(np.arange(1,1,1), ['Feature 1', 'Feature 2'])  # Set text labels.\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Density')\n",
    "plt.title(\"Raincloud plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "as1c3nDGfoAS"
   },
   "outputs": [],
   "source": [
    "df = df.rename({'DEATH_EVENT':'label'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:12]\n",
    "Y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "x_sample, y_sample = oversample.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=x_sample, columns=['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
    "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
    "       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time'])\n",
    "df['label'] = y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    203\n",
       "0    203\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQsXmpq2dmN0",
    "outputId": "a0d2c1af-dcf0-4cc6-e376-96fec0f3db85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((272, 12), (134, 12))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.drop(['label'],axis=1),df['label'],test_size=0.33,random_state=0)\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    72\n",
       "0    62\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "fnl3GUzkhKR2"
   },
   "outputs": [],
   "source": [
    "norm = tf.keras.layers.Normalization(axis=-1)\n",
    "norm.adapt(x_train)\n",
    "x_train = pd.DataFrame(norm(x_train))\n",
    "# norm.adapt(x_test)\n",
    "x_test = pd.DataFrame(norm(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVwvzoOd5bvB",
    "outputId": "a337b3fa-1aa7-41c4-928c-1cf5b6ae89aa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-30 21:27:05,024] A new study created in memory with name: no-name-1e0b3029-a590-4c53-9388-64ff4c2c48cc\n",
      "[I 2024-01-30 21:27:15,557] Trial 0 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softmax', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'activation_5': 'softmax', 'activation_6': 'softsign', 'init_mode_1': 'he_uniform', 'init_mode_2': 'normal', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'zero', 'init_mode_6': 'glorot_normal'}. Best is trial 0 with value: 0.46268656849861145.\n",
      "[I 2024-01-30 21:27:32,265] Trial 1 finished with value: 0.8507462739944458 and parameters: {'regularizer_type': None, 'activation_1': 'softmax', 'activation_2': 'tanh', 'activation_3': 'softmax', 'activation_4': 'hard_sigmoid', 'activation_5': 'softplus', 'activation_6': 'swish', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:27:42,745] Trial 2 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'exponential', 'activation_2': 'sigmoid', 'activation_3': 'softmax', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'elu', 'init_mode_1': 'zero', 'init_mode_2': 'normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'uniform', 'init_mode_5': 'he_normal', 'init_mode_6': 'glorot_normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:27:52,971] Trial 3 finished with value: 0.8283582329750061 and parameters: {'regularizer_type': None, 'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'exponential', 'activation_4': 'softplus', 'activation_5': 'elu', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'he_normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:28:03,613] Trial 4 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softmax', 'activation_2': 'elu', 'activation_3': 'selu', 'activation_4': 'sigmoid', 'activation_5': 'softmax', 'activation_6': 'swish', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:28:15,414] Trial 5 finished with value: 0.8134328126907349 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'hard_sigmoid', 'activation_3': 'tanh', 'activation_4': 'hard_sigmoid', 'activation_5': 'softsign', 'activation_6': 'sigmoid', 'init_mode_1': 'he_uniform', 'init_mode_2': 'zero', 'init_mode_3': 'normal', 'init_mode_4': 'normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:28:26,888] Trial 6 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l2', 'activation_1': 'hard_sigmoid', 'activation_2': 'hard_sigmoid', 'activation_3': 'selu', 'activation_4': 'hard_sigmoid', 'activation_5': 'softsign', 'activation_6': 'swish', 'init_mode_1': 'uniform', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'zero', 'init_mode_6': 'normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:28:37,073] Trial 7 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'linear', 'activation_3': 'softplus', 'activation_4': 'softsign', 'activation_5': 'exponential', 'activation_6': 'relu', 'init_mode_1': 'zero', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'he_normal', 'init_mode_6': 'normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:28:48,255] Trial 8 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'elu', 'activation_4': 'softmax', 'activation_5': 'sigmoid', 'activation_6': 'softplus', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:28:57,986] Trial 9 finished with value: 0.5373134613037109 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'softsign', 'activation_3': 'softplus', 'activation_4': 'exponential', 'activation_5': 'selu', 'activation_6': 'softplus', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'he_normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:29:08,060] Trial 10 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'softmax', 'activation_4': 'swish', 'activation_5': 'softplus', 'activation_6': 'linear', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'zero', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:29:18,708] Trial 11 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'tanh', 'activation_2': 'softplus', 'activation_3': 'exponential', 'activation_4': 'softplus', 'activation_5': 'elu', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'he_normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:29:28,880] Trial 12 finished with value: 0.5373134613037109 and parameters: {'regularizer_type': None, 'activation_1': 'elu', 'activation_2': 'swish', 'activation_3': 'exponential', 'activation_4': 'softplus', 'activation_5': 'elu', 'activation_6': 'exponential', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'zero', 'init_mode_4': 'he_uniform', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'zero'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:29:39,698] Trial 13 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'tanh', 'activation_2': 'selu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'activation_5': 'softplus', 'activation_6': 'tanh', 'init_mode_1': 'normal', 'init_mode_2': 'he_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:29:51,817] Trial 14 finished with value: 0.8208954930305481 and parameters: {'regularizer_type': None, 'activation_1': 'softsign', 'activation_2': 'relu', 'activation_3': 'linear', 'activation_4': 'elu', 'activation_5': 'swish', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'uniform', 'init_mode_6': 'he_uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:30:04,514] Trial 15 finished with value: 0.8208954930305481 and parameters: {'regularizer_type': None, 'activation_1': 'selu', 'activation_2': 'softmax', 'activation_3': 'softsign', 'activation_4': 'linear', 'activation_5': 'hard_sigmoid', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'lecun_uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:30:14,894] Trial 16 finished with value: 0.5373134613037109 and parameters: {'regularizer_type': None, 'activation_1': 'softmax', 'activation_2': 'exponential', 'activation_3': 'hard_sigmoid', 'activation_4': 'selu', 'activation_5': 'relu', 'activation_6': 'softmax', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'uniform', 'init_mode_4': 'he_normal', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'he_normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:30:24,873] Trial 17 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'swish', 'activation_4': 'relu', 'activation_5': 'linear', 'activation_6': 'sigmoid', 'init_mode_1': 'uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'he_uniform', 'init_mode_4': 'zero', 'init_mode_5': 'normal', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:30:35,981] Trial 18 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l2', 'activation_1': 'selu', 'activation_2': 'tanh', 'activation_3': 'softmax', 'activation_4': 'hard_sigmoid', 'activation_5': 'tanh', 'activation_6': 'swish', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'uniform', 'init_mode_3': 'zero', 'init_mode_4': 'uniform', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'he_uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:30:46,213] Trial 19 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'sigmoid', 'activation_2': 'softsign', 'activation_3': 'exponential', 'activation_4': 'softplus', 'activation_5': 'softplus', 'activation_6': 'selu', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_uniform', 'init_mode_5': 'uniform', 'init_mode_6': 'lecun_uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:30:56,599] Trial 20 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'relu', 'activation_3': 'softsign', 'activation_4': 'swish', 'activation_5': 'elu', 'activation_6': 'elu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'zero'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:31:08,544] Trial 21 finished with value: 0.7611940503120422 and parameters: {'regularizer_type': None, 'activation_1': 'softsign', 'activation_2': 'relu', 'activation_3': 'linear', 'activation_4': 'elu', 'activation_5': 'swish', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'uniform', 'init_mode_6': 'he_uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:31:21,611] Trial 22 finished with value: 0.8283582329750061 and parameters: {'regularizer_type': None, 'activation_1': 'softsign', 'activation_2': 'relu', 'activation_3': 'linear', 'activation_4': 'elu', 'activation_5': 'swish', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'uniform', 'init_mode_6': 'he_uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:31:34,368] Trial 23 finished with value: 0.8358209133148193 and parameters: {'regularizer_type': None, 'activation_1': 'softsign', 'activation_2': 'elu', 'activation_3': 'linear', 'activation_4': 'elu', 'activation_5': 'swish', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:31:44,606] Trial 24 finished with value: 0.8059701323509216 and parameters: {'regularizer_type': None, 'activation_1': 'exponential', 'activation_2': 'elu', 'activation_3': 'sigmoid', 'activation_4': 'selu', 'activation_5': 'relu', 'activation_6': 'linear', 'init_mode_1': 'he_normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:31:56,985] Trial 25 finished with value: 0.8432835936546326 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'elu', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'tanh', 'activation_6': 'tanh', 'init_mode_1': 'he_normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:32:37,756] Trial 26 finished with value: 0.8358209133148193 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'elu', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'tanh', 'activation_6': 'tanh', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:32:49,573] Trial 27 finished with value: 0.8208954930305481 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'elu', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'tanh', 'activation_6': 'tanh', 'init_mode_1': 'he_normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:33:00,301] Trial 28 finished with value: 0.5373134613037109 and parameters: {'regularizer_type': 'l2', 'activation_1': 'linear', 'activation_2': 'elu', 'activation_3': 'hard_sigmoid', 'activation_4': 'relu', 'activation_5': 'hard_sigmoid', 'activation_6': 'softmax', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'he_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:33:10,811] Trial 29 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softmax', 'activation_2': 'exponential', 'activation_3': 'relu', 'activation_4': 'exponential', 'activation_5': 'exponential', 'activation_6': 'softsign', 'init_mode_1': 'he_uniform', 'init_mode_2': 'normal', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'zero', 'init_mode_6': 'glorot_normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:33:24,016] Trial 30 finished with value: 0.7313432693481445 and parameters: {'regularizer_type': 'l2', 'activation_1': 'elu', 'activation_2': 'selu', 'activation_3': 'tanh', 'activation_4': 'linear', 'activation_5': 'linear', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:33:44,256] Trial 31 finished with value: 0.8283582329750061 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'elu', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'tanh', 'activation_6': 'tanh', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:34:03,435] Trial 32 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'elu', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'tanh', 'activation_6': 'tanh', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:34:14,439] Trial 33 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'elu', 'activation_3': 'softmax', 'activation_4': 'tanh', 'activation_5': 'tanh', 'activation_6': 'tanh', 'init_mode_1': 'zero', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'uniform', 'init_mode_5': 'he_normal', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:34:26,063] Trial 34 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softmax', 'activation_2': 'swish', 'activation_3': 'swish', 'activation_4': 'sigmoid', 'activation_5': 'selu', 'activation_6': 'swish', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'normal', 'init_mode_3': 'uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'glorot_normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:34:37,243] Trial 35 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'relu', 'activation_2': 'softplus', 'activation_3': 'elu', 'activation_4': 'hard_sigmoid', 'activation_5': 'softmax', 'activation_6': 'relu', 'init_mode_1': 'he_uniform', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:34:48,318] Trial 36 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'hard_sigmoid', 'activation_2': 'linear', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'sigmoid', 'activation_6': 'tanh', 'init_mode_1': 'uniform', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:34:58,505] Trial 37 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softsign', 'activation_2': 'elu', 'activation_3': 'linear', 'activation_4': 'elu', 'activation_5': 'swish', 'activation_6': 'softsign', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'zero', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:35:12,427] Trial 38 finished with value: 0.8432835936546326 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'softmax', 'activation_3': 'selu', 'activation_4': 'softmax', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'zero', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:35:23,195] Trial 39 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'exponential', 'activation_2': 'softmax', 'activation_3': 'selu', 'activation_4': 'softmax', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'zero', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'zero'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:35:42,920] Trial 40 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softmax', 'activation_2': 'softmax', 'activation_3': 'selu', 'activation_4': 'softmax', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'zero', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'normal'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:35:53,235] Trial 41 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'tanh', 'activation_3': 'selu', 'activation_4': 'softmax', 'activation_5': 'softsign', 'activation_6': 'swish', 'init_mode_1': 'zero', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:36:04,079] Trial 42 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'hard_sigmoid', 'activation_3': 'softmax', 'activation_4': 'hard_sigmoid', 'activation_5': 'softplus', 'activation_6': 'elu', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'zero', 'init_mode_4': 'zero', 'init_mode_5': 'he_normal', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.8507462739944458.\n",
      "[I 2024-01-30 21:36:17,339] Trial 43 finished with value: 0.858208954334259 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'softmax', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'tanh', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:36:32,156] Trial 44 finished with value: 0.8507462739944458 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'softmax', 'activation_3': 'softplus', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:36:47,447] Trial 45 finished with value: 0.8432835936546326 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'softmax', 'activation_3': 'softplus', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:37:02,090] Trial 46 finished with value: 0.8208954930305481 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'softmax', 'activation_3': 'softplus', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:37:11,952] Trial 47 finished with value: 0.5373134613037109 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'softmax', 'activation_3': 'softplus', 'activation_4': 'sigmoid', 'activation_5': 'softplus', 'activation_6': 'softplus', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:37:22,547] Trial 48 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'hard_sigmoid', 'activation_2': 'softmax', 'activation_3': 'tanh', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'relu', 'init_mode_1': 'zero', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:37:32,499] Trial 49 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'tanh', 'activation_3': 'selu', 'activation_4': 'softsign', 'activation_5': 'exponential', 'activation_6': 'swish', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:37:45,559] Trial 50 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l2', 'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'softmax', 'activation_4': 'hard_sigmoid', 'activation_5': 'sigmoid', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'he_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'normal', 'init_mode_5': 'normal', 'init_mode_6': 'lecun_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:38:09,649] Trial 51 finished with value: 0.8059701323509216 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'softmax', 'activation_3': 'softplus', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:38:23,871] Trial 52 finished with value: 0.7835820913314819 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'softmax', 'activation_3': 'softplus', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:38:40,667] Trial 53 finished with value: 0.8358209133148193 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'softmax', 'activation_3': 'softplus', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:38:50,948] Trial 54 finished with value: 0.8432835936546326 and parameters: {'regularizer_type': None, 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'elu', 'activation_4': 'swish', 'activation_5': 'selu', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:39:00,805] Trial 55 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'selu', 'activation_2': 'softsign', 'activation_3': 'softplus', 'activation_4': 'tanh', 'activation_5': 'softsign', 'activation_6': 'selu', 'init_mode_1': 'uniform', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'uniform', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'he_normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:39:12,187] Trial 56 finished with value: 0.8432835936546326 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'linear', 'activation_3': 'softsign', 'activation_4': 'exponential', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:39:22,295] Trial 57 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softmax', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'selu', 'activation_5': 'tanh', 'activation_6': 'linear', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:39:32,837] Trial 58 finished with value: 0.5373134613037109 and parameters: {'regularizer_type': None, 'activation_1': 'elu', 'activation_2': 'hard_sigmoid', 'activation_3': 'swish', 'activation_4': 'softmax', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'zero', 'init_mode_5': 'normal', 'init_mode_6': 'glorot_normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:39:43,424] Trial 59 finished with value: 0.5373134613037109 and parameters: {'regularizer_type': None, 'activation_1': 'tanh', 'activation_2': 'softmax', 'activation_3': 'hard_sigmoid', 'activation_4': 'softplus', 'activation_5': 'hard_sigmoid', 'activation_6': 'softmax', 'init_mode_1': 'he_uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'zero'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:39:55,466] Trial 60 finished with value: 0.8507462739944458 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'softplus', 'activation_3': 'exponential', 'activation_4': 'relu', 'activation_5': 'linear', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'normal', 'init_mode_3': 'zero', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'zero', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:40:05,952] Trial 61 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'softplus', 'activation_3': 'exponential', 'activation_4': 'relu', 'activation_5': 'linear', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'normal', 'init_mode_3': 'zero', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'zero', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:40:16,006] Trial 62 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'softplus', 'activation_3': 'exponential', 'activation_4': 'relu', 'activation_5': 'linear', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'normal', 'init_mode_3': 'zero', 'init_mode_4': 'he_uniform', 'init_mode_5': 'zero', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:40:24,535] Trial 63 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'selu', 'activation_3': 'exponential', 'activation_4': 'relu', 'activation_5': 'linear', 'activation_6': 'softplus', 'init_mode_1': 'he_normal', 'init_mode_2': 'normal', 'init_mode_3': 'zero', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'zero', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:40:37,202] Trial 64 finished with value: 0.8432835936546326 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'softplus', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'elu', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'lecun_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:40:47,883] Trial 65 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'exponential', 'activation_3': 'softmax', 'activation_4': 'linear', 'activation_5': 'tanh', 'activation_6': 'elu', 'init_mode_1': 'zero', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'zero', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'zero', 'init_mode_6': 'he_normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:41:06,062] Trial 66 finished with value: 0.8283582329750061 and parameters: {'regularizer_type': None, 'activation_1': 'exponential', 'activation_2': 'softmax', 'activation_3': 'softplus', 'activation_4': 'hard_sigmoid', 'activation_5': 'softmax', 'activation_6': 'swish', 'init_mode_1': 'he_normal', 'init_mode_2': 'normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'normal', 'init_mode_5': 'he_normal', 'init_mode_6': 'he_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:41:16,817] Trial 67 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l2', 'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:41:26,807] Trial 68 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'activation_5': 'tanh', 'activation_6': 'softsign', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'normal', 'init_mode_4': 'uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:41:37,456] Trial 69 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softplus', 'activation_2': 'softsign', 'activation_3': 'exponential', 'activation_4': 'swish', 'activation_5': 'linear', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'uniform', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'uniform', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:41:47,707] Trial 70 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softmax', 'activation_2': 'softplus', 'activation_3': 'selu', 'activation_4': 'softmax', 'activation_5': 'exponential', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'he_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:42:00,448] Trial 71 finished with value: 0.8208954930305481 and parameters: {'regularizer_type': None, 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'elu', 'activation_4': 'swish', 'activation_5': 'selu', 'activation_6': 'swish', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:42:10,690] Trial 72 finished with value: 0.8059701323509216 and parameters: {'regularizer_type': None, 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'elu', 'activation_4': 'swish', 'activation_5': 'selu', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:42:21,525] Trial 73 finished with value: 0.8507462739944458 and parameters: {'regularizer_type': None, 'activation_1': 'relu', 'activation_2': 'swish', 'activation_3': 'elu', 'activation_4': 'swish', 'activation_5': 'softplus', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:42:32,159] Trial 74 finished with value: 0.7985074520111084 and parameters: {'regularizer_type': None, 'activation_1': 'selu', 'activation_2': 'swish', 'activation_3': 'elu', 'activation_4': 'tanh', 'activation_5': 'softplus', 'activation_6': 'sigmoid', 'init_mode_1': 'normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:42:43,319] Trial 75 finished with value: 0.8208954930305481 and parameters: {'regularizer_type': None, 'activation_1': 'relu', 'activation_2': 'swish', 'activation_3': 'tanh', 'activation_4': 'exponential', 'activation_5': 'softplus', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:42:54,066] Trial 76 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'swish', 'activation_3': 'softsign', 'activation_4': 'sigmoid', 'activation_5': 'softplus', 'activation_6': 'relu', 'init_mode_1': 'he_normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'zero', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'zero'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:43:05,021] Trial 77 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'swish', 'activation_3': 'sigmoid', 'activation_4': 'hard_sigmoid', 'activation_5': 'tanh', 'activation_6': 'linear', 'init_mode_1': 'zero', 'init_mode_2': 'normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'glorot_normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:43:15,749] Trial 78 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'hard_sigmoid', 'activation_2': 'relu', 'activation_3': 'swish', 'activation_4': 'selu', 'activation_5': 'softmax', 'activation_6': 'tanh', 'init_mode_1': 'he_uniform', 'init_mode_2': 'uniform', 'init_mode_3': 'zero', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'zero', 'init_mode_6': 'uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:43:27,337] Trial 79 finished with value: 0.746268630027771 and parameters: {'regularizer_type': None, 'activation_1': 'tanh', 'activation_2': 'selu', 'activation_3': 'softmax', 'activation_4': 'linear', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:43:42,200] Trial 80 finished with value: 0.8134328126907349 and parameters: {'regularizer_type': 'l2', 'activation_1': 'elu', 'activation_2': 'linear', 'activation_3': 'hard_sigmoid', 'activation_4': 'softsign', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:43:52,417] Trial 81 finished with value: 0.7910447716712952 and parameters: {'regularizer_type': None, 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'elu', 'activation_4': 'swish', 'activation_5': 'selu', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:44:02,804] Trial 82 finished with value: 0.7910447716712952 and parameters: {'regularizer_type': None, 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'elu', 'activation_4': 'swish', 'activation_5': 'selu', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:44:13,617] Trial 83 finished with value: 0.8283582329750061 and parameters: {'regularizer_type': None, 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'elu', 'activation_4': 'swish', 'activation_5': 'sigmoid', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:44:24,135] Trial 84 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'exponential', 'activation_3': 'softplus', 'activation_4': 'softmax', 'activation_5': 'hard_sigmoid', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:44:34,147] Trial 85 finished with value: 0.5373134613037109 and parameters: {'regularizer_type': None, 'activation_1': 'softmax', 'activation_2': 'softmax', 'activation_3': 'selu', 'activation_4': 'swish', 'activation_5': 'elu', 'activation_6': 'softmax', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'lecun_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:44:44,428] Trial 86 finished with value: 0.8059701323509216 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'tanh', 'activation_3': 'elu', 'activation_4': 'softplus', 'activation_5': 'softsign', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:44:55,733] Trial 87 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l1', 'activation_1': 'relu', 'activation_2': 'hard_sigmoid', 'activation_3': 'softmax', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'tanh', 'init_mode_1': 'zero', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'he_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:45:16,422] Trial 88 finished with value: 0.8134328126907349 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'softmax', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'tanh', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:45:27,648] Trial 89 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softsign', 'activation_2': 'elu', 'activation_3': 'softplus', 'activation_4': 'hard_sigmoid', 'activation_5': 'softplus', 'activation_6': 'swish', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:45:38,455] Trial 90 finished with value: 0.5373134613037109 and parameters: {'regularizer_type': None, 'activation_1': 'exponential', 'activation_2': 'softplus', 'activation_3': 'exponential', 'activation_4': 'relu', 'activation_5': 'swish', 'activation_6': 'softplus', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'he_normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:45:56,384] Trial 91 finished with value: 0.7835820913314819 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'linear', 'activation_3': 'softsign', 'activation_4': 'exponential', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:46:08,196] Trial 92 finished with value: 0.6940298676490784 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'linear', 'activation_3': 'softsign', 'activation_4': 'exponential', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:46:19,397] Trial 93 finished with value: 0.8358209133148193 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'linear', 'activation_3': 'softsign', 'activation_4': 'elu', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'uniform', 'init_mode_4': 'normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:46:35,796] Trial 94 finished with value: 0.7985074520111084 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'softmax', 'activation_3': 'linear', 'activation_4': 'exponential', 'activation_5': 'linear', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:46:51,009] Trial 95 finished with value: 0.7910447716712952 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'linear', 'activation_3': 'softsign', 'activation_4': 'softmax', 'activation_5': 'softplus', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'normal', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:47:00,708] Trial 96 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'linear', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'exponential', 'activation_5': 'selu', 'activation_6': 'elu', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'zero', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'zero', 'init_mode_6': 'uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:47:11,044] Trial 97 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': None, 'activation_1': 'softmax', 'activation_2': 'tanh', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'softmax', 'activation_6': 'softsign', 'init_mode_1': 'uniform', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'normal'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:47:23,738] Trial 98 finished with value: 0.8358209133148193 and parameters: {'regularizer_type': None, 'activation_1': 'sigmoid', 'activation_2': 'softmax', 'activation_3': 'selu', 'activation_4': 'swish', 'activation_5': 'softplus', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 43 with value: 0.858208954334259.\n",
      "[I 2024-01-30 21:47:34,377] Trial 99 finished with value: 0.46268656849861145 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softplus', 'activation_2': 'softsign', 'activation_3': 'softplus', 'activation_4': 'softmax', 'activation_5': 'tanh', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'zero', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'he_uniform', 'init_mode_4': 'he_uniform', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_normal'}. Best is trial 43 with value: 0.858208954334259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparmetros: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'softmax', 'activation_3': 'swish', 'activation_4': 'tanh', 'activation_5': 'tanh', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}\n",
      "Elapsed time: 20.49 min.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "# Define el modelo dentro de una funcin que tomar los hiperparmetros como argumentos\n",
    "def create_model(activation_1, activation_2, activation_3, activation_4, activation_5, activation_6,\n",
    "                 init_mode_1, init_mode_2, init_mode_3, init_mode_4, init_mode_5, init_mode_6, regularizer_type):\n",
    "\n",
    "    if regularizer_type == \"l1\":\n",
    "        regularizer = keras.regularizers.l1(0.01)\n",
    "    elif regularizer_type == \"l2\":\n",
    "        regularizer = keras.regularizers.l2(0.01)\n",
    "    else:\n",
    "        regularizer = None\n",
    "\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(1024, input_shape=(x_train.shape[1],), activation=activation_1,\n",
    "                           kernel_initializer=init_mode_1, kernel_regularizer=regularizer_type),\n",
    "        keras.layers.Dense(512, activation=activation_2, kernel_initializer=init_mode_2),\n",
    "        keras.layers.Dense(256, activation=activation_3, kernel_initializer=init_mode_3),\n",
    "        keras.layers.Dense(128, activation=activation_4, kernel_initializer=init_mode_4),\n",
    "        keras.layers.Dense(64, activation=activation_5, kernel_initializer=init_mode_5),\n",
    "        keras.layers.Dense(1, activation=activation_6, kernel_initializer=init_mode_6),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "    return model\n",
    "\n",
    "# Funcin objetivo para Optuna\n",
    "def objective(trial):\n",
    "\n",
    "    regularizer_type = trial.suggest_categorical('regularizer_type', [None, \"l1\", \"l2\"])\n",
    "\n",
    "    activations_list = [\"elu\",\"exponential\",\"hard_sigmoid\",\"linear\", \"relu\",\"selu\",\"sigmoid\",\"softmax\",\"softplus\",\n",
    "                                                                                         \"softsign\",\"swish\",\"tanh\"]\n",
    "    activation_1 = trial.suggest_categorical('activation_1', activations_list)\n",
    "    activation_2 = trial.suggest_categorical('activation_2', activations_list)\n",
    "    activation_3 = trial.suggest_categorical('activation_3', activations_list)\n",
    "    activation_4 = trial.suggest_categorical('activation_4', activations_list)\n",
    "    activation_5 = trial.suggest_categorical('activation_5', activations_list)\n",
    "    activation_6 = trial.suggest_categorical('activation_6', activations_list)\n",
    "\n",
    "    init_list = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "    init_mode_1 = trial.suggest_categorical('init_mode_1', init_list)\n",
    "    init_mode_2 = trial.suggest_categorical('init_mode_2', init_list)\n",
    "    init_mode_3 = trial.suggest_categorical('init_mode_3', init_list)\n",
    "    init_mode_4 = trial.suggest_categorical('init_mode_4', init_list)\n",
    "    init_mode_5 = trial.suggest_categorical('init_mode_5', init_list)\n",
    "    init_mode_6 = trial.suggest_categorical('init_mode_6', init_list)\n",
    "\n",
    "    model = create_model(activation_1, activation_2, activation_3, activation_4, activation_5, activation_6,\n",
    "                 init_mode_1, init_mode_2, init_mode_3, init_mode_4, init_mode_5, init_mode_6, regularizer_type)\n",
    "    EarlyStop = tf.keras.callbacks.EarlyStopping(monitor = 'val_binary_accuracy', patience = 100, mode = 'max', restore_best_weights = True)\n",
    "    history = model.fit(x_train, y_train, epochs=1000, validation_data=(x_test, y_test), verbose=0, callbacks=EarlyStop)\n",
    "\n",
    "    # Usa la prdida de validacin como mtrica para optimizar\n",
    "    val_loss = history.history['val_binary_accuracy'][-1]\n",
    "    return val_loss\n",
    "start=perf_counter()\n",
    "# Iniciar la optimizacin con Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Mejores hiperparmetros:\", study.best_params)\n",
    "tl=(perf_counter()-start)/60\n",
    "print ('Elapsed time: %.2f min.' %tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regularizer_type': None,\n",
       " 'activation_1': 'softplus',\n",
       " 'activation_2': 'softmax',\n",
       " 'activation_3': 'swish',\n",
       " 'activation_4': 'tanh',\n",
       " 'activation_5': 'tanh',\n",
       " 'activation_6': 'hard_sigmoid',\n",
       " 'init_mode_1': 'he_normal',\n",
       " 'init_mode_2': 'zero',\n",
       " 'init_mode_3': 'glorot_uniform',\n",
       " 'init_mode_4': 'glorot_normal',\n",
       " 'init_mode_5': 'glorot_normal',\n",
       " 'init_mode_6': 'glorot_uniform'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc = study.best_params\n",
    "dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pp1c3jQpnt6D",
    "outputId": "315407ef-522e-40e8-ffd8-a8ba79fb8a3d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 1s 30ms/step - loss: 0.6729 - binary_accuracy: 0.6801 - val_loss: 0.6152 - val_binary_accuracy: 0.8060\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.5054 - binary_accuracy: 0.8676 - val_loss: 0.3819 - val_binary_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4824 - binary_accuracy: 0.8603 - val_loss: 0.5051 - val_binary_accuracy: 0.8507\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.4099 - binary_accuracy: 0.8713 - val_loss: 0.4112 - val_binary_accuracy: 0.8433\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3330 - binary_accuracy: 0.8750 - val_loss: 0.4129 - val_binary_accuracy: 0.8060\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3457 - binary_accuracy: 0.8529 - val_loss: 0.4316 - val_binary_accuracy: 0.8060\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3383 - binary_accuracy: 0.8529 - val_loss: 0.4046 - val_binary_accuracy: 0.8284\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3538 - binary_accuracy: 0.8750 - val_loss: 0.5164 - val_binary_accuracy: 0.8284\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3472 - binary_accuracy: 0.8640 - val_loss: 0.4817 - val_binary_accuracy: 0.8358\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3242 - binary_accuracy: 0.8676 - val_loss: 0.6877 - val_binary_accuracy: 0.8060\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3327 - binary_accuracy: 0.8603 - val_loss: 0.6047 - val_binary_accuracy: 0.8582\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3487 - binary_accuracy: 0.8750 - val_loss: 0.7170 - val_binary_accuracy: 0.8209\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2902 - binary_accuracy: 0.8971 - val_loss: 0.6694 - val_binary_accuracy: 0.8582\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3420 - binary_accuracy: 0.8897 - val_loss: 0.7086 - val_binary_accuracy: 0.8134\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2711 - binary_accuracy: 0.9007 - val_loss: 1.0260 - val_binary_accuracy: 0.7761\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6486 - binary_accuracy: 0.8382 - val_loss: 0.7550 - val_binary_accuracy: 0.8582\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2706 - binary_accuracy: 0.9081 - val_loss: 0.5915 - val_binary_accuracy: 0.8433\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3049 - binary_accuracy: 0.8934 - val_loss: 0.3941 - val_binary_accuracy: 0.8507\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2798 - binary_accuracy: 0.8897 - val_loss: 0.4520 - val_binary_accuracy: 0.7836\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2623 - binary_accuracy: 0.8787 - val_loss: 0.4191 - val_binary_accuracy: 0.8209\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2642 - binary_accuracy: 0.8971 - val_loss: 0.5777 - val_binary_accuracy: 0.8284\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3353 - binary_accuracy: 0.9081 - val_loss: 1.2334 - val_binary_accuracy: 0.8806\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4368 - binary_accuracy: 0.9081 - val_loss: 1.0206 - val_binary_accuracy: 0.8284\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3645 - binary_accuracy: 0.9007 - val_loss: 0.8549 - val_binary_accuracy: 0.8060\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3166 - binary_accuracy: 0.8897 - val_loss: 0.8442 - val_binary_accuracy: 0.8433\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2383 - binary_accuracy: 0.9118 - val_loss: 0.8699 - val_binary_accuracy: 0.8433\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2237 - binary_accuracy: 0.9191 - val_loss: 0.9601 - val_binary_accuracy: 0.8209\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2088 - binary_accuracy: 0.9191 - val_loss: 1.0943 - val_binary_accuracy: 0.8433\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2087 - binary_accuracy: 0.9228 - val_loss: 0.9686 - val_binary_accuracy: 0.8134\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2022 - binary_accuracy: 0.9228 - val_loss: 1.0649 - val_binary_accuracy: 0.8358\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1822 - binary_accuracy: 0.9265 - val_loss: 1.1702 - val_binary_accuracy: 0.8209\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1924 - binary_accuracy: 0.9191 - val_loss: 1.4087 - val_binary_accuracy: 0.8209\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1760 - binary_accuracy: 0.9375 - val_loss: 1.4338 - val_binary_accuracy: 0.8284\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1781 - binary_accuracy: 0.9265 - val_loss: 1.2151 - val_binary_accuracy: 0.8209\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1903 - binary_accuracy: 0.9301 - val_loss: 1.1420 - val_binary_accuracy: 0.8582\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2235 - binary_accuracy: 0.9265 - val_loss: 1.5190 - val_binary_accuracy: 0.8433\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5964 - binary_accuracy: 0.8934 - val_loss: 1.6075 - val_binary_accuracy: 0.8060\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6018 - binary_accuracy: 0.8419 - val_loss: 1.1523 - val_binary_accuracy: 0.7910\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5108 - binary_accuracy: 0.8860 - val_loss: 0.9872 - val_binary_accuracy: 0.8433\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2921 - binary_accuracy: 0.9118 - val_loss: 1.4084 - val_binary_accuracy: 0.8433\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2955 - binary_accuracy: 0.9007 - val_loss: 0.9224 - val_binary_accuracy: 0.8209\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2163 - binary_accuracy: 0.9191 - val_loss: 1.4000 - val_binary_accuracy: 0.8507\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2554 - binary_accuracy: 0.9154 - val_loss: 1.0517 - val_binary_accuracy: 0.8507\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2954 - binary_accuracy: 0.8824 - val_loss: 1.0600 - val_binary_accuracy: 0.8582\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2237 - binary_accuracy: 0.9007 - val_loss: 1.4175 - val_binary_accuracy: 0.8284\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1961 - binary_accuracy: 0.9154 - val_loss: 1.3446 - val_binary_accuracy: 0.8284\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2411 - binary_accuracy: 0.9228 - val_loss: 1.3305 - val_binary_accuracy: 0.8358\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1982 - binary_accuracy: 0.9044 - val_loss: 1.3439 - val_binary_accuracy: 0.8134\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1836 - binary_accuracy: 0.9412 - val_loss: 1.5495 - val_binary_accuracy: 0.8284\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1986 - binary_accuracy: 0.9265 - val_loss: 1.7514 - val_binary_accuracy: 0.8134\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2837 - binary_accuracy: 0.9081 - val_loss: 1.2517 - val_binary_accuracy: 0.8507\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2448 - binary_accuracy: 0.9154 - val_loss: 1.5971 - val_binary_accuracy: 0.8582\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2209 - binary_accuracy: 0.9265 - val_loss: 1.2136 - val_binary_accuracy: 0.8582\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1699 - binary_accuracy: 0.9265 - val_loss: 1.4269 - val_binary_accuracy: 0.8284\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2096 - binary_accuracy: 0.9265 - val_loss: 1.6401 - val_binary_accuracy: 0.8284\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1874 - binary_accuracy: 0.9228 - val_loss: 0.8699 - val_binary_accuracy: 0.7761\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2744 - binary_accuracy: 0.8934 - val_loss: 1.2865 - val_binary_accuracy: 0.8657\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2083 - binary_accuracy: 0.9228 - val_loss: 0.8800 - val_binary_accuracy: 0.7463\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3104 - binary_accuracy: 0.8382 - val_loss: 0.9821 - val_binary_accuracy: 0.7687\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4800 - binary_accuracy: 0.8382 - val_loss: 0.4838 - val_binary_accuracy: 0.8060\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3004 - binary_accuracy: 0.8934 - val_loss: 1.1987 - val_binary_accuracy: 0.7910\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4223 - binary_accuracy: 0.8897 - val_loss: 0.4789 - val_binary_accuracy: 0.8284\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3003 - binary_accuracy: 0.8824 - val_loss: 0.6907 - val_binary_accuracy: 0.8284\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2790 - binary_accuracy: 0.9154 - val_loss: 0.5637 - val_binary_accuracy: 0.8507\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2199 - binary_accuracy: 0.9191 - val_loss: 1.0900 - val_binary_accuracy: 0.8582\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2545 - binary_accuracy: 0.9265 - val_loss: 1.1009 - val_binary_accuracy: 0.8582\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1883 - binary_accuracy: 0.9265 - val_loss: 1.0888 - val_binary_accuracy: 0.8582\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1744 - binary_accuracy: 0.9338 - val_loss: 0.9097 - val_binary_accuracy: 0.8507\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1674 - binary_accuracy: 0.9485 - val_loss: 1.1154 - val_binary_accuracy: 0.8433\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1587 - binary_accuracy: 0.9485 - val_loss: 1.0438 - val_binary_accuracy: 0.8433\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1509 - binary_accuracy: 0.9522 - val_loss: 1.3106 - val_binary_accuracy: 0.8582\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1473 - binary_accuracy: 0.9522 - val_loss: 1.3177 - val_binary_accuracy: 0.8433\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1438 - binary_accuracy: 0.9522 - val_loss: 1.4053 - val_binary_accuracy: 0.8358\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1407 - binary_accuracy: 0.9632 - val_loss: 1.3192 - val_binary_accuracy: 0.8209\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1416 - binary_accuracy: 0.9596 - val_loss: 1.3074 - val_binary_accuracy: 0.8358\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1334 - binary_accuracy: 0.9559 - val_loss: 1.3844 - val_binary_accuracy: 0.8433\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1359 - binary_accuracy: 0.9522 - val_loss: 1.3983 - val_binary_accuracy: 0.8433\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1334 - binary_accuracy: 0.9596 - val_loss: 1.2272 - val_binary_accuracy: 0.8358\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1318 - binary_accuracy: 0.9559 - val_loss: 1.4015 - val_binary_accuracy: 0.8284\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1270 - binary_accuracy: 0.9559 - val_loss: 1.3065 - val_binary_accuracy: 0.8358\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1260 - binary_accuracy: 0.9596 - val_loss: 1.4368 - val_binary_accuracy: 0.8433\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1243 - binary_accuracy: 0.9596 - val_loss: 1.4198 - val_binary_accuracy: 0.8358\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1297 - binary_accuracy: 0.9449 - val_loss: 1.1906 - val_binary_accuracy: 0.8284\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1279 - binary_accuracy: 0.9632 - val_loss: 1.5099 - val_binary_accuracy: 0.8358\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1249 - binary_accuracy: 0.9485 - val_loss: 1.2747 - val_binary_accuracy: 0.8582\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1236 - binary_accuracy: 0.9596 - val_loss: 1.5137 - val_binary_accuracy: 0.8358\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1231 - binary_accuracy: 0.9559 - val_loss: 1.3939 - val_binary_accuracy: 0.8358\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1194 - binary_accuracy: 0.9632 - val_loss: 1.6058 - val_binary_accuracy: 0.8433\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1248 - binary_accuracy: 0.9522 - val_loss: 1.1922 - val_binary_accuracy: 0.8358\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1228 - binary_accuracy: 0.9596 - val_loss: 1.7042 - val_binary_accuracy: 0.8358\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1228 - binary_accuracy: 0.9559 - val_loss: 1.3804 - val_binary_accuracy: 0.8358\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1250 - binary_accuracy: 0.9596 - val_loss: 1.6001 - val_binary_accuracy: 0.8284\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1324 - binary_accuracy: 0.9485 - val_loss: 1.3878 - val_binary_accuracy: 0.8209\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1477 - binary_accuracy: 0.9485 - val_loss: 1.8416 - val_binary_accuracy: 0.8358\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4120 - binary_accuracy: 0.9154 - val_loss: 2.6335 - val_binary_accuracy: 0.8060\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6639 - binary_accuracy: 0.9118 - val_loss: 1.4365 - val_binary_accuracy: 0.7985\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3076 - binary_accuracy: 0.9044 - val_loss: 1.3496 - val_binary_accuracy: 0.8134\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2275 - binary_accuracy: 0.9228 - val_loss: 1.6049 - val_binary_accuracy: 0.8433\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5148 - binary_accuracy: 0.9191 - val_loss: 1.8398 - val_binary_accuracy: 0.8134\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5695 - binary_accuracy: 0.9301 - val_loss: 1.4210 - val_binary_accuracy: 0.8284\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2751 - binary_accuracy: 0.9154 - val_loss: 0.9310 - val_binary_accuracy: 0.6866\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4138 - binary_accuracy: 0.8346 - val_loss: 0.7756 - val_binary_accuracy: 0.8060\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5624 - binary_accuracy: 0.8419 - val_loss: 0.6343 - val_binary_accuracy: 0.6567\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5675 - binary_accuracy: 0.7426 - val_loss: 0.6220 - val_binary_accuracy: 0.6940\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5382 - binary_accuracy: 0.7868 - val_loss: 0.5763 - val_binary_accuracy: 0.7090\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4090 - binary_accuracy: 0.8199 - val_loss: 0.9672 - val_binary_accuracy: 0.7164\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3278 - binary_accuracy: 0.8640 - val_loss: 1.4181 - val_binary_accuracy: 0.7761\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2817 - binary_accuracy: 0.9118 - val_loss: 1.6070 - val_binary_accuracy: 0.7836\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2643 - binary_accuracy: 0.9191 - val_loss: 1.5617 - val_binary_accuracy: 0.8060\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2591 - binary_accuracy: 0.9228 - val_loss: 1.5409 - val_binary_accuracy: 0.8134\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2915 - binary_accuracy: 0.9338 - val_loss: 1.6807 - val_binary_accuracy: 0.7985\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2440 - binary_accuracy: 0.9338 - val_loss: 1.5512 - val_binary_accuracy: 0.8060\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2241 - binary_accuracy: 0.9449 - val_loss: 1.6448 - val_binary_accuracy: 0.7985\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2165 - binary_accuracy: 0.9375 - val_loss: 1.6404 - val_binary_accuracy: 0.8134\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2126 - binary_accuracy: 0.9522 - val_loss: 1.5639 - val_binary_accuracy: 0.8134\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2082 - binary_accuracy: 0.9412 - val_loss: 1.6364 - val_binary_accuracy: 0.8060\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1997 - binary_accuracy: 0.9596 - val_loss: 1.6501 - val_binary_accuracy: 0.8284\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1983 - binary_accuracy: 0.9522 - val_loss: 1.6487 - val_binary_accuracy: 0.8060\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1876 - binary_accuracy: 0.9522 - val_loss: 1.7654 - val_binary_accuracy: 0.8060\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1898 - binary_accuracy: 0.9485 - val_loss: 1.8334 - val_binary_accuracy: 0.8209\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1859 - binary_accuracy: 0.9559 - val_loss: 1.6444 - val_binary_accuracy: 0.8209\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1822 - binary_accuracy: 0.9596 - val_loss: 1.7356 - val_binary_accuracy: 0.8060\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1816 - binary_accuracy: 0.9632 - val_loss: 1.8451 - val_binary_accuracy: 0.8060\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1791 - binary_accuracy: 0.9596 - val_loss: 1.8168 - val_binary_accuracy: 0.8209\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1774 - binary_accuracy: 0.9632 - val_loss: 1.9512 - val_binary_accuracy: 0.8060\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1746 - binary_accuracy: 0.9632 - val_loss: 1.8398 - val_binary_accuracy: 0.8134\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1737 - binary_accuracy: 0.9596 - val_loss: 1.8306 - val_binary_accuracy: 0.8209\n",
      "Epoch 128/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1746 - binary_accuracy: 0.9632 - val_loss: 1.8318 - val_binary_accuracy: 0.8060\n",
      "Epoch 129/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1710 - binary_accuracy: 0.9632 - val_loss: 1.8213 - val_binary_accuracy: 0.8134\n",
      "Epoch 130/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1714 - binary_accuracy: 0.9632 - val_loss: 1.8336 - val_binary_accuracy: 0.8060\n",
      "Epoch 131/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1685 - binary_accuracy: 0.9632 - val_loss: 1.9225 - val_binary_accuracy: 0.8134\n",
      "Epoch 132/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1683 - binary_accuracy: 0.9596 - val_loss: 1.9212 - val_binary_accuracy: 0.8134\n",
      "Epoch 133/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1697 - binary_accuracy: 0.9559 - val_loss: 1.9039 - val_binary_accuracy: 0.8358\n",
      "Epoch 134/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2290 - binary_accuracy: 0.9522 - val_loss: 1.8170 - val_binary_accuracy: 0.8134\n",
      "Epoch 135/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1673 - binary_accuracy: 0.9632 - val_loss: 1.9257 - val_binary_accuracy: 0.8209\n",
      "Epoch 136/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1728 - binary_accuracy: 0.9596 - val_loss: 1.9298 - val_binary_accuracy: 0.8060\n",
      "Epoch 137/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1709 - binary_accuracy: 0.9596 - val_loss: 1.9163 - val_binary_accuracy: 0.8284\n",
      "Epoch 138/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1669 - binary_accuracy: 0.9632 - val_loss: 1.9394 - val_binary_accuracy: 0.8209\n",
      "Epoch 139/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1657 - binary_accuracy: 0.9596 - val_loss: 2.0190 - val_binary_accuracy: 0.8209\n",
      "Epoch 140/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1641 - binary_accuracy: 0.9596 - val_loss: 2.0051 - val_binary_accuracy: 0.8433\n",
      "Epoch 141/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1628 - binary_accuracy: 0.9596 - val_loss: 1.9030 - val_binary_accuracy: 0.8433\n",
      "Epoch 142/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1615 - binary_accuracy: 0.9632 - val_loss: 1.9012 - val_binary_accuracy: 0.8433\n",
      "Epoch 143/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1597 - binary_accuracy: 0.9596 - val_loss: 1.9037 - val_binary_accuracy: 0.8358\n",
      "Epoch 144/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1605 - binary_accuracy: 0.9449 - val_loss: 1.9999 - val_binary_accuracy: 0.8433\n",
      "Epoch 145/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1585 - binary_accuracy: 0.9632 - val_loss: 2.0082 - val_binary_accuracy: 0.8284\n",
      "Epoch 146/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1576 - binary_accuracy: 0.9669 - val_loss: 2.0195 - val_binary_accuracy: 0.8284\n",
      "Epoch 147/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1591 - binary_accuracy: 0.9669 - val_loss: 2.0104 - val_binary_accuracy: 0.8209\n",
      "Epoch 148/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1559 - binary_accuracy: 0.9632 - val_loss: 1.9103 - val_binary_accuracy: 0.8582\n",
      "Epoch 149/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1578 - binary_accuracy: 0.9412 - val_loss: 1.8997 - val_binary_accuracy: 0.8433\n",
      "Epoch 150/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1560 - binary_accuracy: 0.9632 - val_loss: 1.8993 - val_binary_accuracy: 0.8433\n",
      "Epoch 151/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1539 - binary_accuracy: 0.9632 - val_loss: 1.9018 - val_binary_accuracy: 0.8507\n",
      "Epoch 152/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1548 - binary_accuracy: 0.9522 - val_loss: 1.9050 - val_binary_accuracy: 0.8507\n",
      "Epoch 153/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1544 - binary_accuracy: 0.9559 - val_loss: 1.9036 - val_binary_accuracy: 0.8582\n",
      "Epoch 154/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1538 - binary_accuracy: 0.9632 - val_loss: 1.9112 - val_binary_accuracy: 0.8209\n",
      "Epoch 155/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1534 - binary_accuracy: 0.9669 - val_loss: 1.9100 - val_binary_accuracy: 0.8284\n",
      "Epoch 156/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1533 - binary_accuracy: 0.9632 - val_loss: 1.9111 - val_binary_accuracy: 0.8284\n",
      "Epoch 157/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1527 - binary_accuracy: 0.9632 - val_loss: 1.9153 - val_binary_accuracy: 0.8209\n",
      "Epoch 158/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1533 - binary_accuracy: 0.9669 - val_loss: 1.9209 - val_binary_accuracy: 0.8134\n",
      "Epoch 159/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1549 - binary_accuracy: 0.9669 - val_loss: 1.9282 - val_binary_accuracy: 0.8358\n",
      "Epoch 160/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1556 - binary_accuracy: 0.9522 - val_loss: 2.0310 - val_binary_accuracy: 0.8358\n",
      "Epoch 161/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.9102 - binary_accuracy: 0.8934 - val_loss: 2.8622 - val_binary_accuracy: 0.7388\n",
      "Epoch 162/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2.9080 - binary_accuracy: 0.7831 - val_loss: 3.6273 - val_binary_accuracy: 0.7015\n",
      "Epoch 163/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.6846 - binary_accuracy: 0.8088 - val_loss: 3.0628 - val_binary_accuracy: 0.7463\n",
      "Epoch 164/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.3967 - binary_accuracy: 0.8125 - val_loss: 4.1676 - val_binary_accuracy: 0.7090\n",
      "Epoch 165/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 4.6973 - binary_accuracy: 0.6801 - val_loss: 7.9527 - val_binary_accuracy: 0.4776\n",
      "Epoch 166/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 7.0433 - binary_accuracy: 0.5368 - val_loss: 7.9975 - val_binary_accuracy: 0.4701\n",
      "Epoch 167/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 7.1117 - binary_accuracy: 0.5221 - val_loss: 7.9622 - val_binary_accuracy: 0.4701\n",
      "Epoch 168/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 6.7617 - binary_accuracy: 0.5368 - val_loss: 7.4801 - val_binary_accuracy: 0.4851\n",
      "Epoch 169/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3.1196 - binary_accuracy: 0.5110 - val_loss: 1.0656 - val_binary_accuracy: 0.5373\n",
      "Epoch 170/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.9202 - binary_accuracy: 0.4963 - val_loss: 0.6722 - val_binary_accuracy: 0.5821\n",
      "Epoch 171/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6581 - binary_accuracy: 0.6728 - val_loss: 0.7708 - val_binary_accuracy: 0.5821\n",
      "Epoch 172/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6359 - binary_accuracy: 0.6949 - val_loss: 0.6649 - val_binary_accuracy: 0.6343\n",
      "Epoch 173/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5977 - binary_accuracy: 0.7059 - val_loss: 0.6244 - val_binary_accuracy: 0.6716\n",
      "Epoch 174/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5820 - binary_accuracy: 0.7169 - val_loss: 0.6047 - val_binary_accuracy: 0.6791\n",
      "Epoch 175/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5578 - binary_accuracy: 0.7353 - val_loss: 0.5915 - val_binary_accuracy: 0.6940\n",
      "Epoch 176/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5329 - binary_accuracy: 0.7500 - val_loss: 0.5809 - val_binary_accuracy: 0.6940\n",
      "Epoch 177/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4997 - binary_accuracy: 0.7757 - val_loss: 0.5608 - val_binary_accuracy: 0.7164\n",
      "Epoch 178/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4732 - binary_accuracy: 0.7978 - val_loss: 0.5486 - val_binary_accuracy: 0.7239\n",
      "Epoch 179/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4620 - binary_accuracy: 0.8051 - val_loss: 0.5328 - val_binary_accuracy: 0.7463\n",
      "Epoch 180/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4500 - binary_accuracy: 0.8162 - val_loss: 0.5264 - val_binary_accuracy: 0.7537\n",
      "Epoch 181/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4483 - binary_accuracy: 0.8199 - val_loss: 0.5278 - val_binary_accuracy: 0.7612\n",
      "Epoch 182/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4348 - binary_accuracy: 0.8235 - val_loss: 0.5116 - val_binary_accuracy: 0.7836\n",
      "Epoch 183/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4247 - binary_accuracy: 0.8199 - val_loss: 0.5022 - val_binary_accuracy: 0.7836\n",
      "Epoch 184/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4131 - binary_accuracy: 0.8382 - val_loss: 0.4958 - val_binary_accuracy: 0.7985\n",
      "Epoch 185/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4015 - binary_accuracy: 0.8382 - val_loss: 0.4859 - val_binary_accuracy: 0.7985\n",
      "Epoch 186/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3887 - binary_accuracy: 0.8419 - val_loss: 0.4709 - val_binary_accuracy: 0.8134\n",
      "Epoch 187/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3805 - binary_accuracy: 0.8493 - val_loss: 0.4774 - val_binary_accuracy: 0.8060\n",
      "Epoch 188/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3712 - binary_accuracy: 0.8419 - val_loss: 0.4466 - val_binary_accuracy: 0.8284\n",
      "Epoch 189/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3549 - binary_accuracy: 0.8566 - val_loss: 0.4533 - val_binary_accuracy: 0.8284\n",
      "Epoch 190/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3455 - binary_accuracy: 0.8566 - val_loss: 0.4545 - val_binary_accuracy: 0.8209\n",
      "Epoch 191/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3361 - binary_accuracy: 0.8640 - val_loss: 0.4418 - val_binary_accuracy: 0.8209\n",
      "Epoch 192/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3305 - binary_accuracy: 0.8676 - val_loss: 0.4346 - val_binary_accuracy: 0.8209\n",
      "Epoch 193/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3230 - binary_accuracy: 0.8860 - val_loss: 0.4298 - val_binary_accuracy: 0.8209\n",
      "Epoch 194/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3173 - binary_accuracy: 0.8897 - val_loss: 0.4350 - val_binary_accuracy: 0.8209\n",
      "Epoch 195/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3164 - binary_accuracy: 0.8787 - val_loss: 0.4393 - val_binary_accuracy: 0.8209\n",
      "Epoch 196/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3112 - binary_accuracy: 0.8934 - val_loss: 0.4189 - val_binary_accuracy: 0.8358\n",
      "Epoch 197/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3111 - binary_accuracy: 0.8897 - val_loss: 0.4227 - val_binary_accuracy: 0.8358\n",
      "Epoch 198/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3115 - binary_accuracy: 0.8897 - val_loss: 0.4266 - val_binary_accuracy: 0.8433\n",
      "Epoch 199/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3073 - binary_accuracy: 0.8934 - val_loss: 0.4149 - val_binary_accuracy: 0.8358\n",
      "Epoch 200/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3094 - binary_accuracy: 0.8897 - val_loss: 0.4195 - val_binary_accuracy: 0.8433\n",
      "Epoch 201/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3044 - binary_accuracy: 0.8934 - val_loss: 0.4217 - val_binary_accuracy: 0.8433\n",
      "Epoch 202/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3016 - binary_accuracy: 0.8934 - val_loss: 0.4301 - val_binary_accuracy: 0.8358\n",
      "Epoch 203/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3043 - binary_accuracy: 0.8897 - val_loss: 0.4262 - val_binary_accuracy: 0.8358\n",
      "Epoch 204/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2983 - binary_accuracy: 0.8971 - val_loss: 0.4147 - val_binary_accuracy: 0.8582\n",
      "Epoch 205/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3023 - binary_accuracy: 0.8860 - val_loss: 0.4211 - val_binary_accuracy: 0.8507\n",
      "Epoch 206/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3007 - binary_accuracy: 0.8934 - val_loss: 0.4184 - val_binary_accuracy: 0.8507\n",
      "Epoch 207/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3062 - binary_accuracy: 0.8971 - val_loss: 0.4222 - val_binary_accuracy: 0.8507\n",
      "Epoch 208/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3180 - binary_accuracy: 0.9044 - val_loss: 0.4139 - val_binary_accuracy: 0.8507\n",
      "Epoch 209/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3161 - binary_accuracy: 0.9044 - val_loss: 0.4124 - val_binary_accuracy: 0.8507\n",
      "Epoch 210/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2974 - binary_accuracy: 0.8971 - val_loss: 0.4448 - val_binary_accuracy: 0.8507\n",
      "Epoch 211/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3094 - binary_accuracy: 0.9081 - val_loss: 0.4168 - val_binary_accuracy: 0.8507\n",
      "Epoch 212/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2970 - binary_accuracy: 0.9081 - val_loss: 0.4291 - val_binary_accuracy: 0.8507\n",
      "Epoch 213/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2930 - binary_accuracy: 0.9081 - val_loss: 0.4194 - val_binary_accuracy: 0.8507\n",
      "Epoch 214/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2931 - binary_accuracy: 0.9044 - val_loss: 0.4226 - val_binary_accuracy: 0.8507\n",
      "Epoch 215/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2926 - binary_accuracy: 0.9081 - val_loss: 0.4214 - val_binary_accuracy: 0.8507\n",
      "Epoch 216/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2918 - binary_accuracy: 0.9081 - val_loss: 0.4267 - val_binary_accuracy: 0.8507\n",
      "Epoch 217/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2927 - binary_accuracy: 0.9081 - val_loss: 0.4357 - val_binary_accuracy: 0.8507\n",
      "Epoch 218/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2947 - binary_accuracy: 0.9081 - val_loss: 0.4160 - val_binary_accuracy: 0.8507\n",
      "Epoch 219/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2919 - binary_accuracy: 0.9044 - val_loss: 0.4262 - val_binary_accuracy: 0.8433\n",
      "Epoch 220/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2883 - binary_accuracy: 0.9081 - val_loss: 0.4360 - val_binary_accuracy: 0.8433\n",
      "Epoch 221/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2895 - binary_accuracy: 0.9081 - val_loss: 0.4295 - val_binary_accuracy: 0.8507\n",
      "Epoch 222/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2898 - binary_accuracy: 0.9007 - val_loss: 0.4245 - val_binary_accuracy: 0.8507\n",
      "Epoch 223/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2928 - binary_accuracy: 0.9044 - val_loss: 0.4196 - val_binary_accuracy: 0.8507\n",
      "Epoch 224/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2899 - binary_accuracy: 0.9044 - val_loss: 0.4293 - val_binary_accuracy: 0.8433\n",
      "Epoch 225/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2867 - binary_accuracy: 0.9081 - val_loss: 0.4350 - val_binary_accuracy: 0.8433\n",
      "Epoch 226/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2873 - binary_accuracy: 0.9081 - val_loss: 0.4188 - val_binary_accuracy: 0.8507\n",
      "Epoch 227/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2866 - binary_accuracy: 0.9118 - val_loss: 0.4366 - val_binary_accuracy: 0.8433\n",
      "Epoch 228/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2971 - binary_accuracy: 0.9044 - val_loss: 0.4092 - val_binary_accuracy: 0.8507\n",
      "Epoch 229/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2869 - binary_accuracy: 0.9081 - val_loss: 0.4225 - val_binary_accuracy: 0.8433\n",
      "Epoch 230/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2820 - binary_accuracy: 0.9081 - val_loss: 0.4466 - val_binary_accuracy: 0.8433\n",
      "Epoch 231/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2910 - binary_accuracy: 0.9007 - val_loss: 0.4199 - val_binary_accuracy: 0.8433\n",
      "Epoch 232/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2873 - binary_accuracy: 0.9007 - val_loss: 0.4187 - val_binary_accuracy: 0.8433\n",
      "Epoch 233/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2858 - binary_accuracy: 0.9081 - val_loss: 0.4386 - val_binary_accuracy: 0.8433\n",
      "Epoch 234/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2806 - binary_accuracy: 0.9118 - val_loss: 0.4337 - val_binary_accuracy: 0.8358\n",
      "Epoch 235/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2799 - binary_accuracy: 0.9118 - val_loss: 0.4281 - val_binary_accuracy: 0.8507\n",
      "Epoch 236/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2810 - binary_accuracy: 0.9007 - val_loss: 0.4227 - val_binary_accuracy: 0.8433\n",
      "Epoch 237/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2800 - binary_accuracy: 0.9081 - val_loss: 0.4260 - val_binary_accuracy: 0.8358\n",
      "Epoch 238/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2857 - binary_accuracy: 0.9081 - val_loss: 0.4269 - val_binary_accuracy: 0.8433\n",
      "Epoch 239/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2792 - binary_accuracy: 0.9154 - val_loss: 0.4331 - val_binary_accuracy: 0.8433\n",
      "Epoch 240/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2768 - binary_accuracy: 0.9118 - val_loss: 0.4250 - val_binary_accuracy: 0.8358\n",
      "Epoch 241/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2751 - binary_accuracy: 0.9118 - val_loss: 0.4376 - val_binary_accuracy: 0.8507\n",
      "Epoch 242/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2800 - binary_accuracy: 0.9118 - val_loss: 0.4290 - val_binary_accuracy: 0.8433\n",
      "Epoch 243/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2751 - binary_accuracy: 0.9118 - val_loss: 0.4271 - val_binary_accuracy: 0.8358\n",
      "Epoch 244/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2725 - binary_accuracy: 0.9118 - val_loss: 0.4449 - val_binary_accuracy: 0.8433\n",
      "Epoch 245/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2768 - binary_accuracy: 0.9118 - val_loss: 0.4313 - val_binary_accuracy: 0.8433\n",
      "Epoch 246/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2729 - binary_accuracy: 0.9118 - val_loss: 0.4388 - val_binary_accuracy: 0.8358\n",
      "Epoch 247/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2711 - binary_accuracy: 0.9154 - val_loss: 0.4389 - val_binary_accuracy: 0.8433\n",
      "Epoch 248/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2732 - binary_accuracy: 0.9118 - val_loss: 0.4232 - val_binary_accuracy: 0.8433\n",
      "Epoch 249/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2771 - binary_accuracy: 0.9118 - val_loss: 0.4369 - val_binary_accuracy: 0.8433\n",
      "Epoch 250/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2689 - binary_accuracy: 0.9081 - val_loss: 0.4173 - val_binary_accuracy: 0.8358\n",
      "Epoch 251/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2734 - binary_accuracy: 0.9118 - val_loss: 0.4273 - val_binary_accuracy: 0.8358\n",
      "Epoch 252/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2683 - binary_accuracy: 0.9118 - val_loss: 0.4312 - val_binary_accuracy: 0.8358\n",
      "Epoch 253/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2653 - binary_accuracy: 0.9118 - val_loss: 0.4455 - val_binary_accuracy: 0.8358\n",
      "Epoch 254/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2705 - binary_accuracy: 0.9154 - val_loss: 0.4196 - val_binary_accuracy: 0.8358\n",
      "Epoch 255/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2837 - binary_accuracy: 0.9044 - val_loss: 0.4206 - val_binary_accuracy: 0.8433\n",
      "Epoch 256/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2731 - binary_accuracy: 0.9118 - val_loss: 0.4557 - val_binary_accuracy: 0.8358\n",
      "Epoch 257/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2681 - binary_accuracy: 0.9081 - val_loss: 0.4353 - val_binary_accuracy: 0.8433\n",
      "Epoch 258/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2713 - binary_accuracy: 0.9118 - val_loss: 0.4196 - val_binary_accuracy: 0.8358\n",
      "Epoch 259/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2620 - binary_accuracy: 0.9191 - val_loss: 0.4468 - val_binary_accuracy: 0.8358\n",
      "Epoch 260/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2615 - binary_accuracy: 0.9154 - val_loss: 0.4409 - val_binary_accuracy: 0.8358\n",
      "Epoch 261/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2593 - binary_accuracy: 0.9154 - val_loss: 0.4467 - val_binary_accuracy: 0.8433\n",
      "Epoch 262/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2679 - binary_accuracy: 0.9191 - val_loss: 0.4295 - val_binary_accuracy: 0.8358\n",
      "Epoch 263/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2570 - binary_accuracy: 0.9191 - val_loss: 0.4742 - val_binary_accuracy: 0.8507\n",
      "Epoch 264/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2637 - binary_accuracy: 0.9228 - val_loss: 0.4221 - val_binary_accuracy: 0.8433\n",
      "Epoch 265/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2589 - binary_accuracy: 0.9191 - val_loss: 0.4351 - val_binary_accuracy: 0.8433\n",
      "Epoch 266/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2590 - binary_accuracy: 0.9154 - val_loss: 0.4447 - val_binary_accuracy: 0.8507\n",
      "Epoch 267/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2490 - binary_accuracy: 0.9118 - val_loss: 0.4508 - val_binary_accuracy: 0.8358\n",
      "Epoch 268/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2493 - binary_accuracy: 0.9081 - val_loss: 0.4504 - val_binary_accuracy: 0.8507\n",
      "Epoch 269/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2417 - binary_accuracy: 0.9228 - val_loss: 0.4671 - val_binary_accuracy: 0.8507\n",
      "Epoch 270/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2410 - binary_accuracy: 0.9154 - val_loss: 0.4469 - val_binary_accuracy: 0.8507\n",
      "Epoch 271/1000\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2424 - binary_accuracy: 0.9118 - val_loss: 0.4333 - val_binary_accuracy: 0.8507\n",
      "Epoch 272/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2402 - binary_accuracy: 0.9081 - val_loss: 0.4662 - val_binary_accuracy: 0.8507\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.2334 - binary_accuracy: 0.8806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2333645820617676, 0.8805969953536987]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if dicc['regularizer_type'] == 'None':\n",
    "    dicc['regularizer_type'] = None\n",
    "    \n",
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(1024, input_shape=(x_train.shape[1],), activation = dicc['activation_1'], kernel_initializer=dicc['init_mode_1'], kernel_regularizer=dicc['regularizer_type']),\n",
    "    keras.layers.Dense(512, activation=dicc['activation_2'], kernel_initializer=dicc['init_mode_2']),\n",
    "    keras.layers.Dense(256, activation=dicc['activation_3'], kernel_initializer=dicc['init_mode_3']),\n",
    "    keras.layers.Dense(128, activation=dicc['activation_4'], kernel_initializer=dicc['init_mode_4']),\n",
    "    keras.layers.Dense(64, activation=dicc['activation_5'], kernel_initializer=dicc['init_mode_5']),\n",
    "    keras.layers.Dense((df['label'].nunique()-1), activation=dicc['activation_6'], kernel_initializer=dicc['init_mode_6'])\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.BinaryCrossentropy(),\n",
    "    metrics = keras.metrics.BinaryAccuracy()\n",
    ")\n",
    "\n",
    "EarlyStop = tf.keras.callbacks.EarlyStopping(monitor = 'val_binary_accuracy', patience = 250, mode = 'max', restore_best_weights = True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 1000, validation_data=(x_test, y_test), callbacks=EarlyStop)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "id": "8F3bMnOewzVQ",
    "outputId": "462b690e-f155-4f20-cf2d-70ee157a34c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        62\n",
      "           1       0.89      0.89      0.89        72\n",
      "\n",
      "    accuracy                           0.88       134\n",
      "   macro avg       0.88      0.88      0.88       134\n",
      "weighted avg       0.88      0.88      0.88       134\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_names = ['0', '1']\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index=target_names, columns=target_names)\n",
    "sns.set(font_scale=1.0)\n",
    "\n",
    "sns.heatmap(cm_df, cmap='Blues',annot=True, fmt='g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score\n",
      "0.8799283154121864\n",
      "0.8805970149253731\n",
      "0.8805970149253731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F1-score')\n",
    "print(f1_score(y_test, y_pred, average='macro'))\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
