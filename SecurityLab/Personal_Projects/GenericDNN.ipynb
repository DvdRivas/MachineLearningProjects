{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOnIQIsPUMfD",
    "outputId": "60b326c5-2a45-42b6-e6f2-fc3d5c4f4db8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A6ti0PesWLkM"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.read_csv(\"heart_failure_clinical_records_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ba3bCMhlWx1N",
    "outputId": "d65a53a0-5006-457e-e18d-9b36ed1bc892"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.833893</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>581.839465</td>\n",
       "      <td>0.418060</td>\n",
       "      <td>38.083612</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>263358.029264</td>\n",
       "      <td>1.39388</td>\n",
       "      <td>136.625418</td>\n",
       "      <td>0.648829</td>\n",
       "      <td>0.32107</td>\n",
       "      <td>130.260870</td>\n",
       "      <td>0.32107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.894809</td>\n",
       "      <td>0.496107</td>\n",
       "      <td>970.287881</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>11.834841</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>97804.236869</td>\n",
       "      <td>1.03451</td>\n",
       "      <td>4.412477</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.46767</td>\n",
       "      <td>77.614208</td>\n",
       "      <td>0.46767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25100.000000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212500.000000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262000.000000</td>\n",
       "      <td>1.10000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>303500.000000</td>\n",
       "      <td>1.40000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>850000.000000</td>\n",
       "      <td>9.40000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age     anaemia  creatinine_phosphokinase    diabetes  \\\n",
       "count  299.000000  299.000000                299.000000  299.000000   \n",
       "mean    60.833893    0.431438                581.839465    0.418060   \n",
       "std     11.894809    0.496107                970.287881    0.494067   \n",
       "min     40.000000    0.000000                 23.000000    0.000000   \n",
       "25%     51.000000    0.000000                116.500000    0.000000   \n",
       "50%     60.000000    0.000000                250.000000    0.000000   \n",
       "75%     70.000000    1.000000                582.000000    1.000000   \n",
       "max     95.000000    1.000000               7861.000000    1.000000   \n",
       "\n",
       "       ejection_fraction  high_blood_pressure      platelets  \\\n",
       "count         299.000000           299.000000     299.000000   \n",
       "mean           38.083612             0.351171  263358.029264   \n",
       "std            11.834841             0.478136   97804.236869   \n",
       "min            14.000000             0.000000   25100.000000   \n",
       "25%            30.000000             0.000000  212500.000000   \n",
       "50%            38.000000             0.000000  262000.000000   \n",
       "75%            45.000000             1.000000  303500.000000   \n",
       "max            80.000000             1.000000  850000.000000   \n",
       "\n",
       "       serum_creatinine  serum_sodium         sex    smoking        time  \\\n",
       "count         299.00000    299.000000  299.000000  299.00000  299.000000   \n",
       "mean            1.39388    136.625418    0.648829    0.32107  130.260870   \n",
       "std             1.03451      4.412477    0.478136    0.46767   77.614208   \n",
       "min             0.50000    113.000000    0.000000    0.00000    4.000000   \n",
       "25%             0.90000    134.000000    0.000000    0.00000   73.000000   \n",
       "50%             1.10000    137.000000    1.000000    0.00000  115.000000   \n",
       "75%             1.40000    140.000000    1.000000    1.00000  203.000000   \n",
       "max             9.40000    148.000000    1.000000    1.00000  285.000000   \n",
       "\n",
       "       DEATH_EVENT  \n",
       "count    299.00000  \n",
       "mean       0.32107  \n",
       "std        0.46767  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        1.00000  \n",
       "max        1.00000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGHvhQhCfNSu",
    "outputId": "b3b7f1f4-fd58-4d50-8b09-00c18ea23c37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "JDgIifMWXGQl",
    "outputId": "5c4e9e77-0ccf-400b-9b2d-e7be340cfd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de observaciones por clase\n",
      "DEATH_EVENT\n",
      "0    203\n",
      "1     96\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Cantidad de observaciones por clase')\n",
    "print(df['DEATH_EVENT'].value_counts())\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "data_x = df['DEATH_EVENT']\n",
    "\n",
    "# Create a list of colors for the boxplots based on the number of features you have\n",
    "boxplots_colors = ['blue', 'red']\n",
    "\n",
    "# Boxplot data\n",
    "bp = ax.boxplot(data_x, patch_artist = True, vert = False)\n",
    "\n",
    "# Change to the desired color and add transparency\n",
    "for patch, color in zip(bp['boxes'], boxplots_colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.4)\n",
    "\n",
    "# Create a list of colors for the violin plots based on the number of features you have\n",
    "violin_colors = ['black', 'black']\n",
    "\n",
    "# Violinplot data\n",
    "vp = ax.violinplot(data_x, points=500,\n",
    "               showmeans=False, showextrema=False, showmedians=False, vert=False)\n",
    "\n",
    "for idx, b in enumerate(vp['bodies']):\n",
    "    # Get the center of the plot\n",
    "    m = np.mean(b.get_paths()[0].vertices[:, 0])\n",
    "    # Modify it so we only see the upper half of the violin plot\n",
    "    b.get_paths()[0].vertices[:, 1] = np.clip(b.get_paths()[0].vertices[:, 1], idx+1, idx+2)\n",
    "    # Change to the desired color\n",
    "    b.set_color(violin_colors[idx])\n",
    "\n",
    "# Crear scatter plot horizontal\n",
    "scatter_data = data_x\n",
    "y = np.random.normal(1, 0.04, size=len(scatter_data)) - 0.1\n",
    "plt.scatter(scatter_data, y, alpha=0.6)\n",
    "\n",
    "# plt.yticks(np.arange(1,1,1), ['Feature 1', 'Feature 2'])  # Set text labels.\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Density')\n",
    "plt.title(\"Raincloud plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "as1c3nDGfoAS"
   },
   "outputs": [],
   "source": [
    "df = df.rename({'DEATH_EVENT':'label'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQsXmpq2dmN0",
    "outputId": "a0d2c1af-dcf0-4cc6-e376-96fec0f3db85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 12), (99, 12))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.drop(['label'],axis=1),df['label'],test_size=0.33,random_state=0)\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    68\n",
       "1    31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fnl3GUzkhKR2"
   },
   "outputs": [],
   "source": [
    "norm = tf.keras.layers.Normalization(axis=-1)\n",
    "norm.adapt(x_train)\n",
    "x_train = pd.DataFrame(norm(x_train))\n",
    "# norm.adapt(x_test)\n",
    "x_test = pd.DataFrame(norm(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVwvzoOd5bvB",
    "outputId": "a337b3fa-1aa7-41c4-928c-1cf5b6ae89aa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-30 19:12:35,974] A new study created in memory with name: no-name-e14fde21-5133-401b-b923-762ca63c6cca\n",
      "[I 2024-01-30 19:12:42,385] Trial 0 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': None, 'activation_1': 'tanh', 'activation_2': 'selu', 'activation_3': 'sigmoid', 'activation_4': 'elu', 'activation_5': 'softsign', 'activation_6': 'softmax', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'he_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 0 with value: 0.31313130259513855.\n",
      "[I 2024-01-30 19:12:52,063] Trial 1 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'softplus', 'activation_4': 'hard_sigmoid', 'activation_5': 'exponential', 'activation_6': 'softplus', 'init_mode_1': 'he_normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'uniform'}. Best is trial 1 with value: 0.7676767706871033.\n",
      "[I 2024-01-30 19:13:00,258] Trial 2 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softsign', 'activation_2': 'linear', 'activation_3': 'softmax', 'activation_4': 'tanh', 'activation_5': 'linear', 'activation_6': 'linear', 'init_mode_1': 'he_normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'zero', 'init_mode_6': 'glorot_normal'}. Best is trial 1 with value: 0.7676767706871033.\n",
      "[I 2024-01-30 19:13:08,149] Trial 3 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': None, 'activation_1': 'sigmoid', 'activation_2': 'softsign', 'activation_3': 'linear', 'activation_4': 'selu', 'activation_5': 'sigmoid', 'activation_6': 'linear', 'init_mode_1': 'normal', 'init_mode_2': 'normal', 'init_mode_3': 'he_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'lecun_uniform'}. Best is trial 1 with value: 0.7676767706871033.\n",
      "[I 2024-01-30 19:13:17,717] Trial 4 finished with value: 0.7777777910232544 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:13:27,021] Trial 5 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': None, 'activation_1': 'hard_sigmoid', 'activation_2': 'swish', 'activation_3': 'relu', 'activation_4': 'hard_sigmoid', 'activation_5': 'hard_sigmoid', 'activation_6': 'exponential', 'init_mode_1': 'he_uniform', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'uniform', 'init_mode_4': 'normal', 'init_mode_5': 'he_normal', 'init_mode_6': 'lecun_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:13:36,887] Trial 6 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'hard_sigmoid', 'activation_2': 'tanh', 'activation_3': 'softplus', 'activation_4': 'softmax', 'activation_5': 'relu', 'activation_6': 'softplus', 'init_mode_1': 'uniform', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'uniform', 'init_mode_6': 'uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:13:45,503] Trial 7 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l1', 'activation_1': 'sigmoid', 'activation_2': 'exponential', 'activation_3': 'elu', 'activation_4': 'sigmoid', 'activation_5': 'hard_sigmoid', 'activation_6': 'exponential', 'init_mode_1': 'he_uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'zero', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:13:54,003] Trial 8 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': None, 'activation_1': 'elu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'exponential', 'activation_5': 'swish', 'activation_6': 'swish', 'init_mode_1': 'zero', 'init_mode_2': 'normal', 'init_mode_3': 'normal', 'init_mode_4': 'normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:14:02,715] Trial 9 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'softsign', 'activation_3': 'swish', 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'tanh', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'zero', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'zero', 'init_mode_6': 'normal'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:14:11,664] Trial 10 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:14:21,492] Trial 11 finished with value: 0.7575757503509521 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'softplus', 'activation_4': 'softsign', 'activation_5': 'exponential', 'activation_6': 'softplus', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:14:30,059] Trial 12 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'exponential', 'activation_4': 'hard_sigmoid', 'activation_5': 'exponential', 'activation_6': 'selu', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'zero', 'init_mode_3': 'he_normal', 'init_mode_4': 'uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'zero'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:14:38,346] Trial 13 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'selu', 'activation_2': 'softmax', 'activation_3': 'softsign', 'activation_4': 'linear', 'activation_5': 'softplus', 'activation_6': 'elu', 'init_mode_1': 'he_normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:14:46,961] Trial 14 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softmax', 'activation_2': 'softplus', 'activation_3': 'hard_sigmoid', 'activation_4': 'relu', 'activation_5': 'tanh', 'activation_6': 'sigmoid', 'init_mode_1': 'normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:14:55,687] Trial 15 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softplus', 'activation_2': 'hard_sigmoid', 'activation_3': 'softplus', 'activation_4': 'softplus', 'activation_5': 'selu', 'activation_6': 'softsign', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'normal', 'init_mode_3': 'zero', 'init_mode_4': 'uniform', 'init_mode_5': 'normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:15:04,440] Trial 16 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'linear', 'activation_2': 'elu', 'activation_3': 'selu', 'activation_4': 'swish', 'activation_5': 'exponential', 'activation_6': 'relu', 'init_mode_1': 'uniform', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'zero', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'he_normal'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:15:12,046] Trial 17 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'exponential', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'hard_sigmoid', 'activation_5': 'elu', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'uniform', 'init_mode_3': 'normal', 'init_mode_4': 'he_uniform', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'zero'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:15:20,282] Trial 18 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'selu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'selu', 'init_mode_1': 'zero', 'init_mode_2': 'zero', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'uniform', 'init_mode_6': 'glorot_normal'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:15:30,509] Trial 19 finished with value: 0.7575757503509521 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'relu', 'activation_5': 'softplus', 'activation_6': 'softplus', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'uniform', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'normal'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:15:39,400] Trial 20 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softsign', 'activation_2': 'swish', 'activation_3': 'hard_sigmoid', 'activation_4': 'swish', 'activation_5': 'selu', 'activation_6': 'softmax', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'uniform', 'init_mode_5': 'he_normal', 'init_mode_6': 'uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:15:48,548] Trial 21 finished with value: 0.6767676472663879 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:16:13,175] Trial 22 finished with value: 0.7777777910232544 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:16:22,125] Trial 23 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'selu', 'init_mode_1': 'he_normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:16:35,845] Trial 24 finished with value: 0.7070707082748413 and parameters: {'regularizer_type': 'l2', 'activation_1': 'tanh', 'activation_2': 'softplus', 'activation_3': 'linear', 'activation_4': 'selu', 'activation_5': 'softmax', 'activation_6': 'relu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:16:44,323] Trial 25 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'softplus', 'activation_5': 'softsign', 'activation_6': 'softsign', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:16:53,986] Trial 26 finished with value: 0.6969696879386902 and parameters: {'regularizer_type': 'l2', 'activation_1': 'selu', 'activation_2': 'linear', 'activation_3': 'softsign', 'activation_4': 'exponential', 'activation_5': 'relu', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:17:02,869] Trial 27 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'elu', 'activation_2': 'hard_sigmoid', 'activation_3': 'elu', 'activation_4': 'tanh', 'activation_5': 'elu', 'activation_6': 'swish', 'init_mode_1': 'normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:17:11,108] Trial 28 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'exponential', 'activation_2': 'selu', 'activation_3': 'sigmoid', 'activation_4': 'elu', 'activation_5': 'linear', 'activation_6': 'elu', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'normal', 'init_mode_3': 'he_uniform', 'init_mode_4': 'normal', 'init_mode_5': 'uniform', 'init_mode_6': 'zero'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:17:19,735] Trial 29 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l2', 'activation_1': 'linear', 'activation_2': 'elu', 'activation_3': 'softmax', 'activation_4': 'linear', 'activation_5': 'sigmoid', 'activation_6': 'sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'zero', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'he_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:17:28,131] Trial 30 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': None, 'activation_1': 'softmax', 'activation_2': 'relu', 'activation_3': 'exponential', 'activation_4': 'sigmoid', 'activation_5': 'swish', 'activation_6': 'tanh', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'zero', 'init_mode_5': 'zero', 'init_mode_6': 'lecun_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:17:37,374] Trial 31 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 4 with value: 0.7777777910232544.\n",
      "[I 2024-01-30 19:17:45,982] Trial 32 finished with value: 0.7979797720909119 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:17:54,800] Trial 33 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'glorot_normal'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:18:03,955] Trial 34 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softplus', 'activation_2': 'selu', 'activation_3': 'sigmoid', 'activation_4': 'hard_sigmoid', 'activation_5': 'softsign', 'activation_6': 'linear', 'init_mode_1': 'he_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'uniform', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_normal', 'init_mode_6': 'he_uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:18:12,507] Trial 35 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'softplus', 'activation_4': 'elu', 'activation_5': 'exponential', 'activation_6': 'softplus', 'init_mode_1': 'he_normal', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:18:20,508] Trial 36 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': None, 'activation_1': 'tanh', 'activation_2': 'softmax', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'softmax', 'init_mode_1': 'uniform', 'init_mode_2': 'normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'lecun_uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:18:29,387] Trial 37 finished with value: 0.7979797720909119 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softsign', 'activation_2': 'softsign', 'activation_3': 'relu', 'activation_4': 'tanh', 'activation_5': 'hard_sigmoid', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'he_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:18:38,292] Trial 38 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softsign', 'activation_2': 'softsign', 'activation_3': 'relu', 'activation_4': 'tanh', 'activation_5': 'hard_sigmoid', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'he_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:18:46,901] Trial 39 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softsign', 'activation_2': 'softsign', 'activation_3': 'relu', 'activation_4': 'tanh', 'activation_5': 'hard_sigmoid', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'he_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:18:55,883] Trial 40 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': None, 'activation_1': 'sigmoid', 'activation_2': 'softsign', 'activation_3': 'softmax', 'activation_4': 'tanh', 'activation_5': 'hard_sigmoid', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'he_normal', 'init_mode_3': 'normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'normal'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:19:04,800] Trial 41 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'hard_sigmoid', 'activation_2': 'swish', 'activation_3': 'relu', 'activation_4': 'softmax', 'activation_5': 'linear', 'activation_6': 'selu', 'init_mode_1': 'zero', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'zero', 'init_mode_6': 'uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:19:13,666] Trial 42 finished with value: 0.747474730014801 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softsign', 'activation_2': 'softmax', 'activation_3': 'linear', 'activation_4': 'selu', 'activation_5': 'sigmoid', 'activation_6': 'softplus', 'init_mode_1': 'he_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:19:23,367] Trial 43 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'linear', 'activation_3': 'softplus', 'activation_4': 'hard_sigmoid', 'activation_5': 'tanh', 'activation_6': 'linear', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'zero', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'glorot_uniform', 'init_mode_6': 'uniform'}. Best is trial 32 with value: 0.7979797720909119.\n",
      "[I 2024-01-30 19:19:32,082] Trial 44 finished with value: 0.808080792427063 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 44 with value: 0.808080792427063.\n",
      "[I 2024-01-30 19:19:40,264] Trial 45 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 44 with value: 0.808080792427063.\n",
      "[I 2024-01-30 19:19:49,268] Trial 46 finished with value: 0.7373737096786499 and parameters: {'regularizer_type': 'l2', 'activation_1': 'elu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 44 with value: 0.808080792427063.\n",
      "[I 2024-01-30 19:19:59,022] Trial 47 finished with value: 0.8181818127632141 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'swish', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:20:10,152] Trial 48 finished with value: 0.7373737096786499 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'activation_5': 'swish', 'activation_6': 'swish', 'init_mode_1': 'normal', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:20:19,542] Trial 49 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'tanh', 'activation_3': 'elu', 'activation_4': 'exponential', 'activation_5': 'swish', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:20:30,976] Trial 50 finished with value: 0.808080792427063 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:20:42,075] Trial 51 finished with value: 0.8181818127632141 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:20:50,737] Trial 52 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:21:04,866] Trial 53 finished with value: 0.7979797720909119 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:21:15,082] Trial 54 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:21:23,758] Trial 55 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'relu', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:21:40,462] Trial 56 finished with value: 0.808080792427063 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'tanh', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:21:49,189] Trial 57 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'tanh', 'init_mode_1': 'uniform', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:21:58,593] Trial 58 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'tanh', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:22:08,101] Trial 59 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'swish', 'activation_5': 'softplus', 'activation_6': 'tanh', 'init_mode_1': 'zero', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:22:17,432] Trial 60 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l1', 'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'hard_sigmoid', 'activation_4': 'softsign', 'activation_5': 'softmax', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:22:25,864] Trial 61 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'selu', 'activation_2': 'softplus', 'activation_3': 'selu', 'activation_4': 'softplus', 'activation_5': 'selu', 'activation_6': 'elu', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'uniform', 'init_mode_4': 'uniform', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'glorot_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:22:34,980] Trial 62 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'hard_sigmoid', 'activation_2': 'relu', 'activation_3': 'softsign', 'activation_4': 'linear', 'activation_5': 'relu', 'activation_6': 'softsign', 'init_mode_1': 'normal', 'init_mode_2': 'zero', 'init_mode_3': 'zero', 'init_mode_4': 'zero', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:22:44,332] Trial 63 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softmax', 'activation_2': 'softsign', 'activation_3': 'exponential', 'activation_4': 'softmax', 'activation_5': 'swish', 'activation_6': 'relu', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'uniform', 'init_mode_6': 'glorot_uniform'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:22:54,206] Trial 64 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'linear', 'activation_2': 'hard_sigmoid', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'hard_sigmoid', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'he_normal', 'init_mode_6': 'zero'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:23:02,798] Trial 65 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'exponential', 'activation_2': 'elu', 'activation_3': 'relu', 'activation_4': 'tanh', 'activation_5': 'elu', 'activation_6': 'sigmoid', 'init_mode_1': 'normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'he_uniform', 'init_mode_4': 'uniform', 'init_mode_5': 'normal', 'init_mode_6': 'normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:23:11,359] Trial 66 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'softmax', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:23:25,116] Trial 67 finished with value: 0.7777777910232544 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softsign', 'activation_2': 'tanh', 'activation_3': 'linear', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:23:33,431] Trial 68 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'tanh', 'activation_2': 'exponential', 'activation_3': 'relu', 'activation_4': 'selu', 'activation_5': 'softsign', 'activation_6': 'selu', 'init_mode_1': 'he_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'he_uniform', 'init_mode_5': 'zero', 'init_mode_6': 'lecun_uniform'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:23:42,104] Trial 69 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softplus', 'activation_2': 'selu', 'activation_3': 'softmax', 'activation_4': 'elu', 'activation_5': 'swish', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:23:51,556] Trial 70 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': None, 'activation_1': 'swish', 'activation_2': 'swish', 'activation_3': 'sigmoid', 'activation_4': 'softsign', 'activation_5': 'hard_sigmoid', 'activation_6': 'tanh', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'uniform', 'init_mode_5': 'uniform', 'init_mode_6': 'glorot_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:24:01,051] Trial 71 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:24:12,872] Trial 72 finished with value: 0.7979797720909119 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:24:22,070] Trial 73 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'exponential', 'activation_3': 'swish', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:24:33,192] Trial 74 finished with value: 0.808080792427063 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'softsign', 'activation_3': 'elu', 'activation_4': 'relu', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:24:41,552] Trial 75 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'elu', 'activation_2': 'softsign', 'activation_3': 'elu', 'activation_4': 'relu', 'activation_5': 'linear', 'activation_6': 'selu', 'init_mode_1': 'glorot_uniform', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'zero', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'zero'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:24:52,926] Trial 76 finished with value: 0.7575757503509521 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softsign', 'activation_2': 'softsign', 'activation_3': 'elu', 'activation_4': 'relu', 'activation_5': 'softplus', 'activation_6': 'swish', 'init_mode_1': 'uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'glorot_uniform'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:25:02,065] Trial 77 finished with value: 0.7272727489471436 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'softsign', 'activation_3': 'elu', 'activation_4': 'relu', 'activation_5': 'sigmoid', 'activation_6': 'linear', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'he_uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:25:10,773] Trial 78 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'selu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'exponential', 'activation_5': 'softmax', 'activation_6': 'relu', 'init_mode_1': 'normal', 'init_mode_2': 'zero', 'init_mode_3': 'uniform', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_normal', 'init_mode_6': 'uniform'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:25:19,128] Trial 79 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'softmax', 'activation_2': 'linear', 'activation_3': 'tanh', 'activation_4': 'tanh', 'activation_5': 'exponential', 'activation_6': 'elu', 'init_mode_1': 'zero', 'init_mode_2': 'uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:25:27,947] Trial 80 finished with value: 0.808080792427063 and parameters: {'regularizer_type': 'l2', 'activation_1': 'linear', 'activation_2': 'sigmoid', 'activation_3': 'hard_sigmoid', 'activation_4': 'sigmoid', 'activation_5': 'selu', 'activation_6': 'sigmoid', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:25:42,098] Trial 81 finished with value: 0.7878788113594055 and parameters: {'regularizer_type': 'l2', 'activation_1': 'linear', 'activation_2': 'sigmoid', 'activation_3': 'hard_sigmoid', 'activation_4': 'swish', 'activation_5': 'selu', 'activation_6': 'sigmoid', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:25:51,493] Trial 82 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l2', 'activation_1': 'linear', 'activation_2': 'sigmoid', 'activation_3': 'hard_sigmoid', 'activation_4': 'sigmoid', 'activation_5': 'elu', 'activation_6': 'sigmoid', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:26:10,783] Trial 83 finished with value: 0.7575757503509521 and parameters: {'regularizer_type': 'l2', 'activation_1': 'linear', 'activation_2': 'sigmoid', 'activation_3': 'hard_sigmoid', 'activation_4': 'sigmoid', 'activation_5': 'selu', 'activation_6': 'sigmoid', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:26:19,499] Trial 84 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'exponential', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'linear', 'activation_5': 'selu', 'activation_6': 'softsign', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'normal', 'init_mode_4': 'lecun_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'lecun_uniform'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:26:28,302] Trial 85 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'relu', 'activation_2': 'softsign', 'activation_3': 'softsign', 'activation_4': 'softplus', 'activation_5': 'relu', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'he_normal', 'init_mode_4': 'uniform', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:26:38,695] Trial 86 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': None, 'activation_1': 'softplus', 'activation_2': 'hard_sigmoid', 'activation_3': 'selu', 'activation_4': 'sigmoid', 'activation_5': 'swish', 'activation_6': 'hard_sigmoid', 'init_mode_1': 'he_normal', 'init_mode_2': 'he_normal', 'init_mode_3': 'zero', 'init_mode_4': 'he_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'he_uniform'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:26:47,447] Trial 87 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'sigmoid', 'activation_2': 'softplus', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'activation_5': 'hard_sigmoid', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'normal', 'init_mode_4': 'normal', 'init_mode_5': 'zero', 'init_mode_6': 'uniform'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:26:56,566] Trial 88 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l2', 'activation_1': 'hard_sigmoid', 'activation_2': 'elu', 'activation_3': 'exponential', 'activation_4': 'relu', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'he_uniform', 'init_mode_2': 'lecun_uniform', 'init_mode_3': 'glorot_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:27:12,499] Trial 89 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l1', 'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'elu', 'activation_4': 'tanh', 'activation_5': 'selu', 'activation_6': 'tanh', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 47 with value: 0.8181818127632141.\n",
      "[I 2024-01-30 19:27:21,986] Trial 90 finished with value: 0.8282828330993652 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'sigmoid', 'activation_3': 'softplus', 'activation_4': 'hard_sigmoid', 'activation_5': 'tanh', 'activation_6': 'softplus', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 90 with value: 0.8282828330993652.\n",
      "[I 2024-01-30 19:27:30,728] Trial 91 finished with value: 0.31313130259513855 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'sigmoid', 'activation_3': 'softplus', 'activation_4': 'hard_sigmoid', 'activation_5': 'tanh', 'activation_6': 'softmax', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 90 with value: 0.8282828330993652.\n",
      "[I 2024-01-30 19:27:44,190] Trial 92 finished with value: 0.7676767706871033 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'softmax', 'activation_3': 'softplus', 'activation_4': 'softsign', 'activation_5': 'tanh', 'activation_6': 'softplus', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 90 with value: 0.8282828330993652.\n",
      "[I 2024-01-30 19:27:53,070] Trial 93 finished with value: 0.7878788113594055 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'sigmoid', 'activation_3': 'softplus', 'activation_4': 'elu', 'activation_5': 'tanh', 'activation_6': 'softplus', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 90 with value: 0.8282828330993652.\n",
      "[I 2024-01-30 19:28:03,149] Trial 94 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'hard_sigmoid', 'activation_5': 'softsign', 'activation_6': 'softplus', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 90 with value: 0.8282828330993652.\n",
      "[I 2024-01-30 19:28:12,537] Trial 95 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'softsign', 'activation_2': 'softsign', 'activation_3': 'hard_sigmoid', 'activation_4': 'hard_sigmoid', 'activation_5': 'relu', 'activation_6': 'selu', 'init_mode_1': 'lecun_uniform', 'init_mode_2': 'glorot_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'he_normal', 'init_mode_5': 'he_uniform', 'init_mode_6': 'he_uniform'}. Best is trial 90 with value: 0.8282828330993652.\n",
      "[I 2024-01-30 19:28:21,055] Trial 96 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'swish', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'softmax', 'activation_5': 'tanh', 'activation_6': 'sigmoid', 'init_mode_1': 'normal', 'init_mode_2': 'normal', 'init_mode_3': 'glorot_uniform', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'glorot_normal', 'init_mode_6': 'uniform'}. Best is trial 90 with value: 0.8282828330993652.\n",
      "[I 2024-01-30 19:28:30,532] Trial 97 finished with value: 0.7878788113594055 and parameters: {'regularizer_type': 'l2', 'activation_1': 'tanh', 'activation_2': 'selu', 'activation_3': 'relu', 'activation_4': 'softsign', 'activation_5': 'relu', 'activation_6': 'exponential', 'init_mode_1': 'glorot_normal', 'init_mode_2': 'glorot_normal', 'init_mode_3': 'lecun_uniform', 'init_mode_4': 'uniform', 'init_mode_5': 'normal', 'init_mode_6': 'glorot_normal'}. Best is trial 90 with value: 0.8282828330993652.\n",
      "[I 2024-01-30 19:28:39,015] Trial 98 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l2', 'activation_1': 'linear', 'activation_2': 'tanh', 'activation_3': 'linear', 'activation_4': 'selu', 'activation_5': 'sigmoid', 'activation_6': 'selu', 'init_mode_1': 'normal', 'init_mode_2': 'uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_normal', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}. Best is trial 90 with value: 0.8282828330993652.\n",
      "[I 2024-01-30 19:28:48,069] Trial 99 finished with value: 0.6868686676025391 and parameters: {'regularizer_type': 'l1', 'activation_1': 'relu', 'activation_2': 'swish', 'activation_3': 'softmax', 'activation_4': 'hard_sigmoid', 'activation_5': 'linear', 'activation_6': 'softplus', 'init_mode_1': 'uniform', 'init_mode_2': 'he_normal', 'init_mode_3': 'normal', 'init_mode_4': 'zero', 'init_mode_5': 'lecun_uniform', 'init_mode_6': 'zero'}. Best is trial 90 with value: 0.8282828330993652.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'regularizer_type': 'l2', 'activation_1': 'swish', 'activation_2': 'sigmoid', 'activation_3': 'softplus', 'activation_4': 'hard_sigmoid', 'activation_5': 'tanh', 'activation_6': 'softplus', 'init_mode_1': 'normal', 'init_mode_2': 'he_uniform', 'init_mode_3': 'he_normal', 'init_mode_4': 'glorot_uniform', 'init_mode_5': 'normal', 'init_mode_6': 'he_normal'}\n",
      "Elapsed time: 16.20 min.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "# Define el modelo dentro de una función que tomará los hiperparámetros como argumentos\n",
    "def create_model(activation_1, activation_2, activation_3, activation_4, activation_5, activation_6,\n",
    "                 init_mode_1, init_mode_2, init_mode_3, init_mode_4, init_mode_5, init_mode_6, regularizer_type):\n",
    "\n",
    "    if regularizer_type == \"l1\":\n",
    "        regularizer = keras.regularizers.l1(0.01)\n",
    "    elif regularizer_type == \"l2\":\n",
    "        regularizer = keras.regularizers.l2(0.01)\n",
    "    else:\n",
    "        regularizer = None\n",
    "\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(1024, input_shape=(x_train.shape[1],), activation=activation_1,\n",
    "                           kernel_initializer=init_mode_1, kernel_regularizer=regularizer_type),\n",
    "        keras.layers.Dense(512, activation=activation_2, kernel_initializer=init_mode_2),\n",
    "        keras.layers.Dense(256, activation=activation_3, kernel_initializer=init_mode_3),\n",
    "        keras.layers.Dense(128, activation=activation_4, kernel_initializer=init_mode_4),\n",
    "        keras.layers.Dense(64, activation=activation_5, kernel_initializer=init_mode_5),\n",
    "        keras.layers.Dense(1, activation=activation_6, kernel_initializer=init_mode_6),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "    return model\n",
    "\n",
    "# Función objetivo para Optuna\n",
    "def objective(trial):\n",
    "\n",
    "    regularizer_type = trial.suggest_categorical('regularizer_type', [None, \"l1\", \"l2\"])\n",
    "\n",
    "    activations_list = [\"elu\",\"exponential\",\"hard_sigmoid\",\"linear\", \"relu\",\"selu\",\"sigmoid\",\"softmax\",\"softplus\",\n",
    "                                                                                         \"softsign\",\"swish\",\"tanh\"]\n",
    "    activation_1 = trial.suggest_categorical('activation_1', activations_list)\n",
    "    activation_2 = trial.suggest_categorical('activation_2', activations_list)\n",
    "    activation_3 = trial.suggest_categorical('activation_3', activations_list)\n",
    "    activation_4 = trial.suggest_categorical('activation_4', activations_list)\n",
    "    activation_5 = trial.suggest_categorical('activation_5', activations_list)\n",
    "    activation_6 = trial.suggest_categorical('activation_6', activations_list)\n",
    "\n",
    "    init_list = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "    init_mode_1 = trial.suggest_categorical('init_mode_1', init_list)\n",
    "    init_mode_2 = trial.suggest_categorical('init_mode_2', init_list)\n",
    "    init_mode_3 = trial.suggest_categorical('init_mode_3', init_list)\n",
    "    init_mode_4 = trial.suggest_categorical('init_mode_4', init_list)\n",
    "    init_mode_5 = trial.suggest_categorical('init_mode_5', init_list)\n",
    "    init_mode_6 = trial.suggest_categorical('init_mode_6', init_list)\n",
    "\n",
    "    model = create_model(activation_1, activation_2, activation_3, activation_4, activation_5, activation_6,\n",
    "                 init_mode_1, init_mode_2, init_mode_3, init_mode_4, init_mode_5, init_mode_6, regularizer_type)\n",
    "    EarlyStop = tf.keras.callbacks.EarlyStopping(monitor = 'val_binary_accuracy', patience = 100, mode = 'max', restore_best_weights = True)\n",
    "    history = model.fit(x_train, y_train, epochs=1000, validation_data=(x_test, y_test), verbose=0, callbacks=EarlyStop)\n",
    "\n",
    "    # Usa la pérdida de validación como métrica para optimizar\n",
    "    val_loss = history.history['val_binary_accuracy'][-1]\n",
    "    return val_loss\n",
    "start=perf_counter()\n",
    "# Iniciar la optimización con Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", study.best_params)\n",
    "tl=(perf_counter()-start)/60\n",
    "print ('Elapsed time: %.2f min.' %tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regularizer_type': 'l2',\n",
       " 'activation_1': 'swish',\n",
       " 'activation_2': 'sigmoid',\n",
       " 'activation_3': 'softplus',\n",
       " 'activation_4': 'hard_sigmoid',\n",
       " 'activation_5': 'tanh',\n",
       " 'activation_6': 'softplus',\n",
       " 'init_mode_1': 'normal',\n",
       " 'init_mode_2': 'he_uniform',\n",
       " 'init_mode_3': 'he_normal',\n",
       " 'init_mode_4': 'glorot_uniform',\n",
       " 'init_mode_5': 'normal',\n",
       " 'init_mode_6': 'he_normal'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc = study.best_params\n",
    "dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pp1c3jQpnt6D",
    "outputId": "315407ef-522e-40e8-ffd8-a8ba79fb8a3d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "7/7 [==============================] - 1s 36ms/step - loss: 0.9843 - binary_accuracy: 0.6000 - val_loss: 0.8540 - val_binary_accuracy: 0.6869\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.8539 - binary_accuracy: 0.6750 - val_loss: 0.7917 - val_binary_accuracy: 0.6869\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8052 - binary_accuracy: 0.7500 - val_loss: 0.7209 - val_binary_accuracy: 0.6869\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6787 - binary_accuracy: 0.7450 - val_loss: 0.6361 - val_binary_accuracy: 0.7071\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6249 - binary_accuracy: 0.8000 - val_loss: 0.7974 - val_binary_accuracy: 0.8384\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6911 - binary_accuracy: 0.8250 - val_loss: 0.8452 - val_binary_accuracy: 0.8182\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7240 - binary_accuracy: 0.8400 - val_loss: 0.9469 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5975 - binary_accuracy: 0.8400 - val_loss: 0.6337 - val_binary_accuracy: 0.7374\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5316 - binary_accuracy: 0.8300 - val_loss: 0.6573 - val_binary_accuracy: 0.7980\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4961 - binary_accuracy: 0.8650 - val_loss: 0.7652 - val_binary_accuracy: 0.8182\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4333 - binary_accuracy: 0.8550 - val_loss: 0.6293 - val_binary_accuracy: 0.7172\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4663 - binary_accuracy: 0.8200 - val_loss: 0.7443 - val_binary_accuracy: 0.8182\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5612 - binary_accuracy: 0.8450 - val_loss: 0.5809 - val_binary_accuracy: 0.7778\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4957 - binary_accuracy: 0.8350 - val_loss: 0.7468 - val_binary_accuracy: 0.8081\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6943 - binary_accuracy: 0.8400 - val_loss: 0.6160 - val_binary_accuracy: 0.7374\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6536 - binary_accuracy: 0.7550 - val_loss: 0.7077 - val_binary_accuracy: 0.7172\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5439 - binary_accuracy: 0.7900 - val_loss: 0.7904 - val_binary_accuracy: 0.7879\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4123 - binary_accuracy: 0.8600 - val_loss: 0.5560 - val_binary_accuracy: 0.7273\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4624 - binary_accuracy: 0.8000 - val_loss: 0.5497 - val_binary_accuracy: 0.7374\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4204 - binary_accuracy: 0.8450 - val_loss: 0.5276 - val_binary_accuracy: 0.7879\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4151 - binary_accuracy: 0.8500 - val_loss: 0.5128 - val_binary_accuracy: 0.7778\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4196 - binary_accuracy: 0.8300 - val_loss: 0.6232 - val_binary_accuracy: 0.7879\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4002 - binary_accuracy: 0.8650 - val_loss: 0.6445 - val_binary_accuracy: 0.7879\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4039 - binary_accuracy: 0.8500 - val_loss: 0.6408 - val_binary_accuracy: 0.7879\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3899 - binary_accuracy: 0.8600 - val_loss: 0.6221 - val_binary_accuracy: 0.8081\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3889 - binary_accuracy: 0.8600 - val_loss: 0.6331 - val_binary_accuracy: 0.7879\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4514 - binary_accuracy: 0.8500 - val_loss: 0.6056 - val_binary_accuracy: 0.8182\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4403 - binary_accuracy: 0.8700 - val_loss: 0.6041 - val_binary_accuracy: 0.7980\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4377 - binary_accuracy: 0.8600 - val_loss: 0.6084 - val_binary_accuracy: 0.8081\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4352 - binary_accuracy: 0.8700 - val_loss: 0.7231 - val_binary_accuracy: 0.8081\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4330 - binary_accuracy: 0.8650 - val_loss: 0.6306 - val_binary_accuracy: 0.7677\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4374 - binary_accuracy: 0.8300 - val_loss: 0.7355 - val_binary_accuracy: 0.7980\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4998 - binary_accuracy: 0.8550 - val_loss: 0.7108 - val_binary_accuracy: 0.8182\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4445 - binary_accuracy: 0.8550 - val_loss: 0.5192 - val_binary_accuracy: 0.7475\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4853 - binary_accuracy: 0.8350 - val_loss: 0.5086 - val_binary_accuracy: 0.7475\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4915 - binary_accuracy: 0.7650 - val_loss: 0.5633 - val_binary_accuracy: 0.6869\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4748 - binary_accuracy: 0.8050 - val_loss: 0.5014 - val_binary_accuracy: 0.8081\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4397 - binary_accuracy: 0.8200 - val_loss: 0.5919 - val_binary_accuracy: 0.8182\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3980 - binary_accuracy: 0.8050 - val_loss: 0.6373 - val_binary_accuracy: 0.7576\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3979 - binary_accuracy: 0.8200 - val_loss: 0.6198 - val_binary_accuracy: 0.7980\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3793 - binary_accuracy: 0.8350 - val_loss: 0.5996 - val_binary_accuracy: 0.8081\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3731 - binary_accuracy: 0.8500 - val_loss: 0.6136 - val_binary_accuracy: 0.7677\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3745 - binary_accuracy: 0.8500 - val_loss: 0.5012 - val_binary_accuracy: 0.7576\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4077 - binary_accuracy: 0.8250 - val_loss: 0.4866 - val_binary_accuracy: 0.7778\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3975 - binary_accuracy: 0.8500 - val_loss: 0.5837 - val_binary_accuracy: 0.8283\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3963 - binary_accuracy: 0.8150 - val_loss: 0.6152 - val_binary_accuracy: 0.8081\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3747 - binary_accuracy: 0.8500 - val_loss: 0.5864 - val_binary_accuracy: 0.8081\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4367 - binary_accuracy: 0.8500 - val_loss: 0.5862 - val_binary_accuracy: 0.8081\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4324 - binary_accuracy: 0.8600 - val_loss: 0.6093 - val_binary_accuracy: 0.7677\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4269 - binary_accuracy: 0.8550 - val_loss: 0.7243 - val_binary_accuracy: 0.8081\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4244 - binary_accuracy: 0.8500 - val_loss: 0.6011 - val_binary_accuracy: 0.8081\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4220 - binary_accuracy: 0.8450 - val_loss: 0.6259 - val_binary_accuracy: 0.8182\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4254 - binary_accuracy: 0.8700 - val_loss: 0.6140 - val_binary_accuracy: 0.8081\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4546 - binary_accuracy: 0.8150 - val_loss: 0.6152 - val_binary_accuracy: 0.7879\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4338 - binary_accuracy: 0.8500 - val_loss: 0.5992 - val_binary_accuracy: 0.7879\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4198 - binary_accuracy: 0.8350 - val_loss: 0.6235 - val_binary_accuracy: 0.7576\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4188 - binary_accuracy: 0.8650 - val_loss: 0.7013 - val_binary_accuracy: 0.8081\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4826 - binary_accuracy: 0.8650 - val_loss: 0.7262 - val_binary_accuracy: 0.8081\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4844 - binary_accuracy: 0.8300 - val_loss: 0.7166 - val_binary_accuracy: 0.8182\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4798 - binary_accuracy: 0.8750 - val_loss: 0.7139 - val_binary_accuracy: 0.8182\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4852 - binary_accuracy: 0.8750 - val_loss: 0.7305 - val_binary_accuracy: 0.7980\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4777 - binary_accuracy: 0.8500 - val_loss: 0.7052 - val_binary_accuracy: 0.8081\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4851 - binary_accuracy: 0.8600 - val_loss: 0.7503 - val_binary_accuracy: 0.7879\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4486 - binary_accuracy: 0.8450 - val_loss: 0.6201 - val_binary_accuracy: 0.7273\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4705 - binary_accuracy: 0.7950 - val_loss: 0.6181 - val_binary_accuracy: 0.7576\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4982 - binary_accuracy: 0.8150 - val_loss: 0.5974 - val_binary_accuracy: 0.7677\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4204 - binary_accuracy: 0.8150 - val_loss: 0.5147 - val_binary_accuracy: 0.7273\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4146 - binary_accuracy: 0.8250 - val_loss: 0.5844 - val_binary_accuracy: 0.7980\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3766 - binary_accuracy: 0.8200 - val_loss: 0.5989 - val_binary_accuracy: 0.7778\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3840 - binary_accuracy: 0.8400 - val_loss: 0.6035 - val_binary_accuracy: 0.7576\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4261 - binary_accuracy: 0.8450 - val_loss: 0.7003 - val_binary_accuracy: 0.8182\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4319 - binary_accuracy: 0.8550 - val_loss: 0.6206 - val_binary_accuracy: 0.7778\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4130 - binary_accuracy: 0.8450 - val_loss: 0.5388 - val_binary_accuracy: 0.7374\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3815 - binary_accuracy: 0.8400 - val_loss: 0.5781 - val_binary_accuracy: 0.8384\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4603 - binary_accuracy: 0.8500 - val_loss: 0.5730 - val_binary_accuracy: 0.8283\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3629 - binary_accuracy: 0.8650 - val_loss: 0.6176 - val_binary_accuracy: 0.7475\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3724 - binary_accuracy: 0.8350 - val_loss: 0.5937 - val_binary_accuracy: 0.7778\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3617 - binary_accuracy: 0.8500 - val_loss: 0.5843 - val_binary_accuracy: 0.7980\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3588 - binary_accuracy: 0.8700 - val_loss: 0.5808 - val_binary_accuracy: 0.8182\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3594 - binary_accuracy: 0.8550 - val_loss: 0.6289 - val_binary_accuracy: 0.7475\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3994 - binary_accuracy: 0.8350 - val_loss: 0.6549 - val_binary_accuracy: 0.7576\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3818 - binary_accuracy: 0.8550 - val_loss: 0.5700 - val_binary_accuracy: 0.8081\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3945 - binary_accuracy: 0.8300 - val_loss: 0.6188 - val_binary_accuracy: 0.7576\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3812 - binary_accuracy: 0.8250 - val_loss: 0.6014 - val_binary_accuracy: 0.7576\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3624 - binary_accuracy: 0.8500 - val_loss: 0.5874 - val_binary_accuracy: 0.8081\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3648 - binary_accuracy: 0.8400 - val_loss: 0.6232 - val_binary_accuracy: 0.7576\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4235 - binary_accuracy: 0.8400 - val_loss: 0.7149 - val_binary_accuracy: 0.8081\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4232 - binary_accuracy: 0.8650 - val_loss: 0.6058 - val_binary_accuracy: 0.7980\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4160 - binary_accuracy: 0.8550 - val_loss: 0.6068 - val_binary_accuracy: 0.7879\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4183 - binary_accuracy: 0.8450 - val_loss: 0.7227 - val_binary_accuracy: 0.7778\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4166 - binary_accuracy: 0.8500 - val_loss: 0.7115 - val_binary_accuracy: 0.7879\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4153 - binary_accuracy: 0.8500 - val_loss: 0.7078 - val_binary_accuracy: 0.8081\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4152 - binary_accuracy: 0.8550 - val_loss: 0.7118 - val_binary_accuracy: 0.7980\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4135 - binary_accuracy: 0.8450 - val_loss: 0.7130 - val_binary_accuracy: 0.8182\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4795 - binary_accuracy: 0.8650 - val_loss: 0.7165 - val_binary_accuracy: 0.7980\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4779 - binary_accuracy: 0.8500 - val_loss: 0.7308 - val_binary_accuracy: 0.7980\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4787 - binary_accuracy: 0.8450 - val_loss: 0.7099 - val_binary_accuracy: 0.8081\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4803 - binary_accuracy: 0.8550 - val_loss: 0.7245 - val_binary_accuracy: 0.8081\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4840 - binary_accuracy: 0.8500 - val_loss: 0.7337 - val_binary_accuracy: 0.7980\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4423 - binary_accuracy: 0.8300 - val_loss: 0.6614 - val_binary_accuracy: 0.7475\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4225 - binary_accuracy: 0.8450 - val_loss: 0.7115 - val_binary_accuracy: 0.8081\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4164 - binary_accuracy: 0.8450 - val_loss: 0.7425 - val_binary_accuracy: 0.7475\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4209 - binary_accuracy: 0.8350 - val_loss: 0.7171 - val_binary_accuracy: 0.7879\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4152 - binary_accuracy: 0.8450 - val_loss: 0.7231 - val_binary_accuracy: 0.7778\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4150 - binary_accuracy: 0.8600 - val_loss: 0.7116 - val_binary_accuracy: 0.7980\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4089 - binary_accuracy: 0.8600 - val_loss: 0.6107 - val_binary_accuracy: 0.7879\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4146 - binary_accuracy: 0.8400 - val_loss: 0.6034 - val_binary_accuracy: 0.7879\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4433 - binary_accuracy: 0.8350 - val_loss: 0.5983 - val_binary_accuracy: 0.7879\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4602 - binary_accuracy: 0.8300 - val_loss: 0.5106 - val_binary_accuracy: 0.7576\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4423 - binary_accuracy: 0.7900 - val_loss: 0.5519 - val_binary_accuracy: 0.7071\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4920 - binary_accuracy: 0.7850 - val_loss: 0.5588 - val_binary_accuracy: 0.7475\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4725 - binary_accuracy: 0.7950 - val_loss: 0.5527 - val_binary_accuracy: 0.7778\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4798 - binary_accuracy: 0.8050 - val_loss: 0.6889 - val_binary_accuracy: 0.7677\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4236 - binary_accuracy: 0.8050 - val_loss: 0.6154 - val_binary_accuracy: 0.8182\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4202 - binary_accuracy: 0.8400 - val_loss: 0.6507 - val_binary_accuracy: 0.7475\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3950 - binary_accuracy: 0.8400 - val_loss: 0.6020 - val_binary_accuracy: 0.7879\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3798 - binary_accuracy: 0.8500 - val_loss: 0.5992 - val_binary_accuracy: 0.7576\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3678 - binary_accuracy: 0.8500 - val_loss: 0.6113 - val_binary_accuracy: 0.7475\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3657 - binary_accuracy: 0.8350 - val_loss: 0.6174 - val_binary_accuracy: 0.7677\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4261 - binary_accuracy: 0.8600 - val_loss: 0.5924 - val_binary_accuracy: 0.8081\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4321 - binary_accuracy: 0.8650 - val_loss: 0.5980 - val_binary_accuracy: 0.7778\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4211 - binary_accuracy: 0.8400 - val_loss: 0.5899 - val_binary_accuracy: 0.7980\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4245 - binary_accuracy: 0.8600 - val_loss: 0.7088 - val_binary_accuracy: 0.7980\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4190 - binary_accuracy: 0.8650 - val_loss: 0.6014 - val_binary_accuracy: 0.7778\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4257 - binary_accuracy: 0.8500 - val_loss: 0.6024 - val_binary_accuracy: 0.7778\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4250 - binary_accuracy: 0.8450 - val_loss: 0.5762 - val_binary_accuracy: 0.7879\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4198 - binary_accuracy: 0.8500 - val_loss: 0.5885 - val_binary_accuracy: 0.7980\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4183 - binary_accuracy: 0.8400 - val_loss: 0.7231 - val_binary_accuracy: 0.7980\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4171 - binary_accuracy: 0.8550 - val_loss: 0.6009 - val_binary_accuracy: 0.7980\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4106 - binary_accuracy: 0.8600 - val_loss: 0.6088 - val_binary_accuracy: 0.7879\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4284 - binary_accuracy: 0.8600 - val_loss: 0.5987 - val_binary_accuracy: 0.7980\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4179 - binary_accuracy: 0.8200 - val_loss: 0.6319 - val_binary_accuracy: 0.7071\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4931 - binary_accuracy: 0.7450 - val_loss: 0.5122 - val_binary_accuracy: 0.7576\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4364 - binary_accuracy: 0.8100 - val_loss: 0.6183 - val_binary_accuracy: 0.7778\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4227 - binary_accuracy: 0.8300 - val_loss: 0.5999 - val_binary_accuracy: 0.8081\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3836 - binary_accuracy: 0.8250 - val_loss: 0.6244 - val_binary_accuracy: 0.7879\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3787 - binary_accuracy: 0.8400 - val_loss: 0.6109 - val_binary_accuracy: 0.7980\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3648 - binary_accuracy: 0.8500 - val_loss: 0.5934 - val_binary_accuracy: 0.7980\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3551 - binary_accuracy: 0.8500 - val_loss: 0.5772 - val_binary_accuracy: 0.8182\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3576 - binary_accuracy: 0.8550 - val_loss: 0.5881 - val_binary_accuracy: 0.7677\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3538 - binary_accuracy: 0.8600 - val_loss: 0.5858 - val_binary_accuracy: 0.7778\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3528 - binary_accuracy: 0.8650 - val_loss: 0.5802 - val_binary_accuracy: 0.7980\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3550 - binary_accuracy: 0.8550 - val_loss: 0.5957 - val_binary_accuracy: 0.7980\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4276 - binary_accuracy: 0.8600 - val_loss: 0.5841 - val_binary_accuracy: 0.8081\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3577 - binary_accuracy: 0.8500 - val_loss: 0.6005 - val_binary_accuracy: 0.7576\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3542 - binary_accuracy: 0.8400 - val_loss: 0.5803 - val_binary_accuracy: 0.7879\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3541 - binary_accuracy: 0.8600 - val_loss: 0.5867 - val_binary_accuracy: 0.7778\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3470 - binary_accuracy: 0.8650 - val_loss: 0.5825 - val_binary_accuracy: 0.7879\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3495 - binary_accuracy: 0.8650 - val_loss: 0.5955 - val_binary_accuracy: 0.7879\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3582 - binary_accuracy: 0.8250 - val_loss: 0.6078 - val_binary_accuracy: 0.7778\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3480 - binary_accuracy: 0.8500 - val_loss: 0.5695 - val_binary_accuracy: 0.7980\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3457 - binary_accuracy: 0.8550 - val_loss: 0.5894 - val_binary_accuracy: 0.7778\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3484 - binary_accuracy: 0.8450 - val_loss: 0.5589 - val_binary_accuracy: 0.7980\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4124 - binary_accuracy: 0.8650 - val_loss: 0.5490 - val_binary_accuracy: 0.8182\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4097 - binary_accuracy: 0.8600 - val_loss: 0.5651 - val_binary_accuracy: 0.7980\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4093 - binary_accuracy: 0.8500 - val_loss: 0.6861 - val_binary_accuracy: 0.8384\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4041 - binary_accuracy: 0.8500 - val_loss: 0.5831 - val_binary_accuracy: 0.7778\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4112 - binary_accuracy: 0.8450 - val_loss: 0.5729 - val_binary_accuracy: 0.7879\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3995 - binary_accuracy: 0.8500 - val_loss: 0.5509 - val_binary_accuracy: 0.8283\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4188 - binary_accuracy: 0.8750 - val_loss: 0.4965 - val_binary_accuracy: 0.7576\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5930 - binary_accuracy: 0.7200 - val_loss: 0.6790 - val_binary_accuracy: 0.6869\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5850 - binary_accuracy: 0.6850 - val_loss: 0.5529 - val_binary_accuracy: 0.7273\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5171 - binary_accuracy: 0.8200 - val_loss: 0.4894 - val_binary_accuracy: 0.7374\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4275 - binary_accuracy: 0.8300 - val_loss: 0.4592 - val_binary_accuracy: 0.8182\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4012 - binary_accuracy: 0.8400 - val_loss: 0.5120 - val_binary_accuracy: 0.7677\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4080 - binary_accuracy: 0.8200 - val_loss: 0.5048 - val_binary_accuracy: 0.7576\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3931 - binary_accuracy: 0.8500 - val_loss: 0.5784 - val_binary_accuracy: 0.8384\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3937 - binary_accuracy: 0.8550 - val_loss: 0.4884 - val_binary_accuracy: 0.7576\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3781 - binary_accuracy: 0.8550 - val_loss: 0.4763 - val_binary_accuracy: 0.8384\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3728 - binary_accuracy: 0.8550 - val_loss: 0.5927 - val_binary_accuracy: 0.8182\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3693 - binary_accuracy: 0.8600 - val_loss: 0.5165 - val_binary_accuracy: 0.7879\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3699 - binary_accuracy: 0.8550 - val_loss: 0.5800 - val_binary_accuracy: 0.8081\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3888 - binary_accuracy: 0.8500 - val_loss: 0.4807 - val_binary_accuracy: 0.7677\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4054 - binary_accuracy: 0.8300 - val_loss: 0.4554 - val_binary_accuracy: 0.7980\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3828 - binary_accuracy: 0.8350 - val_loss: 0.5784 - val_binary_accuracy: 0.7980\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3769 - binary_accuracy: 0.8450 - val_loss: 0.5765 - val_binary_accuracy: 0.8182\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3668 - binary_accuracy: 0.8450 - val_loss: 0.5864 - val_binary_accuracy: 0.8081\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3523 - binary_accuracy: 0.8600 - val_loss: 0.5633 - val_binary_accuracy: 0.8182\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3653 - binary_accuracy: 0.8400 - val_loss: 0.5784 - val_binary_accuracy: 0.7879\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3544 - binary_accuracy: 0.8450 - val_loss: 0.5718 - val_binary_accuracy: 0.7980\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3483 - binary_accuracy: 0.8500 - val_loss: 0.5736 - val_binary_accuracy: 0.7980\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3515 - binary_accuracy: 0.8500 - val_loss: 0.5552 - val_binary_accuracy: 0.8283\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3483 - binary_accuracy: 0.8600 - val_loss: 0.6056 - val_binary_accuracy: 0.7980\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3509 - binary_accuracy: 0.8600 - val_loss: 0.5484 - val_binary_accuracy: 0.8182\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3477 - binary_accuracy: 0.8350 - val_loss: 0.5444 - val_binary_accuracy: 0.8081\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3401 - binary_accuracy: 0.8500 - val_loss: 0.5710 - val_binary_accuracy: 0.7879\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3432 - binary_accuracy: 0.8450 - val_loss: 0.5509 - val_binary_accuracy: 0.8182\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3508 - binary_accuracy: 0.8500 - val_loss: 0.5657 - val_binary_accuracy: 0.7980\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3735 - binary_accuracy: 0.8350 - val_loss: 0.6276 - val_binary_accuracy: 0.7576\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3731 - binary_accuracy: 0.8250 - val_loss: 0.5575 - val_binary_accuracy: 0.7980\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3537 - binary_accuracy: 0.8250 - val_loss: 0.5446 - val_binary_accuracy: 0.8283\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3517 - binary_accuracy: 0.8250 - val_loss: 0.5691 - val_binary_accuracy: 0.8182\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3339 - binary_accuracy: 0.8300 - val_loss: 0.5325 - val_binary_accuracy: 0.8384\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3390 - binary_accuracy: 0.8450 - val_loss: 0.5347 - val_binary_accuracy: 0.8485\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3359 - binary_accuracy: 0.8500 - val_loss: 0.5616 - val_binary_accuracy: 0.8182\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3299 - binary_accuracy: 0.8450 - val_loss: 0.5777 - val_binary_accuracy: 0.8182\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3307 - binary_accuracy: 0.8500 - val_loss: 0.5661 - val_binary_accuracy: 0.8384\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3322 - binary_accuracy: 0.8400 - val_loss: 0.5549 - val_binary_accuracy: 0.8384\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3334 - binary_accuracy: 0.8400 - val_loss: 0.5609 - val_binary_accuracy: 0.8182\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3356 - binary_accuracy: 0.8400 - val_loss: 0.6103 - val_binary_accuracy: 0.7879\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3275 - binary_accuracy: 0.8450 - val_loss: 0.5568 - val_binary_accuracy: 0.8283\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3440 - binary_accuracy: 0.8600 - val_loss: 0.6101 - val_binary_accuracy: 0.7879\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3580 - binary_accuracy: 0.8500 - val_loss: 0.6141 - val_binary_accuracy: 0.7879\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3398 - binary_accuracy: 0.8250 - val_loss: 0.5761 - val_binary_accuracy: 0.8283\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3310 - binary_accuracy: 0.8400 - val_loss: 0.5608 - val_binary_accuracy: 0.8586\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3325 - binary_accuracy: 0.8500 - val_loss: 0.5733 - val_binary_accuracy: 0.8485\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3334 - binary_accuracy: 0.8450 - val_loss: 0.5732 - val_binary_accuracy: 0.8384\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3293 - binary_accuracy: 0.8500 - val_loss: 0.5625 - val_binary_accuracy: 0.8384\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3358 - binary_accuracy: 0.8500 - val_loss: 0.5894 - val_binary_accuracy: 0.8182\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3180 - binary_accuracy: 0.8300 - val_loss: 0.5786 - val_binary_accuracy: 0.8384\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3146 - binary_accuracy: 0.8450 - val_loss: 0.5668 - val_binary_accuracy: 0.8384\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3132 - binary_accuracy: 0.8600 - val_loss: 0.5890 - val_binary_accuracy: 0.8384\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3214 - binary_accuracy: 0.8600 - val_loss: 0.6171 - val_binary_accuracy: 0.8081\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3926 - binary_accuracy: 0.8200 - val_loss: 0.4920 - val_binary_accuracy: 0.7475\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3851 - binary_accuracy: 0.8200 - val_loss: 0.4676 - val_binary_accuracy: 0.7879\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3748 - binary_accuracy: 0.8200 - val_loss: 0.4443 - val_binary_accuracy: 0.8283\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3614 - binary_accuracy: 0.8300 - val_loss: 0.4480 - val_binary_accuracy: 0.8081\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3380 - binary_accuracy: 0.8450 - val_loss: 0.4517 - val_binary_accuracy: 0.8283\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3304 - binary_accuracy: 0.8500 - val_loss: 0.5663 - val_binary_accuracy: 0.8182\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3342 - binary_accuracy: 0.8500 - val_loss: 0.5703 - val_binary_accuracy: 0.8283\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3265 - binary_accuracy: 0.8550 - val_loss: 0.5821 - val_binary_accuracy: 0.8283\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3278 - binary_accuracy: 0.8450 - val_loss: 0.5908 - val_binary_accuracy: 0.8283\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3213 - binary_accuracy: 0.8450 - val_loss: 0.6073 - val_binary_accuracy: 0.8485\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3096 - binary_accuracy: 0.8450 - val_loss: 0.5955 - val_binary_accuracy: 0.8384\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3138 - binary_accuracy: 0.8450 - val_loss: 0.6074 - val_binary_accuracy: 0.8384\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3018 - binary_accuracy: 0.8350 - val_loss: 0.6383 - val_binary_accuracy: 0.8182\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3067 - binary_accuracy: 0.8350 - val_loss: 0.6256 - val_binary_accuracy: 0.8283\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3051 - binary_accuracy: 0.8400 - val_loss: 0.6091 - val_binary_accuracy: 0.8182\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3171 - binary_accuracy: 0.8550 - val_loss: 0.6008 - val_binary_accuracy: 0.8283\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3250 - binary_accuracy: 0.8350 - val_loss: 0.6356 - val_binary_accuracy: 0.8182\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3162 - binary_accuracy: 0.8400 - val_loss: 0.6005 - val_binary_accuracy: 0.8384\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3262 - binary_accuracy: 0.8700 - val_loss: 0.6122 - val_binary_accuracy: 0.8182\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3289 - binary_accuracy: 0.8450 - val_loss: 0.6684 - val_binary_accuracy: 0.7677\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3290 - binary_accuracy: 0.8300 - val_loss: 0.6285 - val_binary_accuracy: 0.8283\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3984 - binary_accuracy: 0.8350 - val_loss: 0.6002 - val_binary_accuracy: 0.8384\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3294 - binary_accuracy: 0.8250 - val_loss: 0.6325 - val_binary_accuracy: 0.8182\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3140 - binary_accuracy: 0.8300 - val_loss: 0.6088 - val_binary_accuracy: 0.8283\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3017 - binary_accuracy: 0.8450 - val_loss: 0.5898 - val_binary_accuracy: 0.8283\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3138 - binary_accuracy: 0.8600 - val_loss: 0.6005 - val_binary_accuracy: 0.8384\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3235 - binary_accuracy: 0.8500 - val_loss: 0.6312 - val_binary_accuracy: 0.8182\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3145 - binary_accuracy: 0.8450 - val_loss: 0.6605 - val_binary_accuracy: 0.8182\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3131 - binary_accuracy: 0.8450 - val_loss: 0.6417 - val_binary_accuracy: 0.8182\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3069 - binary_accuracy: 0.8500 - val_loss: 0.6365 - val_binary_accuracy: 0.8081\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3074 - binary_accuracy: 0.8450 - val_loss: 0.6207 - val_binary_accuracy: 0.8283\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3037 - binary_accuracy: 0.8650 - val_loss: 0.6342 - val_binary_accuracy: 0.8182\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2924 - binary_accuracy: 0.8500 - val_loss: 0.6386 - val_binary_accuracy: 0.8283\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3035 - binary_accuracy: 0.8700 - val_loss: 0.6550 - val_binary_accuracy: 0.8182\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3080 - binary_accuracy: 0.8300 - val_loss: 0.6470 - val_binary_accuracy: 0.8081\n",
      "Epoch 249/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3704 - binary_accuracy: 0.8400 - val_loss: 0.6074 - val_binary_accuracy: 0.8283\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3210 - binary_accuracy: 0.8450 - val_loss: 0.5544 - val_binary_accuracy: 0.7778\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3386 - binary_accuracy: 0.8350 - val_loss: 0.5168 - val_binary_accuracy: 0.7879\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3440 - binary_accuracy: 0.8100 - val_loss: 0.5028 - val_binary_accuracy: 0.8081\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3553 - binary_accuracy: 0.8100 - val_loss: 0.5068 - val_binary_accuracy: 0.8283\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3243 - binary_accuracy: 0.8150 - val_loss: 0.5072 - val_binary_accuracy: 0.8283\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3228 - binary_accuracy: 0.8300 - val_loss: 0.5003 - val_binary_accuracy: 0.8384\n",
      "Epoch 256/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3093 - binary_accuracy: 0.8400 - val_loss: 0.6255 - val_binary_accuracy: 0.8182\n",
      "Epoch 257/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3123 - binary_accuracy: 0.8350 - val_loss: 0.6205 - val_binary_accuracy: 0.8182\n",
      "Epoch 258/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3042 - binary_accuracy: 0.8400 - val_loss: 0.6173 - val_binary_accuracy: 0.8384\n",
      "Epoch 259/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3080 - binary_accuracy: 0.8400 - val_loss: 0.6271 - val_binary_accuracy: 0.8182\n",
      "Epoch 260/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3085 - binary_accuracy: 0.8250 - val_loss: 0.6457 - val_binary_accuracy: 0.8182\n",
      "Epoch 261/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2978 - binary_accuracy: 0.8300 - val_loss: 0.6342 - val_binary_accuracy: 0.8485\n",
      "Epoch 262/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2981 - binary_accuracy: 0.8500 - val_loss: 0.6370 - val_binary_accuracy: 0.8485\n",
      "Epoch 263/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2982 - binary_accuracy: 0.8450 - val_loss: 0.6470 - val_binary_accuracy: 0.8384\n",
      "Epoch 264/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3118 - binary_accuracy: 0.8350 - val_loss: 0.6623 - val_binary_accuracy: 0.7778\n",
      "Epoch 265/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3068 - binary_accuracy: 0.8450 - val_loss: 0.6293 - val_binary_accuracy: 0.8182\n",
      "Epoch 266/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3113 - binary_accuracy: 0.8550 - val_loss: 0.6272 - val_binary_accuracy: 0.8485\n",
      "Epoch 267/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3027 - binary_accuracy: 0.8450 - val_loss: 0.5976 - val_binary_accuracy: 0.8283\n",
      "Epoch 268/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3500 - binary_accuracy: 0.8350 - val_loss: 0.6086 - val_binary_accuracy: 0.8081\n",
      "Epoch 269/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3379 - binary_accuracy: 0.8400 - val_loss: 0.6008 - val_binary_accuracy: 0.8182\n",
      "Epoch 270/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3267 - binary_accuracy: 0.8400 - val_loss: 0.6109 - val_binary_accuracy: 0.8182\n",
      "Epoch 271/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3105 - binary_accuracy: 0.8450 - val_loss: 0.6201 - val_binary_accuracy: 0.8182\n",
      "Epoch 272/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2980 - binary_accuracy: 0.8500 - val_loss: 0.6437 - val_binary_accuracy: 0.8182\n",
      "Epoch 273/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2930 - binary_accuracy: 0.8500 - val_loss: 0.6387 - val_binary_accuracy: 0.8182\n",
      "Epoch 274/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2905 - binary_accuracy: 0.8650 - val_loss: 0.6381 - val_binary_accuracy: 0.8182\n",
      "Epoch 275/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2894 - binary_accuracy: 0.8600 - val_loss: 0.6327 - val_binary_accuracy: 0.8182\n",
      "Epoch 276/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2874 - binary_accuracy: 0.8450 - val_loss: 0.6522 - val_binary_accuracy: 0.8182\n",
      "Epoch 277/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2895 - binary_accuracy: 0.8500 - val_loss: 0.6543 - val_binary_accuracy: 0.8182\n",
      "Epoch 278/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2824 - binary_accuracy: 0.8500 - val_loss: 0.6689 - val_binary_accuracy: 0.8182\n",
      "Epoch 279/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2813 - binary_accuracy: 0.8450 - val_loss: 0.6656 - val_binary_accuracy: 0.8182\n",
      "Epoch 280/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2848 - binary_accuracy: 0.8550 - val_loss: 0.6488 - val_binary_accuracy: 0.8182\n",
      "Epoch 281/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2808 - binary_accuracy: 0.8600 - val_loss: 0.6298 - val_binary_accuracy: 0.8182\n",
      "Epoch 282/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2798 - binary_accuracy: 0.8650 - val_loss: 0.6397 - val_binary_accuracy: 0.8081\n",
      "Epoch 283/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2871 - binary_accuracy: 0.8750 - val_loss: 0.6338 - val_binary_accuracy: 0.8182\n",
      "Epoch 284/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2874 - binary_accuracy: 0.8750 - val_loss: 0.6471 - val_binary_accuracy: 0.8182\n",
      "Epoch 285/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3021 - binary_accuracy: 0.8500 - val_loss: 0.6659 - val_binary_accuracy: 0.8182\n",
      "Epoch 286/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3034 - binary_accuracy: 0.8600 - val_loss: 0.6725 - val_binary_accuracy: 0.8182\n",
      "Epoch 287/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2943 - binary_accuracy: 0.8400 - val_loss: 0.6777 - val_binary_accuracy: 0.7879\n",
      "Epoch 288/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2965 - binary_accuracy: 0.8250 - val_loss: 0.6402 - val_binary_accuracy: 0.8081\n",
      "Epoch 289/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2856 - binary_accuracy: 0.8450 - val_loss: 0.6326 - val_binary_accuracy: 0.8081\n",
      "Epoch 290/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2837 - binary_accuracy: 0.8450 - val_loss: 0.6417 - val_binary_accuracy: 0.8182\n",
      "Epoch 291/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2854 - binary_accuracy: 0.8500 - val_loss: 0.6513 - val_binary_accuracy: 0.8081\n",
      "Epoch 292/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2789 - binary_accuracy: 0.8550 - val_loss: 0.6581 - val_binary_accuracy: 0.8182\n",
      "Epoch 293/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2872 - binary_accuracy: 0.8550 - val_loss: 0.6410 - val_binary_accuracy: 0.8384\n",
      "Epoch 294/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2854 - binary_accuracy: 0.8600 - val_loss: 0.6829 - val_binary_accuracy: 0.8081\n",
      "Epoch 295/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2839 - binary_accuracy: 0.8550 - val_loss: 0.6609 - val_binary_accuracy: 0.8182\n",
      "Epoch 296/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2935 - binary_accuracy: 0.8450 - val_loss: 0.6319 - val_binary_accuracy: 0.8182\n",
      "Epoch 297/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3139 - binary_accuracy: 0.8600 - val_loss: 0.6519 - val_binary_accuracy: 0.8182\n",
      "Epoch 298/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3459 - binary_accuracy: 0.8500 - val_loss: 0.6629 - val_binary_accuracy: 0.8182\n",
      "Epoch 299/1000\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.3345 - binary_accuracy: 0.8450 - val_loss: 0.6436 - val_binary_accuracy: 0.8081\n",
      "Epoch 300/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3236 - binary_accuracy: 0.8400 - val_loss: 0.6227 - val_binary_accuracy: 0.8081\n",
      "Epoch 301/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3742 - binary_accuracy: 0.8400 - val_loss: 0.6278 - val_binary_accuracy: 0.8081\n",
      "Epoch 302/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3959 - binary_accuracy: 0.8350 - val_loss: 0.6650 - val_binary_accuracy: 0.7374\n",
      "Epoch 303/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3740 - binary_accuracy: 0.8400 - val_loss: 0.7670 - val_binary_accuracy: 0.7879\n",
      "Epoch 304/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5155 - binary_accuracy: 0.7950 - val_loss: 0.7503 - val_binary_accuracy: 0.6970\n",
      "Epoch 305/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7627 - binary_accuracy: 0.6750 - val_loss: 0.7215 - val_binary_accuracy: 0.6869\n",
      "Epoch 306/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6285 - binary_accuracy: 0.6750 - val_loss: 0.6331 - val_binary_accuracy: 0.7071\n",
      "Epoch 307/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6072 - binary_accuracy: 0.6900 - val_loss: 0.6110 - val_binary_accuracy: 0.7273\n",
      "Epoch 308/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5580 - binary_accuracy: 0.7050 - val_loss: 0.6130 - val_binary_accuracy: 0.6869\n",
      "Epoch 309/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5516 - binary_accuracy: 0.7100 - val_loss: 0.6072 - val_binary_accuracy: 0.7172\n",
      "Epoch 310/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5025 - binary_accuracy: 0.8050 - val_loss: 0.5942 - val_binary_accuracy: 0.7475\n",
      "Epoch 311/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4920 - binary_accuracy: 0.8200 - val_loss: 0.5758 - val_binary_accuracy: 0.7778\n",
      "Epoch 312/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4661 - binary_accuracy: 0.8250 - val_loss: 0.5617 - val_binary_accuracy: 0.7677\n",
      "Epoch 313/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4600 - binary_accuracy: 0.8350 - val_loss: 0.5659 - val_binary_accuracy: 0.8081\n",
      "Epoch 314/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4505 - binary_accuracy: 0.8300 - val_loss: 0.5845 - val_binary_accuracy: 0.8081\n",
      "Epoch 315/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4513 - binary_accuracy: 0.8350 - val_loss: 0.5677 - val_binary_accuracy: 0.8283\n",
      "Epoch 316/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4407 - binary_accuracy: 0.8450 - val_loss: 0.5651 - val_binary_accuracy: 0.8182\n",
      "Epoch 317/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4332 - binary_accuracy: 0.8500 - val_loss: 0.5618 - val_binary_accuracy: 0.8283\n",
      "Epoch 318/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4322 - binary_accuracy: 0.8450 - val_loss: 0.5624 - val_binary_accuracy: 0.8283\n",
      "Epoch 319/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4183 - binary_accuracy: 0.8500 - val_loss: 0.5468 - val_binary_accuracy: 0.8182\n",
      "Epoch 320/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4118 - binary_accuracy: 0.8550 - val_loss: 0.5486 - val_binary_accuracy: 0.8283\n",
      "Epoch 321/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4171 - binary_accuracy: 0.8450 - val_loss: 0.5514 - val_binary_accuracy: 0.8182\n",
      "Epoch 322/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4182 - binary_accuracy: 0.8600 - val_loss: 0.5640 - val_binary_accuracy: 0.8283\n",
      "Epoch 323/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4479 - binary_accuracy: 0.8300 - val_loss: 0.5479 - val_binary_accuracy: 0.8283\n",
      "Epoch 324/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4166 - binary_accuracy: 0.8550 - val_loss: 0.5348 - val_binary_accuracy: 0.8283\n",
      "Epoch 325/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4106 - binary_accuracy: 0.8400 - val_loss: 0.5297 - val_binary_accuracy: 0.8182\n",
      "Epoch 326/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4131 - binary_accuracy: 0.8500 - val_loss: 0.5320 - val_binary_accuracy: 0.8283\n",
      "Epoch 327/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4016 - binary_accuracy: 0.8550 - val_loss: 0.5487 - val_binary_accuracy: 0.8182\n",
      "Epoch 328/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4045 - binary_accuracy: 0.8600 - val_loss: 0.5418 - val_binary_accuracy: 0.8283\n",
      "Epoch 329/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3905 - binary_accuracy: 0.8550 - val_loss: 0.5511 - val_binary_accuracy: 0.8081\n",
      "Epoch 330/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3995 - binary_accuracy: 0.8650 - val_loss: 0.5518 - val_binary_accuracy: 0.8081\n",
      "Epoch 331/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3949 - binary_accuracy: 0.8650 - val_loss: 0.5721 - val_binary_accuracy: 0.8081\n",
      "Epoch 332/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3926 - binary_accuracy: 0.8500 - val_loss: 0.5355 - val_binary_accuracy: 0.8081\n",
      "Epoch 333/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3966 - binary_accuracy: 0.8700 - val_loss: 0.5859 - val_binary_accuracy: 0.8182\n",
      "Epoch 334/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4695 - binary_accuracy: 0.8350 - val_loss: 0.5923 - val_binary_accuracy: 0.8182\n",
      "Epoch 335/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4033 - binary_accuracy: 0.8500 - val_loss: 0.5231 - val_binary_accuracy: 0.8182\n",
      "Epoch 336/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4085 - binary_accuracy: 0.8500 - val_loss: 0.5209 - val_binary_accuracy: 0.8081\n",
      "Epoch 337/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4174 - binary_accuracy: 0.8450 - val_loss: 0.5370 - val_binary_accuracy: 0.8182\n",
      "Epoch 338/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3885 - binary_accuracy: 0.8650 - val_loss: 0.5239 - val_binary_accuracy: 0.7879\n",
      "Epoch 339/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4291 - binary_accuracy: 0.8300 - val_loss: 0.5389 - val_binary_accuracy: 0.7980\n",
      "Epoch 340/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4224 - binary_accuracy: 0.8350 - val_loss: 0.5761 - val_binary_accuracy: 0.7778\n",
      "Epoch 341/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4097 - binary_accuracy: 0.8300 - val_loss: 0.5775 - val_binary_accuracy: 0.7677\n",
      "Epoch 342/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4088 - binary_accuracy: 0.8550 - val_loss: 0.5846 - val_binary_accuracy: 0.7677\n",
      "Epoch 343/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3998 - binary_accuracy: 0.8350 - val_loss: 0.5712 - val_binary_accuracy: 0.7677\n",
      "Epoch 344/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3899 - binary_accuracy: 0.8500 - val_loss: 0.5570 - val_binary_accuracy: 0.7980\n",
      "Epoch 345/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3843 - binary_accuracy: 0.8500 - val_loss: 0.5456 - val_binary_accuracy: 0.7879\n",
      "Epoch 346/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3848 - binary_accuracy: 0.8550 - val_loss: 0.5360 - val_binary_accuracy: 0.7980\n",
      "Epoch 347/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3734 - binary_accuracy: 0.8550 - val_loss: 0.5189 - val_binary_accuracy: 0.8081\n",
      "Epoch 348/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3771 - binary_accuracy: 0.8650 - val_loss: 0.5342 - val_binary_accuracy: 0.8081\n",
      "Epoch 349/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4028 - binary_accuracy: 0.8400 - val_loss: 0.5904 - val_binary_accuracy: 0.7879\n",
      "Epoch 350/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3991 - binary_accuracy: 0.8500 - val_loss: 0.5768 - val_binary_accuracy: 0.7879\n",
      "Epoch 351/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3677 - binary_accuracy: 0.8600 - val_loss: 0.5712 - val_binary_accuracy: 0.7879\n",
      "Epoch 352/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3740 - binary_accuracy: 0.8600 - val_loss: 0.5890 - val_binary_accuracy: 0.7778\n",
      "Epoch 353/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3748 - binary_accuracy: 0.8600 - val_loss: 0.5633 - val_binary_accuracy: 0.7677\n",
      "Epoch 354/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3630 - binary_accuracy: 0.8650 - val_loss: 0.5432 - val_binary_accuracy: 0.7677\n",
      "Epoch 355/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3532 - binary_accuracy: 0.8550 - val_loss: 0.6742 - val_binary_accuracy: 0.7879\n",
      "Epoch 356/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3332 - binary_accuracy: 0.8600 - val_loss: 0.6740 - val_binary_accuracy: 0.7980\n",
      "Epoch 357/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3336 - binary_accuracy: 0.8650 - val_loss: 0.6918 - val_binary_accuracy: 0.7980\n",
      "Epoch 358/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3327 - binary_accuracy: 0.8650 - val_loss: 0.6947 - val_binary_accuracy: 0.7879\n",
      "Epoch 359/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3266 - binary_accuracy: 0.8650 - val_loss: 0.7002 - val_binary_accuracy: 0.7980\n",
      "Epoch 360/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3194 - binary_accuracy: 0.8650 - val_loss: 0.6923 - val_binary_accuracy: 0.7879\n",
      "Epoch 361/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3160 - binary_accuracy: 0.8700 - val_loss: 0.6883 - val_binary_accuracy: 0.7879\n",
      "Epoch 362/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3238 - binary_accuracy: 0.8500 - val_loss: 0.7055 - val_binary_accuracy: 0.7980\n",
      "Epoch 363/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3230 - binary_accuracy: 0.8650 - val_loss: 0.6959 - val_binary_accuracy: 0.7980\n",
      "Epoch 364/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3099 - binary_accuracy: 0.8700 - val_loss: 0.7158 - val_binary_accuracy: 0.7879\n",
      "Epoch 365/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3330 - binary_accuracy: 0.8550 - val_loss: 0.7037 - val_binary_accuracy: 0.7879\n",
      "Epoch 366/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3203 - binary_accuracy: 0.8650 - val_loss: 0.8097 - val_binary_accuracy: 0.8081\n",
      "Epoch 367/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3113 - binary_accuracy: 0.8700 - val_loss: 0.7132 - val_binary_accuracy: 0.7778\n",
      "Epoch 368/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3257 - binary_accuracy: 0.8600 - val_loss: 0.7109 - val_binary_accuracy: 0.7879\n",
      "Epoch 369/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3219 - binary_accuracy: 0.8600 - val_loss: 0.7191 - val_binary_accuracy: 0.7677\n",
      "Epoch 370/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3216 - binary_accuracy: 0.8600 - val_loss: 0.7223 - val_binary_accuracy: 0.7980\n",
      "Epoch 371/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3348 - binary_accuracy: 0.8600 - val_loss: 0.7894 - val_binary_accuracy: 0.7879\n",
      "Epoch 372/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3365 - binary_accuracy: 0.8550 - val_loss: 0.8020 - val_binary_accuracy: 0.7778\n",
      "Epoch 373/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3268 - binary_accuracy: 0.8600 - val_loss: 0.7266 - val_binary_accuracy: 0.7980\n",
      "Epoch 374/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3393 - binary_accuracy: 0.8500 - val_loss: 0.8350 - val_binary_accuracy: 0.7778\n",
      "Epoch 375/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3259 - binary_accuracy: 0.8650 - val_loss: 0.7260 - val_binary_accuracy: 0.7778\n",
      "Epoch 376/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3215 - binary_accuracy: 0.8700 - val_loss: 0.6258 - val_binary_accuracy: 0.7879\n",
      "Epoch 377/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3137 - binary_accuracy: 0.8650 - val_loss: 0.7448 - val_binary_accuracy: 0.7879\n",
      "Epoch 378/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3075 - binary_accuracy: 0.8650 - val_loss: 0.8710 - val_binary_accuracy: 0.7879\n",
      "Epoch 379/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3055 - binary_accuracy: 0.8500 - val_loss: 0.8447 - val_binary_accuracy: 0.7980\n",
      "Epoch 380/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3023 - binary_accuracy: 0.8650 - val_loss: 0.8259 - val_binary_accuracy: 0.7879\n",
      "Epoch 381/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3074 - binary_accuracy: 0.8700 - val_loss: 0.8333 - val_binary_accuracy: 0.7980\n",
      "Epoch 382/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3385 - binary_accuracy: 0.8500 - val_loss: 0.9639 - val_binary_accuracy: 0.7879\n",
      "Epoch 383/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5246 - binary_accuracy: 0.8400 - val_loss: 0.9832 - val_binary_accuracy: 0.7879\n",
      "Epoch 384/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3948 - binary_accuracy: 0.8250 - val_loss: 0.8880 - val_binary_accuracy: 0.7677\n",
      "Epoch 385/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4001 - binary_accuracy: 0.8150 - val_loss: 0.7188 - val_binary_accuracy: 0.7576\n",
      "Epoch 386/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3754 - binary_accuracy: 0.8450 - val_loss: 0.5492 - val_binary_accuracy: 0.7475\n",
      "Epoch 387/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3515 - binary_accuracy: 0.8550 - val_loss: 0.6876 - val_binary_accuracy: 0.7576\n",
      "Epoch 388/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3381 - binary_accuracy: 0.8700 - val_loss: 0.6974 - val_binary_accuracy: 0.7980\n",
      "Epoch 389/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3244 - binary_accuracy: 0.8700 - val_loss: 0.7136 - val_binary_accuracy: 0.7677\n",
      "Epoch 390/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3131 - binary_accuracy: 0.8700 - val_loss: 0.7260 - val_binary_accuracy: 0.7576\n",
      "Epoch 391/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3152 - binary_accuracy: 0.8750 - val_loss: 0.7148 - val_binary_accuracy: 0.7778\n",
      "Epoch 392/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3021 - binary_accuracy: 0.8700 - val_loss: 0.7398 - val_binary_accuracy: 0.7677\n",
      "Epoch 393/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3115 - binary_accuracy: 0.8600 - val_loss: 0.8629 - val_binary_accuracy: 0.7778\n",
      "Epoch 394/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3119 - binary_accuracy: 0.8550 - val_loss: 0.8567 - val_binary_accuracy: 0.7778\n",
      "Epoch 395/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3121 - binary_accuracy: 0.8700 - val_loss: 0.8337 - val_binary_accuracy: 0.7778\n",
      "Epoch 396/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3071 - binary_accuracy: 0.8600 - val_loss: 0.8523 - val_binary_accuracy: 0.7677\n",
      "Epoch 397/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3110 - binary_accuracy: 0.8400 - val_loss: 0.8658 - val_binary_accuracy: 0.7980\n",
      "Epoch 398/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3020 - binary_accuracy: 0.8600 - val_loss: 0.8410 - val_binary_accuracy: 0.7879\n",
      "Epoch 399/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2824 - binary_accuracy: 0.8700 - val_loss: 0.8584 - val_binary_accuracy: 0.7879\n",
      "Epoch 400/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2821 - binary_accuracy: 0.8700 - val_loss: 0.8675 - val_binary_accuracy: 0.7879\n",
      "Epoch 401/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2730 - binary_accuracy: 0.8650 - val_loss: 0.8710 - val_binary_accuracy: 0.7677\n",
      "Epoch 402/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2659 - binary_accuracy: 0.9000 - val_loss: 0.8563 - val_binary_accuracy: 0.7778\n",
      "Epoch 403/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2635 - binary_accuracy: 0.8950 - val_loss: 0.8668 - val_binary_accuracy: 0.7879\n",
      "Epoch 404/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2656 - binary_accuracy: 0.8800 - val_loss: 0.9098 - val_binary_accuracy: 0.7879\n",
      "Epoch 405/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2678 - binary_accuracy: 0.8950 - val_loss: 0.8564 - val_binary_accuracy: 0.7374\n",
      "Epoch 406/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2944 - binary_accuracy: 0.8850 - val_loss: 0.8240 - val_binary_accuracy: 0.7778\n",
      "Epoch 407/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2933 - binary_accuracy: 0.8850 - val_loss: 0.8494 - val_binary_accuracy: 0.7677\n",
      "Epoch 408/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2826 - binary_accuracy: 0.8750 - val_loss: 0.8486 - val_binary_accuracy: 0.7576\n",
      "Epoch 409/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2720 - binary_accuracy: 0.8900 - val_loss: 0.8812 - val_binary_accuracy: 0.7576\n",
      "Epoch 410/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2626 - binary_accuracy: 0.8950 - val_loss: 0.8966 - val_binary_accuracy: 0.7677\n",
      "Epoch 411/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2642 - binary_accuracy: 0.8850 - val_loss: 0.9079 - val_binary_accuracy: 0.7576\n",
      "Epoch 412/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2719 - binary_accuracy: 0.9050 - val_loss: 0.9047 - val_binary_accuracy: 0.7273\n",
      "Epoch 413/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2923 - binary_accuracy: 0.8850 - val_loss: 0.9745 - val_binary_accuracy: 0.7475\n",
      "Epoch 414/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4249 - binary_accuracy: 0.8150 - val_loss: 0.8038 - val_binary_accuracy: 0.7273\n",
      "Epoch 415/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4232 - binary_accuracy: 0.8200 - val_loss: 0.7329 - val_binary_accuracy: 0.7576\n",
      "Epoch 416/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4043 - binary_accuracy: 0.8300 - val_loss: 0.6981 - val_binary_accuracy: 0.7273\n",
      "Epoch 417/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3955 - binary_accuracy: 0.8350 - val_loss: 0.7769 - val_binary_accuracy: 0.7677\n",
      "Epoch 418/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3840 - binary_accuracy: 0.8500 - val_loss: 0.6881 - val_binary_accuracy: 0.7576\n",
      "Epoch 419/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3478 - binary_accuracy: 0.8800 - val_loss: 0.7617 - val_binary_accuracy: 0.7576\n",
      "Epoch 420/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3598 - binary_accuracy: 0.8750 - val_loss: 0.7028 - val_binary_accuracy: 0.7374\n",
      "Epoch 421/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3385 - binary_accuracy: 0.8750 - val_loss: 0.6552 - val_binary_accuracy: 0.7980\n",
      "Epoch 422/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3273 - binary_accuracy: 0.8650 - val_loss: 0.7003 - val_binary_accuracy: 0.7778\n",
      "Epoch 423/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3150 - binary_accuracy: 0.8850 - val_loss: 0.8346 - val_binary_accuracy: 0.7475\n",
      "Epoch 424/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3105 - binary_accuracy: 0.8750 - val_loss: 0.7034 - val_binary_accuracy: 0.7576\n",
      "Epoch 425/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3017 - binary_accuracy: 0.8800 - val_loss: 0.7567 - val_binary_accuracy: 0.7475\n",
      "Epoch 426/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3138 - binary_accuracy: 0.8750 - val_loss: 0.8418 - val_binary_accuracy: 0.7475\n",
      "Epoch 427/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3022 - binary_accuracy: 0.8900 - val_loss: 0.7359 - val_binary_accuracy: 0.7475\n",
      "Epoch 428/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2965 - binary_accuracy: 0.8850 - val_loss: 0.7396 - val_binary_accuracy: 0.7475\n",
      "Epoch 429/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2881 - binary_accuracy: 0.9100 - val_loss: 0.7066 - val_binary_accuracy: 0.7475\n",
      "Epoch 430/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2973 - binary_accuracy: 0.8600 - val_loss: 0.7168 - val_binary_accuracy: 0.7879\n",
      "Epoch 431/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3047 - binary_accuracy: 0.8900 - val_loss: 0.7409 - val_binary_accuracy: 0.7374\n",
      "Epoch 432/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3065 - binary_accuracy: 0.8850 - val_loss: 0.7470 - val_binary_accuracy: 0.7273\n",
      "Epoch 433/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2905 - binary_accuracy: 0.8900 - val_loss: 0.7624 - val_binary_accuracy: 0.7576\n",
      "Epoch 434/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2935 - binary_accuracy: 0.8850 - val_loss: 0.7568 - val_binary_accuracy: 0.7576\n",
      "Epoch 435/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2844 - binary_accuracy: 0.8850 - val_loss: 0.8801 - val_binary_accuracy: 0.7576\n",
      "Epoch 436/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2792 - binary_accuracy: 0.8800 - val_loss: 0.8574 - val_binary_accuracy: 0.7677\n",
      "Epoch 437/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2666 - binary_accuracy: 0.8950 - val_loss: 0.8821 - val_binary_accuracy: 0.7677\n",
      "Epoch 438/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2613 - binary_accuracy: 0.8800 - val_loss: 0.9159 - val_binary_accuracy: 0.7576\n",
      "Epoch 439/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2510 - binary_accuracy: 0.9100 - val_loss: 0.9251 - val_binary_accuracy: 0.7576\n",
      "Epoch 440/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2612 - binary_accuracy: 0.9100 - val_loss: 0.9442 - val_binary_accuracy: 0.7576\n",
      "Epoch 441/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2472 - binary_accuracy: 0.9100 - val_loss: 0.9843 - val_binary_accuracy: 0.7576\n",
      "Epoch 442/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3796 - binary_accuracy: 0.8800 - val_loss: 1.5877 - val_binary_accuracy: 0.7677\n",
      "Epoch 443/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3741 - binary_accuracy: 0.8800 - val_loss: 1.2115 - val_binary_accuracy: 0.7576\n",
      "Epoch 444/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3859 - binary_accuracy: 0.9100 - val_loss: 1.3494 - val_binary_accuracy: 0.7576\n",
      "Epoch 445/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3803 - binary_accuracy: 0.9100 - val_loss: 1.5957 - val_binary_accuracy: 0.7475\n",
      "Epoch 446/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5537 - binary_accuracy: 0.8500 - val_loss: 1.4391 - val_binary_accuracy: 0.6970\n",
      "Epoch 447/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3145 - binary_accuracy: 0.6900 - val_loss: 1.2934 - val_binary_accuracy: 0.6869\n",
      "Epoch 448/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0898 - binary_accuracy: 0.6750 - val_loss: 0.8779 - val_binary_accuracy: 0.5758\n",
      "Epoch 449/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9020 - binary_accuracy: 0.5500 - val_loss: 0.7663 - val_binary_accuracy: 0.6970\n",
      "Epoch 450/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7774 - binary_accuracy: 0.6900 - val_loss: 0.7954 - val_binary_accuracy: 0.6768\n",
      "Epoch 451/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7329 - binary_accuracy: 0.7000 - val_loss: 0.7685 - val_binary_accuracy: 0.6768\n",
      "Epoch 452/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6892 - binary_accuracy: 0.7300 - val_loss: 0.7569 - val_binary_accuracy: 0.6970\n",
      "Epoch 453/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6972 - binary_accuracy: 0.7300 - val_loss: 0.7497 - val_binary_accuracy: 0.7071\n",
      "Epoch 454/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6964 - binary_accuracy: 0.7200 - val_loss: 0.7702 - val_binary_accuracy: 0.6869\n",
      "Epoch 455/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6794 - binary_accuracy: 0.7300 - val_loss: 0.7492 - val_binary_accuracy: 0.7071\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5608 - binary_accuracy: 0.8586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5608489513397217, 0.8585858345031738]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if dicc['regularizer_type'] == 'None':\n",
    "    dicc['regularizer_type'] = None\n",
    "    \n",
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(1024, input_shape=(x_train.shape[1],), activation = dicc['activation_1'], kernel_initializer=dicc['init_mode_1'], kernel_regularizer=dicc['regularizer_type']),\n",
    "    keras.layers.Dense(512, activation=dicc['activation_2'], kernel_initializer=dicc['init_mode_2']),\n",
    "    keras.layers.Dense(256, activation=dicc['activation_3'], kernel_initializer=dicc['init_mode_3']),\n",
    "    keras.layers.Dense(128, activation=dicc['activation_4'], kernel_initializer=dicc['init_mode_4']),\n",
    "    keras.layers.Dense(64, activation=dicc['activation_5'], kernel_initializer=dicc['init_mode_5']),\n",
    "    keras.layers.Dense((df['label'].nunique()-1), activation=dicc['activation_6'], kernel_initializer=dicc['init_mode_6'])\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.BinaryCrossentropy(),\n",
    "    metrics = keras.metrics.BinaryAccuracy()\n",
    ")\n",
    "\n",
    "EarlyStop = tf.keras.callbacks.EarlyStopping(monitor = 'val_binary_accuracy', patience = 250, mode = 'max', restore_best_weights = True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 1000, validation_data=(x_test, y_test), callbacks=EarlyStop)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "id": "8F3bMnOewzVQ",
    "outputId": "462b690e-f155-4f20-cf2d-70ee157a34c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.90        68\n",
      "           1       0.87      0.65      0.74        31\n",
      "\n",
      "    accuracy                           0.86        99\n",
      "   macro avg       0.86      0.80      0.82        99\n",
      "weighted avg       0.86      0.86      0.85        99\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_names = ['0', '1']\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index=target_names, columns=target_names)\n",
    "sns.set(font_scale=1.0)\n",
    "\n",
    "sns.heatmap(cm_df, cmap='Blues',annot=True, fmt='g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score\n",
      "0.8217592592592593\n",
      "0.8585858585858586\n",
      "0.8520389075944631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F1-score')\n",
    "print(f1_score(y_test, y_pred, average='macro'))\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
